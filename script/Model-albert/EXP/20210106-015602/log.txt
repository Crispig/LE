device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1834
step: 10 | train loss: 0.02317609265446663 | train acc 0.4003623127937317
step: 10 | train loss: 0.016634173691272736 | train acc 0.4285714328289032
step: 20 | train loss: 0.011878655292093754 | train acc 0.6965035200119019
step: 20 | train loss: 0.008247810415923595 | train acc 0.7631579041481018
step: 30 | train loss: 0.010340314358472824 | train acc 0.7888730764389038
step: 30 | train loss: 0.0042186882346868515 | train acc 0.9166666865348816
step: 40 | train loss: 0.008048820309340954 | train acc 0.8011363744735718
step: 40 | train loss: 0.0032964383717626333 | train acc 0.8500000238418579
step: 50 | train loss: 0.007227911613881588 | train acc 0.830945611000061
step: 50 | train loss: 0.0074339271523058414 | train acc 0.824999988079071
step: 60 | train loss: 0.008007070980966091 | train acc 0.7979651093482971
step: 60 | train loss: 0.012937603518366814 | train acc 0.6470588445663452
step: 70 | train loss: 0.008596621453762054 | train acc 0.8562367558479309
step: 70 | train loss: 0.005190181080251932 | train acc 0.8378378748893738
step: 80 | train loss: 0.007803766056895256 | train acc 0.8248174786567688
step: 80 | train loss: 0.005228031426668167 | train acc 0.8461538553237915
step: 90 | train loss: 0.007483305409550667 | train acc 0.8065433502197266
step: 90 | train loss: 0.005209803115576506 | train acc 0.8717948794364929
step: 100 | train loss: 0.006156073417514563 | train acc 0.8487874865531921
step: 100 | train loss: 0.004814370535314083 | train acc 0.8648648858070374
step: 110 | train loss: 0.008111403323709965 | train acc 0.8066759705543518
step: 110 | train loss: 0.0035985861904919147 | train acc 0.8888888955116272
step: 120 | train loss: 0.006731550209224224 | train acc 0.8492957353591919
step: 120 | train loss: 0.00813587848097086 | train acc 0.8461538553237915
step: 130 | train loss: 0.006283287890255451 | train acc 0.8532257676124573
step: 130 | train loss: 0.007467776536941528 | train acc 1.0
step: 140 | train loss: 0.004813797306269407 | train acc 0.894568681716919
step: 140 | train loss: 0.003539516357704997 | train acc 0.8918918967247009
step: 150 | train loss: 0.0079945158213377 | train acc 0.8510028719902039
step: 150 | train loss: 0.03928656131029129 | train acc 0.5714285969734192
step: 160 | train loss: 0.00492151640355587 | train acc 0.893217921257019
step: 160 | train loss: 0.003270260291174054 | train acc 0.9473684430122375
step: 170 | train loss: 0.004859079606831074 | train acc 0.8981077075004578
step: 170 | train loss: 0.0046624387614429 | train acc 0.8421052694320679
step: 180 | train loss: 0.005288830492645502 | train acc 0.8693758845329285
step: 180 | train loss: 0.011593981646001339 | train acc 0.6756756901741028
step: 190 | train loss: 0.005789551883935928 | train acc 0.8503703474998474
step: 190 | train loss: 0.0027000438421964645 | train acc 0.90625
step: 200 | train loss: 0.008149540983140469 | train acc 0.840266227722168
step: 200 | train loss: 0.004667906556278467 | train acc 0.8571428656578064
step: 210 | train loss: 0.005508859641849995 | train acc 0.8624113202095032
step: 210 | train loss: 0.01862228848040104 | train acc 0.8148148059844971
step: 220 | train loss: 0.0052574132569134235 | train acc 0.8703169822692871
step: 220 | train loss: 0.0047621699050068855 | train acc 0.8787878751754761
step: 230 | train loss: 0.005738455336540937 | train acc 0.8536585569381714
step: 230 | train loss: 0.004071153234690428 | train acc 0.8888888955116272
step: 240 | train loss: 0.004929530434310436 | train acc 0.8744588494300842
step: 240 | train loss: 0.022328922525048256 | train acc 0.6410256624221802
step: 250 | train loss: 0.005167368799448013 | train acc 0.8842856884002686
step: 250 | train loss: 0.0033658016473054886 | train acc 0.9230769276618958
step: 260 | train loss: 0.005934974644333124 | train acc 0.8680555820465088
step: 260 | train loss: 0.008099985308945179 | train acc 0.8888888955116272
step: 270 | train loss: 0.004573254380375147 | train acc 0.8882521986961365
step: 270 | train loss: 0.003372976090759039 | train acc 0.9166666865348816
step: 280 | train loss: 0.004381310194730759 | train acc 0.8868195414543152
step: 280 | train loss: 0.0050111678428947926 | train acc 0.8918918967247009
step: 290 | train loss: 0.004545568488538265 | train acc 0.8936781287193298
step: 290 | train loss: 0.0023933183401823044 | train acc 0.9210526347160339
step: 300 | train loss: 0.004400234669446945 | train acc 0.8917378783226013
step: 300 | train loss: 0.0073045650497078896 | train acc 0.8684210777282715
step: 310 | train loss: 0.006771160755306482 | train acc 0.8558823466300964
step: 310 | train loss: 0.0017401863588020205 | train acc 0.949999988079071
step: 320 | train loss: 0.005430332850664854 | train acc 0.8714069128036499
step: 320 | train loss: 0.010782886296510696 | train acc 0.7428571581840515
step: 330 | train loss: 0.004842586815357208 | train acc 0.894568681716919
step: 330 | train loss: 0.0048675863072276115 | train acc 0.8611111044883728
step: 340 | train loss: 0.004342556465417147 | train acc 0.8967001438140869
step: 340 | train loss: 0.008543313480913639 | train acc 0.8108108043670654
step: 350 | train loss: 0.003749695373699069 | train acc 0.9058988690376282
step: 350 | train loss: 0.01537337526679039 | train acc 0.6153846383094788
step: 360 | train loss: 0.00343147199600935 | train acc 0.9050279259681702
step: 360 | train loss: 0.0017468456644564867 | train acc 0.9696969985961914
step: 370 | train loss: 0.003955854568630457 | train acc 0.9148311018943787
step: 370 | train loss: 0.005810851231217384 | train acc 0.9210526347160339
step: 380 | train loss: 0.0052607120014727116 | train acc 0.8573466539382935
step: 380 | train loss: 0.0035322478506714106 | train acc 0.8684210777282715
step: 390 | train loss: 0.005919774062931538 | train acc 0.8856209516525269
step: 390 | train loss: 0.002617716556414962 | train acc 0.8947368264198303
step: 400 | train loss: 0.00474298931658268 | train acc 0.8865247964859009
step: 400 | train loss: 0.008595326915383339 | train acc 0.8378378748893738
step: 410 | train loss: 0.0066421558149158955 | train acc 0.8733624815940857
step: 410 | train loss: 0.003580859862267971 | train acc 0.9189189672470093
step: 420 | train loss: 0.004730788059532642 | train acc 0.892241358757019
step: 420 | train loss: 0.003548497799783945 | train acc 0.90625
step: 430 | train loss: 0.00479090865701437 | train acc 0.8830083608627319
step: 430 | train loss: 0.005078469403088093 | train acc 0.875
step: 440 | train loss: 0.005238079000264406 | train acc 0.8884057998657227
step: 440 | train loss: 0.006423036567866802 | train acc 0.8108108043670654
step: 450 | train loss: 0.005216821096837521 | train acc 0.8801916837692261
step: 450 | train loss: 0.0032988530583679676 | train acc 1.0
step: 460 | train loss: 0.005227294750511646 | train acc 0.8839694857597351
step: 460 | train loss: 0.0019033098360523582 | train acc 0.9696969985961914
step: 470 | train loss: 0.007442045956850052 | train acc 0.8644315004348755
step: 470 | train loss: 0.010039189830422401 | train acc 0.7777777910232544
step: 480 | train loss: 0.004515600390732288 | train acc 0.9121037125587463
step: 480 | train loss: 0.005571221932768822 | train acc 0.8108108043670654
step: 490 | train loss: 0.005213605705648661 | train acc 0.8779411911964417
step: 490 | train loss: 0.004224308300763369 | train acc 0.9032257795333862
step: 500 | train loss: 0.007025148253887892 | train acc 0.8525547385215759
step: 500 | train loss: 0.00841005239635706 | train acc 0.7894737124443054
step: 510 | train loss: 0.005051563493907452 | train acc 0.8623718619346619
step: 510 | train loss: 0.008072889409959316 | train acc 0.699999988079071
step: 520 | train loss: 0.0052649895660579205 | train acc 0.8862179517745972
step: 520 | train loss: 0.004354360979050398 | train acc 0.8421052694320679
step: 530 | train loss: 0.007338918745517731 | train acc 0.8549075126647949
step: 530 | train loss: 0.004868234507739544 | train acc 0.8684210777282715
step: 540 | train loss: 0.004649212583899498 | train acc 0.9061166048049927
step: 540 | train loss: 0.002921130508184433 | train acc 0.9393939971923828
step: 550 | train loss: 0.004770477768033743 | train acc 0.8924137949943542
step: 550 | train loss: 0.006067301612347364 | train acc 0.8285714387893677
step: 560 | train loss: 0.00464808102697134 | train acc 0.9011461734771729
step: 560 | train loss: 0.0026009576395154 | train acc 0.9729729890823364
step: 570 | train loss: 0.004997083451598883 | train acc 0.859375
step: 570 | train loss: 0.002537692431360483 | train acc 0.9428571462631226
step: 580 | train loss: 0.005688371602445841 | train acc 0.8998144865036011
step: 580 | train loss: 0.0035125678405165672 | train acc 1.0
step: 590 | train loss: 0.004824684467166662 | train acc 0.8925233483314514
step: 590 | train loss: 0.004532468039542437 | train acc 0.9166666865348816
step: 600 | train loss: 0.004177892114967108 | train acc 0.887798011302948
step: 600 | train loss: 0.002266999799758196 | train acc 0.9142857193946838
step: 610 | train loss: 0.004540198016911745 | train acc 0.8912429213523865
step: 610 | train loss: 0.0062187607400119305 | train acc 0.8974359035491943
step: 620 | train loss: 0.004932956304401159 | train acc 0.8831908702850342
step: 620 | train loss: 0.014170197769999504 | train acc 0.7179487347602844
step: 630 | train loss: 0.00618214625865221 | train acc 0.874471127986908
step: 630 | train loss: 0.0029070947784930468 | train acc 0.925000011920929
step: 640 | train loss: 0.005273914430290461 | train acc 0.8824383020401001
step: 640 | train loss: 0.0032776508014649153 | train acc 0.9333333969116211
step: 650 | train loss: 0.004020167514681816 | train acc 0.8941548466682434
step: 650 | train loss: 0.002682974562048912 | train acc 0.9487179517745972
step: 660 | train loss: 0.005829899106174707 | train acc 0.8699421882629395
step: 660 | train loss: 0.008245171047747135 | train acc 0.8421052694320679
step: 670 | train loss: 0.0040466925129294395 | train acc 0.8999999761581421
step: 670 | train loss: 0.002362586325034499 | train acc 0.9677419066429138
step: 680 | train loss: 0.00420306297019124 | train acc 0.9144927859306335
step: 680 | train loss: 0.0033705574460327625 | train acc 0.9722222089767456
step: 690 | train loss: 0.003442858112975955 | train acc 0.9101449847221375
step: 690 | train loss: 0.009802183136343956 | train acc 0.7878788113594055
step: 700 | train loss: 0.005486511159688234 | train acc 0.8800578117370605
step: 700 | train loss: 0.004042214248329401 | train acc 0.9166666865348816
step: 710 | train loss: 0.006575458683073521 | train acc 0.8627118468284607
step: 710 | train loss: 0.005079315043985844 | train acc 0.8918918967247009
step: 720 | train loss: 0.004675030242651701 | train acc 0.8982300758361816
step: 720 | train loss: 0.005963160656392574 | train acc 0.8709677457809448
step: 730 | train loss: 0.004339775536209345 | train acc 0.8847795128822327
step: 730 | train loss: 0.0038614668883383274 | train acc 0.8947368264198303
step: 740 | train loss: 0.004793295171111822 | train acc 0.8867924213409424
step: 740 | train loss: 0.0030587282963097095 | train acc 0.9230769276618958
step: 750 | train loss: 0.0038549371529370546 | train acc 0.8959537148475647
step: 750 | train loss: 0.003735816339030862 | train acc 0.9487179517745972
step: 760 | train loss: 0.004956626333296299 | train acc 0.8833087086677551
step: 760 | train loss: 0.00624387152493 | train acc 0.75
step: 770 | train loss: 0.0051454175263643265 | train acc 0.8771653771400452
step: 770 | train loss: 0.0068861497566103935 | train acc 0.8947368264198303
step: 780 | train loss: 0.005906205158680677 | train acc 0.8647481799125671
step: 780 | train loss: 0.004098560195416212 | train acc 0.8684210777282715
step: 790 | train loss: 0.004159593489021063 | train acc 0.8916544914245605
step: 790 | train loss: 0.006588970310986042 | train acc 0.8928571939468384
step: 800 | train loss: 0.0034230805467814207 | train acc 0.9067431688308716
step: 800 | train loss: 0.002980980323627591 | train acc 0.9375
step: 810 | train loss: 0.0040714191272854805 | train acc 0.9000000357627869
step: 810 | train loss: 0.0032116705551743507 | train acc 0.9210526347160339
step: 820 | train loss: 0.006388472858816385 | train acc 0.8765778541564941
step: 820 | train loss: 0.004415043164044619 | train acc 0.8684210777282715
step: 830 | train loss: 0.004539520014077425 | train acc 0.8918083310127258
step: 830 | train loss: 0.00937048438936472 | train acc 0.7647058963775635
step: 840 | train loss: 0.006203123833984137 | train acc 0.9059406518936157
step: 840 | train loss: 0.005052063148468733 | train acc 0.9117646813392639
step: 850 | train loss: 0.0033166748471558094 | train acc 0.9148629307746887
step: 850 | train loss: 0.0038862840738147497 | train acc 0.9428571462631226
step: 860 | train loss: 0.0039791627787053585 | train acc 0.8974359035491943
step: 860 | train loss: 0.0030204474460333586 | train acc 0.9000000357627869
step: 870 | train loss: 0.004655737895518541 | train acc 0.8963414430618286
step: 870 | train loss: 0.004865841940045357 | train acc 0.8571428656578064
step: 880 | train loss: 0.0036036160308867693 | train acc 0.9033188819885254
step: 880 | train loss: 0.004714695271104574 | train acc 0.9090909361839294
step: 890 | train loss: 0.004875189159065485 | train acc 0.8787878751754761
step: 890 | train loss: 0.0032260084990411997 | train acc 0.9142857193946838
step: 900 | train loss: 0.005571033805608749 | train acc 0.8823529481887817
step: 900 | train loss: 0.0041211992502212524 | train acc 0.8918918967247009
step: 910 | train loss: 0.004162637982517481 | train acc 0.8960114121437073
step: 910 | train loss: 0.0031475673895329237 | train acc 0.8974359035491943
step: 920 | train loss: 0.0025108044501394033 | train acc 0.9761905074119568
step: 920 | train loss: 0.00442592054605484 | train acc 0.944444477558136
step: 930 | train loss: 0.0020831057336181402 | train acc 0.9518950581550598
step: 930 | train loss: 0.001816271455027163 | train acc 0.96875
step: 940 | train loss: 0.002637629397213459 | train acc 0.9384164214134216
step: 940 | train loss: 0.0009759370586834848 | train acc 0.9736841917037964
step: 950 | train loss: 0.0023232437670230865 | train acc 0.9468531608581543
step: 950 | train loss: 0.00920211523771286 | train acc 0.7750000357627869
step: 960 | train loss: 0.002494509331882 | train acc 0.9485714435577393
step: 960 | train loss: 0.002073764568194747 | train acc 0.9459459781646729
step: 970 | train loss: 0.0022355334367603064 | train acc 0.9495090842247009
step: 970 | train loss: 0.004776539746671915 | train acc 0.9000000357627869
step: 980 | train loss: 0.0024201138876378536 | train acc 0.941605806350708
step: 980 | train loss: 0.0022421851754188538 | train acc 0.9428571462631226
step: 990 | train loss: 0.0029354554135352373 | train acc 0.9485049843788147
step: 990 | train loss: 0.0037376796826720238 | train acc 0.9189189672470093
step: 1000 | train loss: 0.004674193449318409 | train acc 0.9124820828437805
step: 1000 | train loss: 0.0022684584837406874 | train acc 0.9729729890823364
step: 1010 | train loss: 0.0037445269990712404 | train acc 0.9280575513839722
step: 1010 | train loss: 0.0020708998199552298 | train acc 0.9473684430122375
step: 1020 | train loss: 0.002493378007784486 | train acc 0.9415954351425171
step: 1020 | train loss: 0.0016928797122091055 | train acc 0.9696969985961914
step: 1030 | train loss: 0.0022624714765697718 | train acc 0.9510791301727295
step: 1030 | train loss: 0.0020162712316960096 | train acc 0.9729729890823364
step: 1040 | train loss: 0.001876850612461567 | train acc 0.9621318578720093
step: 1040 | train loss: 0.0011543979635462165 | train acc 0.9750000238418579
step: 1050 | train loss: 0.0031264908611774445 | train acc 0.9490333795547485
step: 1050 | train loss: 0.0017032435862347484 | train acc 0.9705882668495178
step: 1060 | train loss: 0.0038792556151747704 | train acc 0.9299269914627075
step: 1060 | train loss: 0.006423160899430513 | train acc 0.8823529481887817
step: 1070 | train loss: 0.003379171947017312 | train acc 0.9467787146568298
step: 1070 | train loss: 0.001828931737691164 | train acc 0.9729729890823364
step: 1080 | train loss: 0.0029137704987078905 | train acc 0.9504249095916748
step: 1080 | train loss: 0.009352355264127254 | train acc 0.9473684430122375
step: 1090 | train loss: 0.003176171099767089 | train acc 0.9340813159942627
step: 1090 | train loss: 0.000741425494197756 | train acc 0.9736841917037964
step: 1100 | train loss: 0.006262800190597773 | train acc 0.8967551589012146
step: 1100 | train loss: 0.0014606433687731624 | train acc 0.9750000238418579
step: 1110 | train loss: 0.003276123898103833 | train acc 0.9280470013618469
step: 1110 | train loss: 0.0023741640616208315 | train acc 0.9333333969116211
step: 1120 | train loss: 0.002825672971084714 | train acc 0.9506802558898926
step: 1120 | train loss: 0.0006370206247083843 | train acc 1.0
step: 1130 | train loss: 0.002057539066299796 | train acc 0.9669064879417419
step: 1130 | train loss: 0.0010736645199358463 | train acc 0.9705882668495178
step: 1140 | train loss: 0.0021604357752949 | train acc 0.9525139331817627
step: 1140 | train loss: 0.0032318036537617445 | train acc 0.9142857193946838
step: 1150 | train loss: 0.003969651181250811 | train acc 0.9317851662635803
step: 1150 | train loss: 0.0024848130997270346 | train acc 0.9411764740943909
step: 1160 | train loss: 0.002076540607959032 | train acc 0.9532577991485596
step: 1160 | train loss: 0.0016211025649681687 | train acc 0.949999988079071
step: 1170 | train loss: 0.0027152360416948795 | train acc 0.9221901893615723
step: 1170 | train loss: 0.0004204674332868308 | train acc 1.0
step: 1180 | train loss: 0.0026440960355103016 | train acc 0.9584055542945862
step: 1180 | train loss: 0.002363763749599457 | train acc 0.9375
step: 1190 | train loss: 0.003477665362879634 | train acc 0.9319825768470764
step: 1190 | train loss: 0.0006739918026141822 | train acc 0.9736841917037964
step: 1200 | train loss: 0.0031707175076007843 | train acc 0.9460992813110352
step: 1200 | train loss: 0.0016996217891573906 | train acc 0.9393939971923828
step: 1210 | train loss: 0.003948663827031851 | train acc 0.9148935675621033
step: 1210 | train loss: 0.002295906189829111 | train acc 0.9729729890823364
step: 1220 | train loss: 0.0025862306356430054 | train acc 0.9411764740943909
step: 1220 | train loss: 0.0014920359244570136 | train acc 0.9487179517745972
step: 1230 | train loss: 0.004546268377453089 | train acc 0.9240875840187073
step: 1230 | train loss: 0.0018180564511567354 | train acc 0.949999988079071
step: 1240 | train loss: 0.002563436748459935 | train acc 0.9335443377494812
step: 1240 | train loss: 0.0024335074704140425 | train acc 0.949999988079071
step: 1250 | train loss: 0.0025585421826690435 | train acc 0.9534161686897278
step: 1250 | train loss: 0.0015297300415113568 | train acc 0.9428571462631226
step: 1260 | train loss: 0.0037873871624469757 | train acc 0.9273504018783569
step: 1260 | train loss: 0.0025031298864632845 | train acc 0.949999988079071
step: 1270 | train loss: 0.0022705895826220512 | train acc 0.9553956985473633
step: 1270 | train loss: 0.0007564384723082185 | train acc 1.0
step: 1280 | train loss: 0.0026725369971245527 | train acc 0.9313725829124451
step: 1280 | train loss: 0.0005586170591413975 | train acc 1.0
step: 1290 | train loss: 0.0033080202993005514 | train acc 0.9386860728263855
step: 1290 | train loss: 0.0029093725606799126 | train acc 0.9230769276618958
step: 1300 | train loss: 0.002645085332915187 | train acc 0.9519774317741394
step: 1300 | train loss: 0.020009780302643776 | train acc 0.675000011920929
step: 1310 | train loss: 0.004512985702604055 | train acc 0.9252971410751343
step: 1310 | train loss: 0.00036373091279529035 | train acc 1.0
step: 1320 | train loss: 0.0012843345757573843 | train acc 0.9723435640335083
step: 1320 | train loss: 0.006413070484995842 | train acc 0.9375
step: 1330 | train loss: 0.001989208161830902 | train acc 0.9524495601654053
step: 1330 | train loss: 0.003633335931226611 | train acc 0.9696969985961914
step: 1340 | train loss: 0.002523741452023387 | train acc 0.9506531357765198
step: 1340 | train loss: 0.00020002170640509576 | train acc 1.0
step: 1350 | train loss: 0.002462476957589388 | train acc 0.9579100012779236
step: 1350 | train loss: 0.0011802436783909798 | train acc 0.9722222089767456
step: 1360 | train loss: 0.004137800540775061 | train acc 0.9137930870056152
step: 1360 | train loss: 0.0020655314438045025 | train acc 0.9666666984558105
step: 1370 | train loss: 0.002413305686786771 | train acc 0.9400684833526611
step: 1370 | train loss: 0.00032196001848205924 | train acc 1.0
step: 1380 | train loss: 0.003283002180978656 | train acc 0.9409221410751343
step: 1380 | train loss: 0.001274535316042602 | train acc 0.949999988079071
step: 1390 | train loss: 0.003573436988517642 | train acc 0.9281689524650574
step: 1390 | train loss: 0.0008950086194090545 | train acc 0.9750000238418579
step: 1400 | train loss: 0.002170705236494541 | train acc 0.9570815563201904
step: 1400 | train loss: 0.00025067038950510323 | train acc 1.0
step: 1410 | train loss: 0.0023063011467456818 | train acc 0.9389204978942871
step: 1410 | train loss: 0.00028222097898833454 | train acc 1.0
step: 1420 | train loss: 0.0044644614681601524 | train acc 0.918639063835144
step: 1420 | train loss: 0.0018447081092745066 | train acc 0.949999988079071
step: 1430 | train loss: 0.0020893283654004335 | train acc 0.954402506351471
step: 1430 | train loss: 0.0026659860741347075 | train acc 0.9666666984558105
step: 1440 | train loss: 0.0024928306229412556 | train acc 0.9638158082962036
step: 1440 | train loss: 0.004164894577115774 | train acc 0.9000000357627869
step: 1450 | train loss: 0.0025193970650434494 | train acc 0.9530791640281677
step: 1450 | train loss: 0.0013458712492138147 | train acc 0.9722222089767456
step: 1460 | train loss: 0.0025967436376959085 | train acc 0.9491525292396545
step: 1460 | train loss: 0.000988173414953053 | train acc 0.9722222089767456
step: 1470 | train loss: 0.001876872149296105 | train acc 0.9504373669624329
step: 1470 | train loss: 0.0016190779861062765 | train acc 0.9642857313156128
step: 1480 | train loss: 0.0026236220728605986 | train acc 0.9388335347175598
step: 1480 | train loss: 0.0006150218541733921 | train acc 0.9729729890823364
step: 1490 | train loss: 0.002296336693689227 | train acc 0.9520348906517029
step: 1490 | train loss: 0.0027829385362565517 | train acc 0.875
step: 1500 | train loss: 0.005731965880841017 | train acc 0.9123711585998535
step: 1500 | train loss: 0.0010022385977208614 | train acc 1.0
step: 1510 | train loss: 0.0022465852089226246 | train acc 0.9583911299705505
step: 1510 | train loss: 0.004851233679801226 | train acc 0.8461538553237915
step: 1520 | train loss: 0.00128465355373919 | train acc 0.9715909361839294
step: 1520 | train loss: 0.0006460738950408995 | train acc 1.0
step: 1530 | train loss: 0.00198287982493639 | train acc 0.9546098709106445
step: 1530 | train loss: 0.002843948546797037 | train acc 0.96875
step: 1540 | train loss: 0.001830394729040563 | train acc 0.957602322101593
step: 1540 | train loss: 0.0037140778731554747 | train acc 0.875
step: 1550 | train loss: 0.0026138753164559603 | train acc 0.9476048350334167
step: 1550 | train loss: 0.0012961371103301644 | train acc 0.9743589758872986
step: 1560 | train loss: 0.001816334668546915 | train acc 0.9675324559211731
step: 1560 | train loss: 0.0008894316852092743 | train acc 1.0
step: 1570 | train loss: 0.0019917269237339497 | train acc 0.9554234743118286
step: 1570 | train loss: 0.004752312321215868 | train acc 0.8823529481887817
step: 1580 | train loss: 0.0036600367166101933 | train acc 0.9259796738624573
step: 1580 | train loss: 0.0013172964099794626 | train acc 0.9696969985961914
step: 1590 | train loss: 0.0016662304988130927 | train acc 0.9633286595344543
step: 1590 | train loss: 0.005229567177593708 | train acc 0.8947368264198303
step: 1600 | train loss: 0.0016484697116538882 | train acc 0.9605078101158142
step: 1600 | train loss: 0.0012452710652723908 | train acc 0.9677419066429138
step: 1610 | train loss: 0.0025416461285203695 | train acc 0.9597122073173523
step: 1610 | train loss: 0.01074387039989233 | train acc 0.875
step: 1620 | train loss: 0.0035659719724208117 | train acc 0.9311999678611755
step: 1620 | train loss: 0.00298494310118258 | train acc 0.9230769872665405
step: 1630 | train loss: 0.003068389603868127 | train acc 0.9528985619544983
step: 1630 | train loss: 0.0012017551343888044 | train acc 0.9714285731315613
step: 1640 | train loss: 0.0031865453347563744 | train acc 0.9357143044471741
step: 1640 | train loss: 0.0019874826539307833 | train acc 0.9393939971923828
step: 1650 | train loss: 0.003772241761907935 | train acc 0.9399707317352295
step: 1650 | train loss: 0.0009246281115338206 | train acc 0.9722222089767456
step: 1660 | train loss: 0.0015140896430239081 | train acc 0.9553072452545166
step: 1660 | train loss: 0.0025253472849726677 | train acc 0.944444477558136
step: 1670 | train loss: 0.0037890539970248938 | train acc 0.9351199269294739
step: 1670 | train loss: 0.002327938564121723 | train acc 0.9032257795333862
step: 1680 | train loss: 0.0032384837977588177 | train acc 0.9408450126647949
step: 1680 | train loss: 0.00138652918394655 | train acc 0.949999988079071
step: 1690 | train loss: 0.0029998801182955503 | train acc 0.9344537854194641
step: 1690 | train loss: 0.00035532747278921306 | train acc 1.0
step: 1700 | train loss: 0.0017087635351344943 | train acc 0.9591549038887024
step: 1700 | train loss: 0.0022261561825871468 | train acc 0.944444477558136
step: 1710 | train loss: 0.0021727392449975014 | train acc 0.949999988079071
step: 1710 | train loss: 0.00011906312283826992 | train acc 1.0
step: 1720 | train loss: 0.0015174216823652387 | train acc 0.9797687530517578
step: 1720 | train loss: 0.002910331590101123 | train acc 0.9189189672470093
step: 1730 | train loss: 0.0015300725353881717 | train acc 0.9683453440666199
step: 1730 | train loss: 0.0015047552296891809 | train acc 0.9714285731315613
step: 1740 | train loss: 0.0010388921946287155 | train acc 0.9803094267845154
step: 1740 | train loss: 0.001457561505958438 | train acc 0.9729729890823364
step: 1750 | train loss: 0.0026016144547611475 | train acc 0.9355783462524414
step: 1750 | train loss: 0.0029694039840251207 | train acc 0.875
step: 1760 | train loss: 0.0027974797412753105 | train acc 0.9460870027542114
step: 1760 | train loss: 0.0006940861348994076 | train acc 0.9743589758872986
step: 1770 | train loss: 0.002754446119070053 | train acc 0.9338235259056091
step: 1770 | train loss: 0.0009046908817254007 | train acc 0.9736841917037964
step: 1780 | train loss: 0.002108265645802021 | train acc 0.9533528089523315
step: 1780 | train loss: 0.002438222523778677 | train acc 0.9487179517745972
step: 1790 | train loss: 0.0015419988194480538 | train acc 0.9680365324020386
step: 1790 | train loss: 0.00963644590228796 | train acc 0.800000011920929
step: 1800 | train loss: 0.0017810631543397903 | train acc 0.969298243522644
step: 1800 | train loss: 0.00011505249131005257 | train acc 1.0
step: 1810 | train loss: 0.002178392605856061 | train acc 0.9584569931030273
step: 1810 | train loss: 0.0025483882054686546 | train acc 0.949999988079071
step: 1820 | train loss: 0.002621622756123543 | train acc 0.9504792094230652
step: 1820 | train loss: 0.0016879916656762362 | train acc 0.949999988079071
step: 1830 | train loss: 0.0018083908362314105 | train acc 0.9570815563201904
step: 1830 | train loss: 0.004793827421963215 | train acc 0.9117646813392639
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1836
  valid_eval_accuracy = 0.8909976917158245
  valid_eval_loss = 0.38525869992544065
