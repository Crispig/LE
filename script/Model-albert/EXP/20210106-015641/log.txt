device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1833
step: 10 | train loss: 0.02151254005730152 | train acc 0.4183514714241028
step: 10 | train loss: 0.01603163219988346 | train acc 0.5
step: 20 | train loss: 0.011649957858026028 | train acc 0.694767415523529
step: 20 | train loss: 0.006405886262655258 | train acc 0.8205128312110901
step: 30 | train loss: 0.008685968816280365 | train acc 0.7862266898155212
step: 30 | train loss: 0.0056253657676279545 | train acc 0.7948718070983887
step: 40 | train loss: 0.008271591737866402 | train acc 0.7900875210762024
step: 40 | train loss: 0.004934343975037336 | train acc 0.8620689511299133
step: 50 | train loss: 0.007303104270249605 | train acc 0.8131241202354431
step: 50 | train loss: 0.004846334457397461 | train acc 0.8421052694320679
step: 60 | train loss: 0.008720551617443562 | train acc 0.7756314873695374
step: 60 | train loss: 0.006606062408536673 | train acc 0.8108108043670654
step: 70 | train loss: 0.009607195854187012 | train acc 0.8098859190940857
step: 70 | train loss: 0.005122786853462458 | train acc 0.8611111044883728
step: 80 | train loss: 0.0072339619509875774 | train acc 0.8234421610832214
step: 80 | train loss: 0.004016757011413574 | train acc 0.9142857193946838
step: 90 | train loss: 0.007530784234404564 | train acc 0.8171262741088867
step: 90 | train loss: 0.0022964307572692633 | train acc 0.9714285731315613
step: 100 | train loss: 0.006929838564246893 | train acc 0.8036984205245972
step: 100 | train loss: 0.00793542992323637 | train acc 0.7692307829856873
step: 110 | train loss: 0.007102952338755131 | train acc 0.8175487518310547
step: 110 | train loss: 0.00715666264295578 | train acc 0.8857142925262451
step: 120 | train loss: 0.008438179269433022 | train acc 0.8076358437538147
step: 120 | train loss: 0.0064229294657707214 | train acc 0.8500000238418579
step: 130 | train loss: 0.0069945696741342545 | train acc 0.8208722472190857
step: 130 | train loss: 0.007038882002234459 | train acc 1.0
step: 140 | train loss: 0.0059218499809503555 | train acc 0.8552238941192627
step: 140 | train loss: 0.007683930452913046 | train acc 0.8484848737716675
step: 150 | train loss: 0.005410860292613506 | train acc 0.8531976938247681
step: 150 | train loss: 0.0026244993787258863 | train acc 0.9000000357627869
step: 160 | train loss: 0.005836350377649069 | train acc 0.8530259132385254
step: 160 | train loss: 0.006611719261854887 | train acc 0.7948718070983887
step: 170 | train loss: 0.005577154457569122 | train acc 0.8486562967300415
step: 170 | train loss: 0.0078093791380524635 | train acc 0.7692307829856873
step: 180 | train loss: 0.005932100582867861 | train acc 0.8632478713989258
step: 180 | train loss: 0.011582313105463982 | train acc 0.7586206793785095
step: 190 | train loss: 0.005269363988190889 | train acc 0.8565217852592468
step: 190 | train loss: 0.008147715590894222 | train acc 0.8823529481887817
step: 200 | train loss: 0.00811570044606924 | train acc 0.8554421663284302
step: 200 | train loss: 0.008144974708557129 | train acc 0.8611111044883728
step: 210 | train loss: 0.005057197064161301 | train acc 0.8762589693069458
step: 210 | train loss: 0.003799005877226591 | train acc 0.8421052694320679
step: 220 | train loss: 0.00856971275061369 | train acc 0.8382978439331055
step: 220 | train loss: 0.010590950958430767 | train acc 0.800000011920929
step: 230 | train loss: 0.004662385676056147 | train acc 0.8762736916542053
step: 230 | train loss: 0.0045418222434818745 | train acc 0.8461538553237915
step: 240 | train loss: 0.0068156179040670395 | train acc 0.8399999737739563
step: 240 | train loss: 0.0023672187235206366 | train acc 0.925000011920929
step: 250 | train loss: 0.006862376816570759 | train acc 0.8333333730697632
step: 250 | train loss: 0.005238142795860767 | train acc 0.875
step: 260 | train loss: 0.0053836931474506855 | train acc 0.8662519454956055
step: 260 | train loss: 0.004409365821629763 | train acc 0.9459459781646729
step: 270 | train loss: 0.00482042133808136 | train acc 0.883024275302887
step: 270 | train loss: 0.0021006527822464705 | train acc 0.9714285731315613
step: 280 | train loss: 0.004638070706278086 | train acc 0.8898550868034363
step: 280 | train loss: 0.0027612580452114344 | train acc 0.944444477558136
step: 290 | train loss: 0.005383426323533058 | train acc 0.8720112442970276
step: 290 | train loss: 0.006147094536572695 | train acc 0.8461538553237915
step: 300 | train loss: 0.004643381107598543 | train acc 0.8846153616905212
step: 300 | train loss: 0.0034953535068780184 | train acc 0.9230769276618958
step: 310 | train loss: 0.00732908770442009 | train acc 0.8418740630149841
step: 310 | train loss: 0.00339950411580503 | train acc 0.875
step: 320 | train loss: 0.00547676719725132 | train acc 0.87151700258255
step: 320 | train loss: 0.01070829201489687 | train acc 0.8500000238418579
step: 330 | train loss: 0.00666614156216383 | train acc 0.8706070184707642
step: 330 | train loss: 0.004952480550855398 | train acc 0.8648648858070374
step: 340 | train loss: 0.0045126513577997684 | train acc 0.8951149582862854
step: 340 | train loss: 0.008316250517964363 | train acc 0.824999988079071
step: 350 | train loss: 0.004560464061796665 | train acc 0.8687589168548584
step: 350 | train loss: 0.0014351645950227976 | train acc 0.9729729890823364
step: 360 | train loss: 0.0047920928336679935 | train acc 0.8804665207862854
step: 360 | train loss: 0.003793883603066206 | train acc 0.8947368264198303
step: 370 | train loss: 0.00548744248226285 | train acc 0.8648256063461304
step: 370 | train loss: 0.0054495492950081825 | train acc 0.8461538553237915
step: 380 | train loss: 0.0062455167062580585 | train acc 0.8267605304718018
step: 380 | train loss: 0.006022201851010323 | train acc 0.8529411554336548
step: 390 | train loss: 0.006002530455589294 | train acc 0.8862385153770447
step: 390 | train loss: 0.003037702292203903 | train acc 0.9230769276618958
step: 400 | train loss: 0.004487671423703432 | train acc 0.8893678188323975
step: 400 | train loss: 0.009306271560490131 | train acc 0.7837837934494019
step: 410 | train loss: 0.0061306762509047985 | train acc 0.8776671290397644
step: 410 | train loss: 0.0023194225504994392 | train acc 0.9166666865348816
step: 420 | train loss: 0.003906646277755499 | train acc 0.895714282989502
step: 420 | train loss: 0.0013813076075166464 | train acc 0.9750000238418579
step: 430 | train loss: 0.0072995820082724094 | train acc 0.8607954978942871
step: 430 | train loss: 0.004399152938276529 | train acc 0.8717948794364929
step: 440 | train loss: 0.005395147483795881 | train acc 0.884839653968811
step: 440 | train loss: 0.0017383522354066372 | train acc 0.96875
step: 450 | train loss: 0.005915447138249874 | train acc 0.8771330714225769
step: 450 | train loss: 0.00378270260989666 | train acc 1.0
step: 460 | train loss: 0.0069009484723210335 | train acc 0.8544668555259705
step: 460 | train loss: 0.0587424635887146 | train acc 0.4333333671092987
step: 470 | train loss: 0.0038642387371510267 | train acc 0.9022988677024841
step: 470 | train loss: 0.00265785725787282 | train acc 0.9210526347160339
step: 480 | train loss: 0.004431203939020634 | train acc 0.8892045617103577
step: 480 | train loss: 0.008479511365294456 | train acc 0.9000000357627869
step: 490 | train loss: 0.006404505111277103 | train acc 0.8648648262023926
step: 490 | train loss: 0.0016517001204192638 | train acc 1.0
step: 500 | train loss: 0.006539348978549242 | train acc 0.8556998372077942
step: 500 | train loss: 0.0012152439448982477 | train acc 1.0
step: 510 | train loss: 0.00516914390027523 | train acc 0.8858447670936584
step: 510 | train loss: 0.007134770974516869 | train acc 0.8378378748893738
step: 520 | train loss: 0.005238205660134554 | train acc 0.8796147704124451
step: 520 | train loss: 0.0008917429368011653 | train acc 1.0
step: 530 | train loss: 0.0044370475225150585 | train acc 0.8836206793785095
step: 530 | train loss: 0.0036638849414885044 | train acc 0.8717948794364929
step: 540 | train loss: 0.007119387853890657 | train acc 0.8569384813308716
step: 540 | train loss: 0.005181791726499796 | train acc 0.9189189672470093
step: 550 | train loss: 0.0038013234734535217 | train acc 0.9076005816459656
step: 550 | train loss: 0.003279317170381546 | train acc 0.9411764740943909
step: 560 | train loss: 0.0031115012243390083 | train acc 0.931851863861084
step: 560 | train loss: 0.0030326759442687035 | train acc 0.9000000357627869
step: 570 | train loss: 0.0038544568233191967 | train acc 0.9057142734527588
step: 570 | train loss: 0.007835699245333672 | train acc 0.7692307829856873
step: 580 | train loss: 0.007225764449685812 | train acc 0.8430033922195435
step: 580 | train loss: 0.005065788049250841 | train acc 0.8378378748893738
step: 590 | train loss: 0.0068279136903584 | train acc 0.874452531337738
step: 590 | train loss: 0.0037753628566861153 | train acc 0.8461538553237915
step: 600 | train loss: 0.004605897702276707 | train acc 0.8997092843055725
step: 600 | train loss: 0.008220456540584564 | train acc 0.7575757503509521
step: 610 | train loss: 0.004158626776188612 | train acc 0.8931083083152771
step: 610 | train loss: 0.005599751602858305 | train acc 0.8684210777282715
step: 620 | train loss: 0.0036997024435549974 | train acc 0.9085714221000671
step: 620 | train loss: 0.004290128126740456 | train acc 0.8787878751754761
step: 630 | train loss: 0.004889876116067171 | train acc 0.8828828930854797
step: 630 | train loss: 0.0038123137783259153 | train acc 0.824999988079071
step: 640 | train loss: 0.0058488426730036736 | train acc 0.8627451062202454
step: 640 | train loss: 0.0051571219228208065 | train acc 0.8666667342185974
step: 650 | train loss: 0.0058703795075416565 | train acc 0.8658536672592163
step: 650 | train loss: 0.0046280547976493835 | train acc 0.8918918967247009
step: 660 | train loss: 0.004616430960595608 | train acc 0.8925501704216003
step: 660 | train loss: 0.0040649608708918095 | train acc 0.9189189672470093
step: 670 | train loss: 0.005775097757577896 | train acc 0.8684582710266113
step: 670 | train loss: 0.001896746689453721 | train acc 0.9696969985961914
step: 680 | train loss: 0.0051164450123906136 | train acc 0.8799999952316284
step: 680 | train loss: 0.004777694586664438 | train acc 0.9000000357627869
step: 690 | train loss: 0.004467075224965811 | train acc 0.898426353931427
step: 690 | train loss: 0.0038062867242842913 | train acc 0.9473684430122375
step: 700 | train loss: 0.004708496388047934 | train acc 0.8802395462989807
step: 700 | train loss: 0.006431611720472574 | train acc 0.8857142925262451
step: 710 | train loss: 0.006065857131034136 | train acc 0.9026217460632324
step: 710 | train loss: 0.005243745166808367 | train acc 0.8571428656578064
step: 720 | train loss: 0.0050062136724591255 | train acc 0.8755426406860352
step: 720 | train loss: 0.0034485128708183765 | train acc 0.8888888955116272
step: 730 | train loss: 0.004800766706466675 | train acc 0.8802309036254883
step: 730 | train loss: 0.009153177961707115 | train acc 0.8000000715255737
step: 740 | train loss: 0.0051066139712929726 | train acc 0.8850072622299194
step: 740 | train loss: 0.0029207810293883085 | train acc 0.9090909361839294
step: 750 | train loss: 0.004328940063714981 | train acc 0.875
step: 750 | train loss: 0.002957735676318407 | train acc 0.9230769276618958
step: 760 | train loss: 0.004882167559117079 | train acc 0.8902778029441833
step: 760 | train loss: 0.003928267862647772 | train acc 0.8823529481887817
step: 770 | train loss: 0.006502356845885515 | train acc 0.8602693676948547
step: 770 | train loss: 0.0023699814919382334 | train acc 0.9736841917037964
step: 780 | train loss: 0.008469942025840282 | train acc 0.8566827774047852
step: 780 | train loss: 0.003601411357522011 | train acc 0.8717948794364929
step: 790 | train loss: 0.005342515185475349 | train acc 0.8766140937805176
step: 790 | train loss: 0.0025560541544109583 | train acc 0.8947368264198303
step: 800 | train loss: 0.004526425618678331 | train acc 0.8978723287582397
step: 800 | train loss: 0.00586403114721179 | train acc 0.875
step: 810 | train loss: 0.0056130844168365 | train acc 0.8669528365135193
step: 810 | train loss: 0.004166290629655123 | train acc 0.8461538553237915
step: 820 | train loss: 0.003977673593908548 | train acc 0.9103840589523315
step: 820 | train loss: 0.008405701257288456 | train acc 0.7631579041481018
step: 830 | train loss: 0.004298336338251829 | train acc 0.9059701561927795
step: 830 | train loss: 0.01271191705018282 | train acc 0.8000000715255737
step: 840 | train loss: 0.008639572188258171 | train acc 0.8661971688270569
step: 840 | train loss: 0.002902223262935877 | train acc 0.9230769276618958
step: 850 | train loss: 0.004030467011034489 | train acc 0.906647801399231
step: 850 | train loss: 0.003957896027714014 | train acc 0.8611111044883728
step: 860 | train loss: 0.00370783731341362 | train acc 0.9141631126403809
step: 860 | train loss: 0.0039914678782224655 | train acc 0.8857142925262451
step: 870 | train loss: 0.0032503872644156218 | train acc 0.9298245906829834
step: 870 | train loss: 0.0134560726583004 | train acc 0.90625
step: 880 | train loss: 0.005433006677776575 | train acc 0.8972100019454956
step: 880 | train loss: 0.003965854644775391 | train acc 0.9000000357627869
step: 890 | train loss: 0.005379539914429188 | train acc 0.8836879134178162
step: 890 | train loss: 0.0018645721720531583 | train acc 0.9473684430122375
step: 900 | train loss: 0.007092840503901243 | train acc 0.8513931632041931
step: 900 | train loss: 0.0059434399008750916 | train acc 0.8333333730697632
step: 910 | train loss: 0.004652645904570818 | train acc 0.8913963437080383
step: 910 | train loss: 0.0049148485995829105 | train acc 0.8974359035491943
step: 920 | train loss: 0.006695284508168697 | train acc 0.8958333730697632
step: 920 | train loss: 0.0037898379378020763 | train acc 0.9333333969116211
step: 930 | train loss: 0.0032672181259840727 | train acc 0.9418604373931885
step: 930 | train loss: 0.0015301204985007644 | train acc 0.9743589758872986
step: 940 | train loss: 0.0024318911600857973 | train acc 0.9544159770011902
step: 940 | train loss: 0.004172519315034151 | train acc 0.8974359035491943
step: 950 | train loss: 0.0020912503823637962 | train acc 0.9597122073173523
step: 950 | train loss: 0.0026349143590778112 | train acc 0.925000011920929
step: 960 | train loss: 0.002050779527053237 | train acc 0.9516358375549316
step: 960 | train loss: 0.0020961640402674675 | train acc 0.9473684430122375
step: 970 | train loss: 0.0024300243239849806 | train acc 0.9506531357765198
step: 970 | train loss: 0.0002296446036780253 | train acc 1.0
step: 980 | train loss: 0.0017993093933910131 | train acc 0.969924807548523
step: 980 | train loss: 0.0012064074398949742 | train acc 1.0
step: 990 | train loss: 0.0024698409251868725 | train acc 0.9581939578056335
step: 990 | train loss: 0.007426196243613958 | train acc 0.9210526347160339
step: 1000 | train loss: 0.002115050330758095 | train acc 0.9627507328987122
step: 1000 | train loss: 0.0013171205064281821 | train acc 0.9666666984558105
step: 1010 | train loss: 0.002277974272146821 | train acc 0.9456366300582886
step: 1010 | train loss: 0.0026903687976300716 | train acc 0.8684210777282715
step: 1020 | train loss: 0.0026335727889090776 | train acc 0.95924311876297
step: 1020 | train loss: 0.0027587676886469126 | train acc 0.9090909361839294
step: 1030 | train loss: 0.005600195378065109 | train acc 0.9059701561927795
step: 1030 | train loss: 0.0013565538683906198 | train acc 0.9736841917037964
step: 1040 | train loss: 0.003297788091003895 | train acc 0.9363905191421509
step: 1040 | train loss: 0.0009310355526395142 | train acc 0.9696969985961914
step: 1050 | train loss: 0.0023443796671926975 | train acc 0.9497400522232056
step: 1050 | train loss: 0.0015781382098793983 | train acc 0.9166666865348816
step: 1060 | train loss: 0.0025026395451277494 | train acc 0.9533528089523315
step: 1060 | train loss: 0.0006555072613991797 | train acc 1.0
step: 1070 | train loss: 0.0026365979574620724 | train acc 0.9497041702270508
step: 1070 | train loss: 0.0011943252757191658 | train acc 0.9736841917037964
step: 1080 | train loss: 0.0033175679855048656 | train acc 0.9391796588897705
step: 1080 | train loss: 0.0013028300600126386 | train acc 0.9729729890823364
step: 1090 | train loss: 0.0015787737211212516 | train acc 0.9601706862449646
step: 1090 | train loss: 0.005913999862968922 | train acc 0.824999988079071
step: 1100 | train loss: 0.0034962412901222706 | train acc 0.931034505367279
step: 1100 | train loss: 0.0003376186650712043 | train acc 1.0
step: 1110 | train loss: 0.004117059987038374 | train acc 0.9211746454238892
step: 1110 | train loss: 0.001021419302560389 | train acc 1.0
step: 1120 | train loss: 0.003218534868210554 | train acc 0.9417177438735962
step: 1120 | train loss: 0.0026603746227920055 | train acc 0.9189189672470093
step: 1130 | train loss: 0.0038782451301813126 | train acc 0.9331395030021667
step: 1130 | train loss: 0.0011786473914980888 | train acc 0.9487179517745972
step: 1140 | train loss: 0.0022609010338783264 | train acc 0.958823561668396
step: 1140 | train loss: 0.0009183096117340028 | train acc 0.9722222089767456
step: 1150 | train loss: 0.0017838916974142194 | train acc 0.9605078101158142
step: 1150 | train loss: 0.0006536030559800565 | train acc 0.9722222089767456
step: 1160 | train loss: 0.0029426824767142534 | train acc 0.9529244303703308
step: 1160 | train loss: 0.0018389446195214987 | train acc 0.9142857193946838
step: 1170 | train loss: 0.0020441312808543444 | train acc 0.9527897238731384
step: 1170 | train loss: 0.003941769246011972 | train acc 0.9333333969116211
step: 1180 | train loss: 0.00507698580622673 | train acc 0.920810341835022
step: 1180 | train loss: 0.004163240548223257 | train acc 0.9210526347160339
step: 1190 | train loss: 0.0014043661067262292 | train acc 0.9712643623352051
step: 1190 | train loss: 0.0002223289484390989 | train acc 1.0
step: 1200 | train loss: 0.0021759970113635063 | train acc 0.9586894512176514
step: 1200 | train loss: 0.00042493437649682164 | train acc 1.0
step: 1210 | train loss: 0.0017620256403461099 | train acc 0.9740259647369385
step: 1210 | train loss: 0.001195469405502081 | train acc 0.9743589758872986
step: 1220 | train loss: 0.001729615731164813 | train acc 0.9673590660095215
step: 1220 | train loss: 0.0010016749147325754 | train acc 1.0
step: 1230 | train loss: 0.0016277895774692297 | train acc 0.9645293354988098
step: 1230 | train loss: 0.0010349059011787176 | train acc 1.0
step: 1240 | train loss: 0.0022956812754273415 | train acc 0.9416282773017883
step: 1240 | train loss: 0.0006436817348003387 | train acc 1.0
step: 1250 | train loss: 0.0021759262308478355 | train acc 0.9604430794715881
step: 1250 | train loss: 0.0008728649117983878 | train acc 0.9729729890823364
step: 1260 | train loss: 0.0017704698257148266 | train acc 0.9598278403282166
step: 1260 | train loss: 0.002246295567601919 | train acc 0.9000000357627869
step: 1270 | train loss: 0.002656482858583331 | train acc 0.9428152441978455
step: 1270 | train loss: 0.0030135747510939837 | train acc 0.9714285731315613
step: 1280 | train loss: 0.001448685536161065 | train acc 0.9710564017295837
step: 1280 | train loss: 0.004881484434008598 | train acc 0.9032257795333862
step: 1290 | train loss: 0.0014182792510837317 | train acc 0.9619883298873901
step: 1290 | train loss: 0.00102319847792387 | train acc 1.0
step: 1300 | train loss: 0.0034874938428401947 | train acc 0.93098384141922
step: 1300 | train loss: 0.003951528109610081 | train acc 0.9199999570846558
step: 1310 | train loss: 0.004322105553001165 | train acc 0.9398373961448669
step: 1310 | train loss: 0.003019292140379548 | train acc 0.9142857193946838
step: 1320 | train loss: 0.001250473433174193 | train acc 0.973314642906189
step: 1320 | train loss: 0.0005718038300983608 | train acc 1.0
step: 1330 | train loss: 0.002349892631173134 | train acc 0.9475219249725342
step: 1330 | train loss: 0.0005776442703790963 | train acc 0.9722222089767456
step: 1340 | train loss: 0.003731637028977275 | train acc 0.9340028762817383
step: 1340 | train loss: 0.0012097281869500875 | train acc 0.9736841917037964
step: 1350 | train loss: 0.0018018950941041112 | train acc 0.9590973258018494
step: 1350 | train loss: 0.0007535383338108659 | train acc 0.9750000238418579
step: 1360 | train loss: 0.0016293482622131705 | train acc 0.9727011322975159
step: 1360 | train loss: 0.0011229545343667269 | train acc 0.9428571462631226
step: 1370 | train loss: 0.0020444237161427736 | train acc 0.9648240804672241
step: 1370 | train loss: 0.0005272988346405327 | train acc 0.9722222089767456
step: 1380 | train loss: 0.0025835148990154266 | train acc 0.9514285326004028
step: 1380 | train loss: 0.00029219535645097494 | train acc 1.0
step: 1390 | train loss: 0.0018722160020843148 | train acc 0.9717114567756653
step: 1390 | train loss: 0.0008469873573631048 | train acc 1.0
step: 1400 | train loss: 0.0030216409359127283 | train acc 0.9358060359954834
step: 1400 | train loss: 0.0007606223807670176 | train acc 0.9487179517745972
step: 1410 | train loss: 0.0026422732044011354 | train acc 0.9457579851150513
step: 1410 | train loss: 0.002289809053763747 | train acc 0.9333333969116211
step: 1420 | train loss: 0.0022524537052959204 | train acc 0.9483775496482849
step: 1420 | train loss: 0.00045805677655152977 | train acc 1.0
step: 1430 | train loss: 0.0023452516179531813 | train acc 0.9365558624267578
step: 1430 | train loss: 0.0006878110580146313 | train acc 0.9729729890823364
step: 1440 | train loss: 0.004675596486777067 | train acc 0.9382352828979492
step: 1440 | train loss: 0.0010383152402937412 | train acc 0.9473684430122375
step: 1450 | train loss: 0.0033266833052039146 | train acc 0.9334319829940796
step: 1450 | train loss: 0.00027784440317191184 | train acc 1.0
step: 1460 | train loss: 0.003487661713734269 | train acc 0.9347826242446899
step: 1460 | train loss: 0.0004910383140668273 | train acc 1.0
step: 1470 | train loss: 0.002173498272895813 | train acc 0.9487534165382385
step: 1470 | train loss: 0.0022163635585457087 | train acc 0.949999988079071
step: 1480 | train loss: 0.0019099934725090861 | train acc 0.9661495089530945
step: 1480 | train loss: 0.000727239646948874 | train acc 0.9743589758872986
step: 1490 | train loss: 0.00319106737151742 | train acc 0.927142858505249
step: 1490 | train loss: 0.0005740816704928875 | train acc 1.0
step: 1500 | train loss: 0.002122806152328849 | train acc 0.9520547986030579
step: 1500 | train loss: 0.0009690335718914866 | train acc 0.9722222089767456
step: 1510 | train loss: 0.00178171182051301 | train acc 0.9619182348251343
step: 1510 | train loss: 0.0006672015297226608 | train acc 1.0
step: 1520 | train loss: 0.002095234114676714 | train acc 0.952654242515564
step: 1520 | train loss: 0.00328191090375185 | train acc 0.9393939971923828
step: 1530 | train loss: 0.0020333435386419296 | train acc 0.9481267929077148
step: 1530 | train loss: 0.0009865880711004138 | train acc 0.9705882668495178
step: 1540 | train loss: 0.0015082170721143484 | train acc 0.9651669263839722
step: 1540 | train loss: 0.0011626549530774355 | train acc 0.9487179517745972
step: 1550 | train loss: 0.002378239529207349 | train acc 0.9443652033805847
step: 1550 | train loss: 0.00473651010543108 | train acc 0.9393939971923828
step: 1560 | train loss: 0.0036004167050123215 | train acc 0.9297012686729431
step: 1560 | train loss: 0.0004459044139366597 | train acc 1.0
step: 1570 | train loss: 0.0038796374574303627 | train acc 0.9419263601303101
step: 1570 | train loss: 0.0003982725029345602 | train acc 1.0
step: 1580 | train loss: 0.0009514482226222754 | train acc 0.977011501789093
step: 1580 | train loss: 0.0028534859884530306 | train acc 0.9743589758872986
step: 1590 | train loss: 0.0020867222920060158 | train acc 0.9556213021278381
step: 1590 | train loss: 0.005322711542248726 | train acc 0.925000011920929
step: 1600 | train loss: 0.001582203316502273 | train acc 0.961262583732605
step: 1600 | train loss: 0.0047609079629182816 | train acc 0.925000011920929
step: 1610 | train loss: 0.0014807804254814982 | train acc 0.9743589758872986
step: 1610 | train loss: 0.001158672384917736 | train acc 0.9729729890823364
step: 1620 | train loss: 0.0018115275306627154 | train acc 0.9641790986061096
step: 1620 | train loss: 0.008494801819324493 | train acc 0.9000000357627869
step: 1630 | train loss: 0.0015780625399202108 | train acc 0.9646017551422119
step: 1630 | train loss: 0.00046393743832595646 | train acc 1.0
step: 1640 | train loss: 0.0017429412109777331 | train acc 0.9681620597839355
step: 1640 | train loss: 0.0005219326121732593 | train acc 0.9743589758872986
step: 1650 | train loss: 0.001683336216956377 | train acc 0.9598337411880493
step: 1650 | train loss: 0.0010273050284013152 | train acc 0.9722222089767456
step: 1660 | train loss: 0.0013303108280524611 | train acc 0.9700854420661926
step: 1660 | train loss: 0.0005215234123170376 | train acc 1.0
step: 1670 | train loss: 0.0017909921007230878 | train acc 0.9591549038887024
step: 1670 | train loss: 0.0013138925423845649 | train acc 0.949999988079071
step: 1680 | train loss: 0.00197217077948153 | train acc 0.953987717628479
step: 1680 | train loss: 0.012062017805874348 | train acc 0.7931034564971924
step: 1690 | train loss: 0.0072517236694693565 | train acc 0.92323237657547
step: 1690 | train loss: 0.000170721992617473 | train acc 1.0
step: 1700 | train loss: 0.0032500464003533125 | train acc 0.9410029649734497
step: 1700 | train loss: 0.0013363235630095005 | train acc 0.9705882668495178
step: 1710 | train loss: 0.001704643713310361 | train acc 0.9642346501350403
step: 1710 | train loss: 0.0011566615430638194 | train acc 0.9750000238418579
step: 1720 | train loss: 0.003466429188847542 | train acc 0.9332365989685059
step: 1720 | train loss: 0.000984866521321237 | train acc 0.9705882668495178
step: 1730 | train loss: 0.0026653490494936705 | train acc 0.9542097449302673
step: 1730 | train loss: 0.002279632957652211 | train acc 0.925000011920929
step: 1740 | train loss: 0.006122970953583717 | train acc 0.9055232405662537
step: 1740 | train loss: 0.0007517577614635229 | train acc 1.0
step: 1750 | train loss: 0.0030067304614931345 | train acc 0.9346405267715454
step: 1750 | train loss: 0.0002972452202811837 | train acc 1.0
step: 1760 | train loss: 0.0026063756085932255 | train acc 0.9505988359451294
step: 1760 | train loss: 0.00033105770125985146 | train acc 1.0
step: 1770 | train loss: 0.0028591288719326258 | train acc 0.9324712753295898
step: 1770 | train loss: 0.004560496192425489 | train acc 0.9743589758872986
step: 1780 | train loss: 0.003727542469277978 | train acc 0.9404255151748657
step: 1780 | train loss: 0.0008361481013707817 | train acc 0.9729729890823364
step: 1790 | train loss: 0.002732650376856327 | train acc 0.9529914259910583
step: 1790 | train loss: 0.0010808390798047185 | train acc 0.9750000238418579
step: 1800 | train loss: 0.003369223792105913 | train acc 0.9373219609260559
step: 1800 | train loss: 0.00031418108846992254 | train acc 1.0
step: 1810 | train loss: 0.0028874764684587717 | train acc 0.9514706134796143
step: 1810 | train loss: 0.00037029871600680053 | train acc 1.0
step: 1820 | train loss: 0.003559680888429284 | train acc 0.9340835809707642
step: 1820 | train loss: 0.001032244530506432 | train acc 0.9736841917037964
step: 1830 | train loss: 0.001985555049031973 | train acc 0.9647886753082275
step: 1830 | train loss: 0.0005712690181098878 | train acc 1.0
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1834
  valid_eval_accuracy = 0.8918953577840472
  valid_eval_loss = 0.38219008285481976
