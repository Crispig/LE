device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1781
step: 10 | train loss: 0.022617630660533905 | train acc 0.44463086128234863
step: 10 | train loss: 0.016228409484028816 | train acc 0.5428571701049805
step: 20 | train loss: 0.011625166982412338 | train acc 0.6772333979606628
step: 20 | train loss: 0.007296762894839048 | train acc 0.800000011920929
step: 30 | train loss: 0.008756807073950768 | train acc 0.7773049473762512
step: 30 | train loss: 0.005362014751881361 | train acc 0.9142857193946838
step: 40 | train loss: 0.009161456488072872 | train acc 0.7920227646827698
step: 40 | train loss: 0.008403957821428776 | train acc 0.75
step: 50 | train loss: 0.009850891306996346 | train acc 0.7890961170196533
step: 50 | train loss: 0.0120806023478508 | train acc 0.6500000357627869
step: 60 | train loss: 0.0078087663277983665 | train acc 0.7732962369918823
step: 60 | train loss: 0.008514352142810822 | train acc 0.699999988079071
step: 70 | train loss: 0.009049961343407631 | train acc 0.8109452724456787
step: 70 | train loss: 0.0038064687978476286 | train acc 0.8857142925262451
step: 80 | train loss: 0.007121930830180645 | train acc 0.7929577231407166
step: 80 | train loss: 0.00839943252503872 | train acc 0.7272727489471436
step: 90 | train loss: 0.008414052426815033 | train acc 0.8304093480110168
step: 90 | train loss: 0.012529698200523853 | train acc 0.7837837934494019
step: 100 | train loss: 0.006635933183133602 | train acc 0.8252149224281311
step: 100 | train loss: 0.004014934878796339 | train acc 0.875
step: 110 | train loss: 0.0057014403864741325 | train acc 0.8526912331581116
step: 110 | train loss: 0.005561008118093014 | train acc 0.8684210777282715
step: 120 | train loss: 0.0061667123809456825 | train acc 0.8392602801322937
step: 120 | train loss: 0.008646372705698013 | train acc 0.7948718070983887
step: 130 | train loss: 0.009603871032595634 | train acc 0.7730263471603394
step: 130 | train loss: 0.009099593386054039 | train acc 0.8571428656578064
step: 140 | train loss: 0.009788519702851772 | train acc 0.8166143894195557
step: 140 | train loss: 0.007306351326406002 | train acc 0.7631579041481018
step: 150 | train loss: 0.00655114883556962 | train acc 0.8347578048706055
step: 150 | train loss: 0.0054501136764883995 | train acc 0.8648648858070374
step: 160 | train loss: 0.0060903336852788925 | train acc 0.8328651785850525
step: 160 | train loss: 0.005854699295014143 | train acc 0.8709677457809448
step: 170 | train loss: 0.007437757216393948 | train acc 0.8173913359642029
step: 170 | train loss: 0.0064591155387461185 | train acc 0.7894737124443054
step: 180 | train loss: 0.007217798847705126 | train acc 0.8299418687820435
step: 180 | train loss: 0.0076598781161010265 | train acc 0.7428571581840515
step: 190 | train loss: 0.007034737151116133 | train acc 0.8150289058685303
step: 190 | train loss: 0.006584580987691879 | train acc 0.8333333730697632
step: 200 | train loss: 0.00803690031170845 | train acc 0.8421052694320679
step: 200 | train loss: 0.004534807521849871 | train acc 0.8918918967247009
step: 210 | train loss: 0.006130158435553312 | train acc 0.8508123755455017
step: 210 | train loss: 0.005468970630317926 | train acc 0.9000000357627869
step: 220 | train loss: 0.005909188650548458 | train acc 0.8530259132385254
step: 220 | train loss: 0.006647641770541668 | train acc 0.7948718070983887
step: 230 | train loss: 0.00683730561286211 | train acc 0.7988747954368591
step: 230 | train loss: 0.008731627836823463 | train acc 0.7179487347602844
step: 240 | train loss: 0.006576926913112402 | train acc 0.8326055407524109
step: 240 | train loss: 0.00434519350528717 | train acc 0.925000011920929
step: 250 | train loss: 0.004937145859003067 | train acc 0.8799999952316284
step: 250 | train loss: 0.011132798157632351 | train acc 0.8181818723678589
step: 260 | train loss: 0.008090347051620483 | train acc 0.8174061179161072
step: 260 | train loss: 0.00991399958729744 | train acc 0.7666667103767395
step: 270 | train loss: 0.004697961732745171 | train acc 0.8952802419662476
step: 270 | train loss: 0.005503357388079166 | train acc 0.8529411554336548
step: 280 | train loss: 0.004345031455159187 | train acc 0.8917748928070068
step: 280 | train loss: 0.003295566188171506 | train acc 0.8378378748893738
step: 290 | train loss: 0.006504433695226908 | train acc 0.8420290350914001
step: 290 | train loss: 0.00404158141463995 | train acc 0.84375
step: 300 | train loss: 0.005426184739917517 | train acc 0.8617771863937378
step: 300 | train loss: 0.006306881085038185 | train acc 0.8648648858070374
step: 310 | train loss: 0.00772002711892128 | train acc 0.8487518429756165
step: 310 | train loss: 0.013809447176754475 | train acc 0.7750000357627869
step: 320 | train loss: 0.007912904024124146 | train acc 0.8251851797103882
step: 320 | train loss: 0.014720253646373749 | train acc 0.7000000476837158
step: 330 | train loss: 0.005639435723423958 | train acc 0.8771043419837952
step: 330 | train loss: 0.003007743740454316 | train acc 0.8918918967247009
step: 340 | train loss: 0.00592709518969059 | train acc 0.8788321018218994
step: 340 | train loss: 0.004484825301915407 | train acc 0.9189189672470093
step: 350 | train loss: 0.00459787342697382 | train acc 0.8895265460014343
step: 350 | train loss: 0.00317462463863194 | train acc 0.9210526347160339
step: 360 | train loss: 0.005184028763324022 | train acc 0.8809869289398193
step: 360 | train loss: 0.0026927203871309757 | train acc 0.9333333969116211
step: 370 | train loss: 0.004044104367494583 | train acc 0.8936781287193298
step: 370 | train loss: 0.007446389179676771 | train acc 0.824999988079071
step: 380 | train loss: 0.004522985778748989 | train acc 0.8971014618873596
step: 380 | train loss: 0.008943031542003155 | train acc 0.7567567825317383
step: 390 | train loss: 0.0051400684751570225 | train acc 0.8861788511276245
step: 390 | train loss: 0.004374663811177015 | train acc 0.8974359035491943
step: 400 | train loss: 0.005003736820071936 | train acc 0.8859649300575256
step: 400 | train loss: 0.005126671399921179 | train acc 0.8888888955116272
step: 410 | train loss: 0.004861466586589813 | train acc 0.8826895952224731
step: 410 | train loss: 0.007366160862147808 | train acc 0.8157894611358643
step: 420 | train loss: 0.0031952504068613052 | train acc 0.9254570603370667
step: 420 | train loss: 0.001154993660748005 | train acc 1.0
step: 430 | train loss: 0.004515392705798149 | train acc 0.8890449404716492
step: 430 | train loss: 0.001881084288470447 | train acc 0.9166666865348816
step: 440 | train loss: 0.006221800576895475 | train acc 0.875881552696228
step: 440 | train loss: 0.002761285984888673 | train acc 0.949999988079071
step: 450 | train loss: 0.0055616856552660465 | train acc 0.8632619380950928
step: 450 | train loss: 0.002056913450360298 | train acc 0.9523809552192688
step: 460 | train loss: 0.006063425913453102 | train acc 0.8734567761421204
step: 460 | train loss: 0.0012327427975833416 | train acc 1.0
step: 470 | train loss: 0.004477567970752716 | train acc 0.883357048034668
step: 470 | train loss: 0.003547045635059476 | train acc 0.9000000357627869
step: 480 | train loss: 0.006872591096907854 | train acc 0.8465909361839294
step: 480 | train loss: 0.002741016447544098 | train acc 0.9375
step: 490 | train loss: 0.004352353047579527 | train acc 0.9063400030136108
step: 490 | train loss: 0.00456776050850749 | train acc 0.9000000357627869
step: 500 | train loss: 0.0038928170688450336 | train acc 0.9098837375640869
step: 500 | train loss: 0.014143644832074642 | train acc 0.7750000357627869
step: 510 | train loss: 0.005246833432465792 | train acc 0.8665667176246643
step: 510 | train loss: 0.005515240132808685 | train acc 0.9000000357627869
step: 520 | train loss: 0.009139902889728546 | train acc 0.8644688725471497
step: 520 | train loss: 0.004626121837645769 | train acc 0.8717948794364929
step: 530 | train loss: 0.005565132945775986 | train acc 0.8616714477539062
step: 530 | train loss: 0.0018766558496281505 | train acc 0.9428571462631226
step: 540 | train loss: 0.005213274620473385 | train acc 0.8906474709510803
step: 540 | train loss: 0.003926617093384266 | train acc 0.8947368264198303
step: 550 | train loss: 0.0033262050710618496 | train acc 0.9107913374900818
step: 550 | train loss: 0.012976109981536865 | train acc 0.8205128312110901
step: 560 | train loss: 0.004078973084688187 | train acc 0.8897058963775635
step: 560 | train loss: 0.0015781874535605311 | train acc 0.9705882668495178
step: 570 | train loss: 0.004248394165188074 | train acc 0.8915835022926331
step: 570 | train loss: 0.005027253180742264 | train acc 0.8611111044883728
step: 580 | train loss: 0.005567684303969145 | train acc 0.8991150259971619
step: 580 | train loss: 0.001595574663951993 | train acc 0.9743589758872986
step: 590 | train loss: 0.004174921195954084 | train acc 0.8943559527397156
step: 590 | train loss: 0.005854560527950525 | train acc 0.8055555820465088
step: 600 | train loss: 0.007059196475893259 | train acc 0.8672438859939575
step: 600 | train loss: 0.006345157977193594 | train acc 0.8285714387893677
step: 610 | train loss: 0.004699258599430323 | train acc 0.8835227489471436
step: 610 | train loss: 0.0023793689906597137 | train acc 0.9142857193946838
step: 620 | train loss: 0.004486049525439739 | train acc 0.8847262263298035
step: 620 | train loss: 0.0013750891666859388 | train acc 0.9666666984558105
step: 630 | train loss: 0.004760819021612406 | train acc 0.8947368264198303
step: 630 | train loss: 0.006208487786352634 | train acc 0.8500000238418579
step: 640 | train loss: 0.0044676437973976135 | train acc 0.890260636806488
step: 640 | train loss: 0.00911670457571745 | train acc 0.800000011920929
step: 650 | train loss: 0.0061187525279819965 | train acc 0.8875839114189148
step: 650 | train loss: 0.004053608514368534 | train acc 0.875
step: 660 | train loss: 0.008053427562117577 | train acc 0.8459302186965942
step: 660 | train loss: 0.001817328971810639 | train acc 0.9487179517745972
step: 670 | train loss: 0.0057592848315835 | train acc 0.8801711797714233
step: 670 | train loss: 0.0037136028986424208 | train acc 0.9000000357627869
step: 680 | train loss: 0.005269025918096304 | train acc 0.8922609686851501
step: 680 | train loss: 0.005300051067024469 | train acc 0.9000000357627869
step: 690 | train loss: 0.005225234664976597 | train acc 0.8916184902191162
step: 690 | train loss: 0.006377983372658491 | train acc 0.800000011920929
step: 700 | train loss: 0.004880020394921303 | train acc 0.8831360936164856
step: 700 | train loss: 0.0020378378685563803 | train acc 0.9142857193946838
step: 710 | train loss: 0.00508173368871212 | train acc 0.8925476670265198
step: 710 | train loss: 0.006847850978374481 | train acc 0.8461538553237915
step: 720 | train loss: 0.00424602348357439 | train acc 0.9080459475517273
step: 720 | train loss: 0.0027296775951981544 | train acc 0.8974359035491943
step: 730 | train loss: 0.003443887224420905 | train acc 0.9063829779624939
step: 730 | train loss: 0.0018676379695534706 | train acc 0.9487179517745972
step: 740 | train loss: 0.005306075792759657 | train acc 0.900288999080658
step: 740 | train loss: 0.002165736397728324 | train acc 0.925000011920929
step: 750 | train loss: 0.0053380755707621574 | train acc 0.8863309025764465
step: 750 | train loss: 0.028420686721801758 | train acc 0.5675675868988037
step: 760 | train loss: 0.0037350100465118885 | train acc 0.9124820828437805
step: 760 | train loss: 0.003425381612032652 | train acc 0.8947368264198303
step: 770 | train loss: 0.0065022241324186325 | train acc 0.8464977741241455
step: 770 | train loss: 0.010437901131808758 | train acc 0.8571428656578064
step: 780 | train loss: 0.0033722929656505585 | train acc 0.9219653010368347
step: 780 | train loss: 0.003484406042844057 | train acc 0.9142857193946838
step: 790 | train loss: 0.003883662633597851 | train acc 0.9009901285171509
step: 790 | train loss: 0.0032441793009638786 | train acc 0.9090909361839294
step: 800 | train loss: 0.004260759800672531 | train acc 0.9055794477462769
step: 800 | train loss: 0.0028234990313649178 | train acc 0.9230769276618958
step: 810 | train loss: 0.004338701721280813 | train acc 0.8969520926475525
step: 810 | train loss: 0.0024019181728363037 | train acc 0.9487179517745972
step: 820 | train loss: 0.0046474202536046505 | train acc 0.9007298946380615
step: 820 | train loss: 0.0065650176256895065 | train acc 0.8684210777282715
step: 830 | train loss: 0.0043041338212788105 | train acc 0.898975133895874
step: 830 | train loss: 0.009719367139041424 | train acc 0.824999988079071
step: 840 | train loss: 0.007631847634911537 | train acc 0.9111841917037964
step: 840 | train loss: 0.003353892592713237 | train acc 0.8717948794364929
step: 850 | train loss: 0.0055831680074334145 | train acc 0.8898426294326782
step: 850 | train loss: 0.005560173187404871 | train acc 0.8857142925262451
step: 860 | train loss: 0.004692694637924433 | train acc 0.9033675193786621
step: 860 | train loss: 0.0011152380611747503 | train acc 1.0
step: 870 | train loss: 0.0031445659697055817 | train acc 0.926086962223053
step: 870 | train loss: 0.0025458908639848232 | train acc 0.9459459781646729
step: 880 | train loss: 0.0047758799046278 | train acc 0.8999999761581421
step: 880 | train loss: 0.009034084156155586 | train acc 0.7142857313156128
step: 890 | train loss: 0.004352287854999304 | train acc 0.8967551589012146
step: 890 | train loss: 0.006122299004346132 | train acc 0.8666667342185974
step: 900 | train loss: 0.0036631959956139326 | train acc 0.9411765336990356
step: 900 | train loss: 0.0007682751165702939 | train acc 1.0
step: 910 | train loss: 0.0032769027166068554 | train acc 0.9456366300582886
step: 910 | train loss: 0.001912959385663271 | train acc 0.9459459781646729
step: 920 | train loss: 0.0030370543245226145 | train acc 0.9420903921127319
step: 920 | train loss: 0.0005394727922976017 | train acc 1.0
step: 930 | train loss: 0.0026000686921179295 | train acc 0.9475219249725342
step: 930 | train loss: 0.0018298056675121188 | train acc 0.949999988079071
step: 940 | train loss: 0.0030435235239565372 | train acc 0.9457142949104309
step: 940 | train loss: 0.0029383895453065634 | train acc 0.9459459781646729
step: 950 | train loss: 0.002031076466664672 | train acc 0.9579710364341736
step: 950 | train loss: 0.0020197953563183546 | train acc 0.949999988079071
step: 960 | train loss: 0.0022201717365533113 | train acc 0.9583999514579773
step: 960 | train loss: 0.004840590059757233 | train acc 0.8571428656578064
step: 970 | train loss: 0.0032556026708334684 | train acc 0.9388646483421326
step: 970 | train loss: 0.0017177078407257795 | train acc 0.9696969985961914
step: 980 | train loss: 0.003960147965699434 | train acc 0.938144326210022
step: 980 | train loss: 0.0002286981325596571 | train acc 1.0
step: 990 | train loss: 0.0016894944710657 | train acc 0.9731638431549072
step: 990 | train loss: 0.0014755605952814221 | train acc 0.9705882668495178
step: 1000 | train loss: 0.0019119824282824993 | train acc 0.9680556058883667
step: 1000 | train loss: 0.0013946936232969165 | train acc 0.9750000238418579
step: 1010 | train loss: 0.0039389911107718945 | train acc 0.9318841099739075
step: 1010 | train loss: 0.002233937382698059 | train acc 0.9750000238418579
step: 1020 | train loss: 0.003735512960702181 | train acc 0.9331259727478027
step: 1020 | train loss: 0.00111673295032233 | train acc 0.9696969985961914
step: 1030 | train loss: 0.003910006955265999 | train acc 0.9321766495704651
step: 1030 | train loss: 0.0019758606795221567 | train acc 0.9714285731315613
step: 1040 | train loss: 0.003446676069870591 | train acc 0.9395217895507812
step: 1040 | train loss: 0.0033848874736577272 | train acc 0.9166666865348816
step: 1050 | train loss: 0.002507711760699749 | train acc 0.946915328502655
step: 1050 | train loss: 0.0027064511086791754 | train acc 0.9411764740943909
step: 1060 | train loss: 0.0013586890418082476 | train acc 0.964488685131073
step: 1060 | train loss: 0.0030121770687401295 | train acc 0.9459459781646729
step: 1070 | train loss: 0.0011431836755946279 | train acc 0.9780701994895935
step: 1070 | train loss: 0.003226781263947487 | train acc 0.9736841917037964
step: 1080 | train loss: 0.002499741967767477 | train acc 0.9516128897666931
step: 1080 | train loss: 0.0032680362928658724 | train acc 0.9642857313156128
step: 1090 | train loss: 0.0019319900311529636 | train acc 0.9567307829856873
step: 1090 | train loss: 0.0013136694906279445 | train acc 0.9714285731315613
step: 1100 | train loss: 0.0020722660701721907 | train acc 0.9487179517745972
step: 1100 | train loss: 0.0008713345159776509 | train acc 0.9714285731315613
step: 1110 | train loss: 0.0034348396584391594 | train acc 0.9441261291503906
step: 1110 | train loss: 0.0017492403276264668 | train acc 0.9729729890823364
step: 1120 | train loss: 0.0027397186495363712 | train acc 0.944847583770752
step: 1120 | train loss: 0.0023711256217211485 | train acc 0.9729729890823364
step: 1130 | train loss: 0.0021707017440348864 | train acc 0.9533528089523315
step: 1130 | train loss: 0.0010616052895784378 | train acc 0.9705882668495178
step: 1140 | train loss: 0.002883424051105976 | train acc 0.9527220726013184
step: 1140 | train loss: 0.0012777644442394376 | train acc 0.9666666984558105
step: 1150 | train loss: 0.0054963985458016396 | train acc 0.9444444179534912
step: 1150 | train loss: 0.0009934421395882964 | train acc 0.9729729890823364
step: 1160 | train loss: 0.002295080106705427 | train acc 0.9535558819770813
step: 1160 | train loss: 0.00018128570809494704 | train acc 1.0
step: 1170 | train loss: 0.0013783854665234685 | train acc 0.9770774245262146
step: 1170 | train loss: 0.0013024858199059963 | train acc 0.9189189672470093
step: 1180 | train loss: 0.002441850956529379 | train acc 0.9508670568466187
step: 1180 | train loss: 0.000431237043812871 | train acc 0.9729729890823364
step: 1190 | train loss: 0.002073257463052869 | train acc 0.9658119678497314
step: 1190 | train loss: 0.0008593208622187376 | train acc 0.9736841917037964
step: 1200 | train loss: 0.002673395676538348 | train acc 0.9526627063751221
step: 1200 | train loss: 0.0029143239371478558 | train acc 0.9189189672470093
step: 1210 | train loss: 0.0026854253374040127 | train acc 0.9394856095314026
step: 1210 | train loss: 0.000846128910779953 | train acc 0.96875
step: 1220 | train loss: 0.0018519596196711063 | train acc 0.9557822942733765
step: 1220 | train loss: 0.0008114580414257944 | train acc 0.9487179517745972
step: 1230 | train loss: 0.002226879820227623 | train acc 0.9608696103096008
step: 1230 | train loss: 0.0061790901236236095 | train acc 0.9428571462631226
step: 1240 | train loss: 0.003837902331724763 | train acc 0.9238653182983398
step: 1240 | train loss: 0.0009570985566824675 | train acc 0.96875
step: 1250 | train loss: 0.0018642564537003636 | train acc 0.966810941696167
step: 1250 | train loss: 0.0003762197447940707 | train acc 1.0
step: 1260 | train loss: 0.0018009532941505313 | train acc 0.9615384936332703
step: 1260 | train loss: 0.0004476471513044089 | train acc 1.0
step: 1270 | train loss: 0.0024849511682987213 | train acc 0.9314285516738892
step: 1270 | train loss: 0.0030245352536439896 | train acc 0.90625
step: 1280 | train loss: 0.0017428573919460177 | train acc 0.9569892287254333
step: 1280 | train loss: 0.0007844193023629487 | train acc 1.0
step: 1290 | train loss: 0.005023729056119919 | train acc 0.9215976595878601
step: 1290 | train loss: 0.0010657364036887884 | train acc 0.9696969985961914
step: 1300 | train loss: 0.0011322111822664738 | train acc 0.9809104204177856
step: 1300 | train loss: 0.009563104249536991 | train acc 0.90625
step: 1310 | train loss: 0.0030207657255232334 | train acc 0.9446808099746704
step: 1310 | train loss: 0.001105242408812046 | train acc 0.9736841917037964
step: 1320 | train loss: 0.003032001666724682 | train acc 0.939481258392334
step: 1320 | train loss: 0.0003620883508119732 | train acc 1.0
step: 1330 | train loss: 0.0037858416326344013 | train acc 0.9252468347549438
step: 1330 | train loss: 0.004800909664481878 | train acc 0.9210526347160339
step: 1340 | train loss: 0.0037848246283829212 | train acc 0.9340490698814392
step: 1340 | train loss: 0.0036479923874139786 | train acc 0.8974359035491943
step: 1350 | train loss: 0.001875172252766788 | train acc 0.9636048674583435
step: 1350 | train loss: 0.003243660554289818 | train acc 0.9705882668495178
step: 1360 | train loss: 0.0016258014366030693 | train acc 0.9669539928436279
step: 1360 | train loss: 0.0020580021664500237 | train acc 0.9473684430122375
step: 1370 | train loss: 0.0024249721318483353 | train acc 0.9643917083740234
step: 1370 | train loss: 0.0018123732879757881 | train acc 0.9428571462631226
step: 1380 | train loss: 0.0039856405928730965 | train acc 0.9384835958480835
step: 1380 | train loss: 0.0014896381180733442 | train acc 0.9750000238418579
step: 1390 | train loss: 0.0023242582101374865 | train acc 0.9488304257392883
step: 1390 | train loss: 0.0009241346269845963 | train acc 1.0
step: 1400 | train loss: 0.002170134801417589 | train acc 0.9558404684066772
step: 1400 | train loss: 0.0019957185722887516 | train acc 0.9655172228813171
step: 1410 | train loss: 0.003423915943130851 | train acc 0.9440559148788452
step: 1410 | train loss: 0.001963967690244317 | train acc 0.96875
step: 1420 | train loss: 0.0018824851140379906 | train acc 0.9599428176879883
step: 1420 | train loss: 0.00552351726219058 | train acc 0.9428571462631226
step: 1430 | train loss: 0.0021833714563399553 | train acc 0.9590973258018494
step: 1430 | train loss: 0.0006427844637073576 | train acc 0.9750000238418579
step: 1440 | train loss: 0.0017453944310545921 | train acc 0.9622641205787659
step: 1440 | train loss: 0.002127468353137374 | train acc 0.9473684430122375
step: 1450 | train loss: 0.002004304900765419 | train acc 0.9626972675323486
step: 1450 | train loss: 0.0003288716252427548 | train acc 1.0
step: 1460 | train loss: 0.00231389282271266 | train acc 0.9529914259910583
step: 1460 | train loss: 0.00048095048987306654 | train acc 1.0
step: 1470 | train loss: 0.002343255328014493 | train acc 0.9464285969734192
step: 1470 | train loss: 0.001751532545313239 | train acc 0.9230769276618958
step: 1480 | train loss: 0.0020868380088359118 | train acc 0.9599999785423279
step: 1480 | train loss: 0.001679681707173586 | train acc 0.9696969985961914
step: 1490 | train loss: 0.003157141385599971 | train acc 0.9343794584274292
step: 1490 | train loss: 0.00035944071714766324 | train acc 1.0
step: 1500 | train loss: 0.0022390561643987894 | train acc 0.9406779408454895
step: 1500 | train loss: 0.004094657022505999 | train acc 0.9090909361839294
step: 1510 | train loss: 0.0037463787011802197 | train acc 0.927142858505249
step: 1510 | train loss: 0.0021342935506254435 | train acc 0.925000011920929
step: 1520 | train loss: 0.001676648622378707 | train acc 0.9606987237930298
step: 1520 | train loss: 0.00025073366123251617 | train acc 1.0
step: 1530 | train loss: 0.0025923096109181643 | train acc 0.9518072009086609
step: 1530 | train loss: 0.0010940348729491234 | train acc 0.9666666984558105
step: 1540 | train loss: 0.002806057222187519 | train acc 0.9518900513648987
step: 1540 | train loss: 0.0007566114654764533 | train acc 1.0
step: 1550 | train loss: 0.0012587298406288028 | train acc 0.969072163105011
step: 1550 | train loss: 0.0009369581239297986 | train acc 0.9722222089767456
step: 1560 | train loss: 0.002628857968375087 | train acc 0.9491525292396545
step: 1560 | train loss: 0.0007282967562787235 | train acc 0.9736841917037964
step: 1570 | train loss: 0.0014159622369334102 | train acc 0.9731258749961853
step: 1570 | train loss: 0.0014947792515158653 | train acc 0.9729729890823364
step: 1580 | train loss: 0.0010102157248184085 | train acc 0.9814020395278931
step: 1580 | train loss: 0.03781799599528313 | train acc 0.6285714507102966
step: 1590 | train loss: 0.0047920746728777885 | train acc 0.9252468347549438
step: 1590 | train loss: 0.002948552370071411 | train acc 0.875
step: 1600 | train loss: 0.0022502364590764046 | train acc 0.9553571343421936
step: 1600 | train loss: 0.020331047475337982 | train acc 0.7948718070983887
step: 1610 | train loss: 0.001563111785799265 | train acc 0.974926233291626
step: 1610 | train loss: 0.0005202819593250751 | train acc 1.0
step: 1620 | train loss: 0.0038203324656933546 | train acc 0.9368723034858704
step: 1620 | train loss: 0.0007440192857757211 | train acc 0.9736841917037964
step: 1630 | train loss: 0.0015203830553218722 | train acc 0.9649122953414917
step: 1630 | train loss: 0.0017479415982961655 | train acc 0.96875
step: 1640 | train loss: 0.004262706730514765 | train acc 0.9365079402923584
step: 1640 | train loss: 0.00047654210356995463 | train acc 1.0
step: 1650 | train loss: 0.002402045065537095 | train acc 0.9459459185600281
step: 1650 | train loss: 0.015894273295998573 | train acc 0.7941176295280457
step: 1660 | train loss: 0.0030462341383099556 | train acc 0.9438202381134033
step: 1660 | train loss: 0.001315033994615078 | train acc 0.9736841917037964
step: 1670 | train loss: 0.0013475747546181083 | train acc 0.9672619104385376
step: 1670 | train loss: 0.0021747411228716373 | train acc 0.9230769276618958
step: 1680 | train loss: 0.0032851265277713537 | train acc 0.9296551942825317
step: 1680 | train loss: 0.004436201881617308 | train acc 0.931034505367279
step: 1690 | train loss: 0.0014935687649995089 | train acc 0.96137934923172
step: 1690 | train loss: 0.004676258657127619 | train acc 0.8857142925262451
step: 1700 | train loss: 0.002440172480419278 | train acc 0.9451038241386414
step: 1700 | train loss: 0.0013080333592370152 | train acc 1.0
step: 1710 | train loss: 0.002160663018003106 | train acc 0.9529914259910583
step: 1710 | train loss: 0.002910582348704338 | train acc 0.949999988079071
step: 1720 | train loss: 0.0019622205290943384 | train acc 0.9491525292396545
step: 1720 | train loss: 0.002554920967668295 | train acc 0.9736841917037964
step: 1730 | train loss: 0.0028211825992912054 | train acc 0.9478827118873596
step: 1730 | train loss: 0.007250888738781214 | train acc 0.9210526347160339
step: 1740 | train loss: 0.003177027450874448 | train acc 0.9297752976417542
step: 1740 | train loss: 0.0007641958072781563 | train acc 1.0
step: 1750 | train loss: 0.0016553717432543635 | train acc 0.9557774662971497
step: 1750 | train loss: 0.003653220133855939 | train acc 0.9210526347160339
step: 1760 | train loss: 0.0019475342705845833 | train acc 0.9677419066429138
step: 1760 | train loss: 0.0016214867355301976 | train acc 0.9736841917037964
step: 1770 | train loss: 0.001503683626651764 | train acc 0.9639249444007874
step: 1770 | train loss: 0.0003741607069969177 | train acc 1.0
step: 1780 | train loss: 0.001757976715452969 | train acc 0.9556213021278381
step: 1780 | train loss: 0.002018908504396677 | train acc 0.9666666984558105
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1782
  valid_eval_accuracy = 0.8957424980764298
  valid_eval_loss = 0.3807332546643491
