device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1783
step: 10 | train loss: 0.023583166301250458 | train acc 0.41709402203559875
step: 10 | train loss: 0.015577937476336956 | train acc 0.5789473652839661
step: 20 | train loss: 0.011127110570669174 | train acc 0.7114285826683044
step: 20 | train loss: 0.007173292338848114 | train acc 0.7692307829856873
step: 30 | train loss: 0.011845095083117485 | train acc 0.7368420958518982
step: 30 | train loss: 0.013673988170921803 | train acc 0.6578947305679321
step: 40 | train loss: 0.008748616091907024 | train acc 0.7716763019561768
step: 40 | train loss: 0.007609290536493063 | train acc 0.7222222089767456
step: 50 | train loss: 0.006693942937999964 | train acc 0.8230884671211243
step: 50 | train loss: 0.0035178952384740114 | train acc 0.8974359035491943
step: 60 | train loss: 0.007661627139896154 | train acc 0.8014285564422607
step: 60 | train loss: 0.008079309947788715 | train acc 0.8484848737716675
step: 70 | train loss: 0.008005059324204922 | train acc 0.8368932008743286
step: 70 | train loss: 0.006056761834770441 | train acc 0.8461538553237915
step: 80 | train loss: 0.005957997404038906 | train acc 0.8536232113838196
step: 80 | train loss: 0.0031912962440401316 | train acc 0.9142857193946838
step: 90 | train loss: 0.006758942734450102 | train acc 0.8394697904586792
step: 90 | train loss: 0.007432193495333195 | train acc 0.8787878751754761
step: 100 | train loss: 0.005886974278837442 | train acc 0.848870038986206
step: 100 | train loss: 0.004811258055269718 | train acc 0.8500000238418579
step: 110 | train loss: 0.007188831921666861 | train acc 0.8133515119552612
step: 110 | train loss: 0.005832554306834936 | train acc 0.824999988079071
step: 120 | train loss: 0.0078045385889709 | train acc 0.8217967748641968
step: 120 | train loss: 0.005232314579188824 | train acc 0.875
step: 130 | train loss: 0.006305391434580088 | train acc 0.8489096164703369
step: 130 | train loss: 0.0046465639024972916 | train acc 0.9090909361839294
step: 140 | train loss: 0.007627722341567278 | train acc 0.8621236681938171
step: 140 | train loss: 0.00514353159815073 | train acc 0.8108108043670654
step: 150 | train loss: 0.006683940999209881 | train acc 0.8312056660652161
step: 150 | train loss: 0.005956505425274372 | train acc 0.8235294222831726
step: 160 | train loss: 0.006206848658621311 | train acc 0.8380681872367859
step: 160 | train loss: 0.004244101699441671 | train acc 0.9210526347160339
step: 170 | train loss: 0.006787825375795364 | train acc 0.8258345127105713
step: 170 | train loss: 0.008551283739507198 | train acc 0.8205128312110901
step: 180 | train loss: 0.006517942063510418 | train acc 0.852173924446106
step: 180 | train loss: 0.003145243041217327 | train acc 0.8974359035491943
step: 190 | train loss: 0.007258754689246416 | train acc 0.8017492890357971
step: 190 | train loss: 0.003384028095752001 | train acc 0.8717948794364929
step: 200 | train loss: 0.006703278981149197 | train acc 0.8534923195838928
step: 200 | train loss: 0.009048373438417912 | train acc 0.7435897588729858
step: 210 | train loss: 0.0070404913276433945 | train acc 0.851311981678009
step: 210 | train loss: 0.00791184976696968 | train acc 0.8000000715255737
step: 220 | train loss: 0.004496736917644739 | train acc 0.8841201663017273
step: 220 | train loss: 0.004164958838373423 | train acc 0.8717948794364929
step: 230 | train loss: 0.005587134510278702 | train acc 0.8473609089851379
step: 230 | train loss: 0.003134877420961857 | train acc 0.9473684430122375
step: 240 | train loss: 0.005516381002962589 | train acc 0.8488211035728455
step: 240 | train loss: 0.002549199853092432 | train acc 0.9375
step: 250 | train loss: 0.005018987227231264 | train acc 0.8632596731185913
step: 250 | train loss: 0.0047506061382591724 | train acc 0.8461538553237915
step: 260 | train loss: 0.007499607279896736 | train acc 0.8470790386199951
step: 260 | train loss: 0.002997353672981262 | train acc 0.944444477558136
step: 270 | train loss: 0.006169402040541172 | train acc 0.876632809638977
step: 270 | train loss: 0.0018523067701607943 | train acc 0.9729729890823364
step: 280 | train loss: 0.004597706254571676 | train acc 0.8920863270759583
step: 280 | train loss: 0.004958471283316612 | train acc 0.8823529481887817
step: 290 | train loss: 0.004488338250666857 | train acc 0.9044862389564514
step: 290 | train loss: 0.0034235017374157906 | train acc 0.8974359035491943
step: 300 | train loss: 0.005823067855089903 | train acc 0.8777778148651123
step: 300 | train loss: 0.0036639170721173286 | train acc 0.8717948794364929
step: 310 | train loss: 0.004487250000238419 | train acc 0.8867647051811218
step: 310 | train loss: 0.005027901381254196 | train acc 0.824999988079071
step: 320 | train loss: 0.004388732369989157 | train acc 0.8888888955116272
step: 320 | train loss: 0.006759438663721085 | train acc 0.931034505367279
step: 330 | train loss: 0.006422541104257107 | train acc 0.8558421730995178
step: 330 | train loss: 0.0036785134579986334 | train acc 0.9411764740943909
step: 340 | train loss: 0.003668362507596612 | train acc 0.9053497910499573
step: 340 | train loss: 0.006009021773934364 | train acc 0.8285714387893677
step: 350 | train loss: 0.0060899462550878525 | train acc 0.8563299775123596
step: 350 | train loss: 0.00538795767351985 | train acc 0.8157894611358643
step: 360 | train loss: 0.004657913465052843 | train acc 0.882778525352478
step: 360 | train loss: 0.004399996250867844 | train acc 0.9210526347160339
step: 370 | train loss: 0.007796717807650566 | train acc 0.8302425146102905
step: 370 | train loss: 0.007887768559157848 | train acc 0.8666667342185974
step: 380 | train loss: 0.004530685022473335 | train acc 0.8825215101242065
step: 380 | train loss: 0.012001722119748592 | train acc 0.7666667103767395
step: 390 | train loss: 0.0065389457158744335 | train acc 0.8792756199836731
step: 390 | train loss: 0.0024924608878791332 | train acc 0.9411764740943909
step: 400 | train loss: 0.003941643517464399 | train acc 0.8904898762702942
step: 400 | train loss: 0.005607757717370987 | train acc 0.9117646813392639
step: 410 | train loss: 0.00673819612711668 | train acc 0.8603988289833069
step: 410 | train loss: 0.006162265781313181 | train acc 0.7837837934494019
step: 420 | train loss: 0.003852576483041048 | train acc 0.9108186960220337
step: 420 | train loss: 0.004632201045751572 | train acc 0.875
step: 430 | train loss: 0.0038888254202902317 | train acc 0.9189189076423645
step: 430 | train loss: 0.001700440770946443 | train acc 0.9545454978942871
step: 440 | train loss: 0.0038841210771352053 | train acc 0.9103840589523315
step: 440 | train loss: 0.0056881289929151535 | train acc 0.8787878751754761
step: 450 | train loss: 0.0049139815382659435 | train acc 0.8864406943321228
step: 450 | train loss: 0.02302408404648304 | train acc 0.6470588445663452
step: 460 | train loss: 0.004637335427105427 | train acc 0.895865261554718
step: 460 | train loss: 0.00471248896792531 | train acc 0.9117646813392639
step: 470 | train loss: 0.0027870642952620983 | train acc 0.9318841099739075
step: 470 | train loss: 0.00896216556429863 | train acc 0.8648648858070374
step: 480 | train loss: 0.004483005031943321 | train acc 0.900719404220581
step: 480 | train loss: 0.00417071208357811 | train acc 0.8717948794364929
step: 490 | train loss: 0.005865374114364386 | train acc 0.8831169009208679
step: 490 | train loss: 0.008139553479850292 | train acc 0.8333333730697632
step: 500 | train loss: 0.005600209813565016 | train acc 0.8917378783226013
step: 500 | train loss: 0.00203149882145226 | train acc 0.9487179517745972
step: 510 | train loss: 0.00503826979547739 | train acc 0.8757396340370178
step: 510 | train loss: 0.003258907236158848 | train acc 0.9333333969116211
step: 520 | train loss: 0.0055825673043727875 | train acc 0.889776349067688
step: 520 | train loss: 0.0035303751938045025 | train acc 0.9473684430122375
step: 530 | train loss: 0.003712030127644539 | train acc 0.9061166048049927
step: 530 | train loss: 0.008016209118068218 | train acc 0.8055555820465088
step: 540 | train loss: 0.0045947725884616375 | train acc 0.8732393980026245
step: 540 | train loss: 0.0014780648052692413 | train acc 1.0
step: 550 | train loss: 0.003916890360414982 | train acc 0.9166666865348816
step: 550 | train loss: 0.002310312818735838 | train acc 0.9583333730697632
step: 560 | train loss: 0.0033816914074122906 | train acc 0.9156976938247681
step: 560 | train loss: 0.002920755185186863 | train acc 0.9629629850387573
step: 570 | train loss: 0.007193263620138168 | train acc 0.8436090350151062
step: 570 | train loss: 0.004707054700702429 | train acc 0.8571428656578064
step: 580 | train loss: 0.006737987976521254 | train acc 0.8611599206924438
step: 580 | train loss: 0.026148831471800804 | train acc 0.7096773982048035
step: 590 | train loss: 0.007423273287713528 | train acc 0.8577648997306824
step: 590 | train loss: 0.005509504582732916 | train acc 0.9166666865348816
step: 600 | train loss: 0.00869102030992508 | train acc 0.8471810221672058
step: 600 | train loss: 0.005603997502475977 | train acc 0.9428571462631226
step: 610 | train loss: 0.00417289836332202 | train acc 0.8978416919708252
step: 610 | train loss: 0.00305208214558661 | train acc 0.9142857193946838
step: 620 | train loss: 0.004216453060507774 | train acc 0.8995816111564636
step: 620 | train loss: 0.0019280643900856376 | train acc 0.9736841917037964
step: 630 | train loss: 0.004399233963340521 | train acc 0.8890489935874939
step: 630 | train loss: 0.001761599793098867 | train acc 0.9705882668495178
step: 640 | train loss: 0.0055619943886995316 | train acc 0.8726207613945007
step: 640 | train loss: 0.005860859993845224 | train acc 0.8666667342185974
step: 650 | train loss: 0.004952396731823683 | train acc 0.9058823585510254
step: 650 | train loss: 0.0036819821689277887 | train acc 0.8823529481887817
step: 660 | train loss: 0.005639274138957262 | train acc 0.8958031535148621
step: 660 | train loss: 0.003081214614212513 | train acc 0.9142857193946838
step: 670 | train loss: 0.004016958177089691 | train acc 0.904285728931427
step: 670 | train loss: 0.0014499920653179288 | train acc 0.9743589758872986
step: 680 | train loss: 0.004112627822905779 | train acc 0.9015691876411438
step: 680 | train loss: 0.0034840605221688747 | train acc 0.8717948794364929
step: 690 | train loss: 0.0054734935984015465 | train acc 0.8785607218742371
step: 690 | train loss: 0.005328598897904158 | train acc 0.9166666865348816
step: 700 | train loss: 0.004314964637160301 | train acc 0.8981077075004578
step: 700 | train loss: 0.004155821166932583 | train acc 0.8235294222831726
step: 710 | train loss: 0.005565444473177195 | train acc 0.8928571939468384
step: 710 | train loss: 0.0068674287758767605 | train acc 0.8181818723678589
step: 720 | train loss: 0.005369109567254782 | train acc 0.8834808468818665
step: 720 | train loss: 0.004348577465862036 | train acc 0.8717948794364929
step: 730 | train loss: 0.004409442655742168 | train acc 0.8810198307037354
step: 730 | train loss: 0.0032035105396062136 | train acc 0.9166666865348816
step: 740 | train loss: 0.003614068264141679 | train acc 0.90666663646698
step: 740 | train loss: 0.0038423710502684116 | train acc 0.875
step: 750 | train loss: 0.0037025066558271646 | train acc 0.9028571248054504
step: 750 | train loss: 0.0017691947286948562 | train acc 0.9729729890823364
step: 760 | train loss: 0.0037162387743592262 | train acc 0.9121813178062439
step: 760 | train loss: 0.002650884911417961 | train acc 0.9487179517745972
step: 770 | train loss: 0.004583786241710186 | train acc 0.9025641083717346
step: 770 | train loss: 0.0035289060324430466 | train acc 1.0
step: 780 | train loss: 0.003021195065230131 | train acc 0.9299553036689758
step: 780 | train loss: 0.004628957714885473 | train acc 0.8823529481887817
step: 790 | train loss: 0.003537531942129135 | train acc 0.9160839319229126
step: 790 | train loss: 0.0058429003693163395 | train acc 0.8684210777282715
step: 800 | train loss: 0.004401304293423891 | train acc 0.9031338691711426
step: 800 | train loss: 0.004577173385769129 | train acc 0.8717948794364929
step: 810 | train loss: 0.004334470257163048 | train acc 0.904347836971283
step: 810 | train loss: 0.0009087153594009578 | train acc 0.9677419066429138
step: 820 | train loss: 0.004422986879944801 | train acc 0.9012875556945801
step: 820 | train loss: 0.0011213197140023112 | train acc 1.0
step: 830 | train loss: 0.003935397602617741 | train acc 0.8920863270759583
step: 830 | train loss: 0.004263713490217924 | train acc 0.9000000357627869
step: 840 | train loss: 0.006918640341609716 | train acc 0.8691099286079407
step: 840 | train loss: 0.0026340875774621964 | train acc 0.9736841917037964
step: 850 | train loss: 0.006348889786750078 | train acc 0.8858773708343506
step: 850 | train loss: 0.001546108047477901 | train acc 0.9750000238418579
step: 860 | train loss: 0.0045892526395618916 | train acc 0.9113019108772278
step: 860 | train loss: 0.0017616541590541601 | train acc 0.9210526347160339
step: 870 | train loss: 0.0036669960245490074 | train acc 0.9075630307197571
step: 870 | train loss: 0.0022870360407978296 | train acc 0.9142857193946838
step: 880 | train loss: 0.004955590236932039 | train acc 0.8880918025970459
step: 880 | train loss: 0.006309781223535538 | train acc 0.75
step: 890 | train loss: 0.0045683919452130795 | train acc 0.888235330581665
step: 890 | train loss: 0.00724818604066968 | train acc 0.800000011920929
step: 900 | train loss: 0.0051448894664645195 | train acc 0.9092920422554016
step: 900 | train loss: 0.002892028773203492 | train acc 0.925000011920929
step: 910 | train loss: 0.002070471877232194 | train acc 0.95652174949646
step: 910 | train loss: 0.0018428872572258115 | train acc 0.9736841917037964
step: 920 | train loss: 0.002529455116018653 | train acc 0.9507958889007568
step: 920 | train loss: 0.0016274991212412715 | train acc 1.0
step: 930 | train loss: 0.002511832630261779 | train acc 0.955244779586792
step: 930 | train loss: 0.0010584286646917462 | train acc 1.0
step: 940 | train loss: 0.0017015159828588367 | train acc 0.9669539928436279
step: 940 | train loss: 0.0010862852213904262 | train acc 0.9750000238418579
step: 950 | train loss: 0.0018607759848237038 | train acc 0.9603960514068604
step: 950 | train loss: 0.004109544213861227 | train acc 0.9285714626312256
step: 960 | train loss: 0.0018235394963994622 | train acc 0.9699812531471252
step: 960 | train loss: 0.0033536835107952356 | train acc 0.8918918967247009
step: 970 | train loss: 0.004314083606004715 | train acc 0.9283626079559326
step: 970 | train loss: 0.004070368129760027 | train acc 0.8918918967247009
step: 980 | train loss: 0.0021722265519201756 | train acc 0.9531478881835938
step: 980 | train loss: 0.0017211439553648233 | train acc 0.9487179517745972
step: 990 | train loss: 0.0020470775198191404 | train acc 0.9566473960876465
step: 990 | train loss: 0.0004358926962595433 | train acc 1.0
step: 1000 | train loss: 0.0024174125865101814 | train acc 0.9553956985473633
step: 1000 | train loss: 0.001076504704542458 | train acc 0.9714285731315613
step: 1010 | train loss: 0.0026061381213366985 | train acc 0.9608127474784851
step: 1010 | train loss: 0.013751032762229443 | train acc 0.800000011920929
step: 1020 | train loss: 0.0022495302837342024 | train acc 0.9604863524436951
step: 1020 | train loss: 0.0010608972515910864 | train acc 1.0
step: 1030 | train loss: 0.002676069037988782 | train acc 0.9518716335296631
step: 1030 | train loss: 0.001038435730151832 | train acc 0.949999988079071
step: 1040 | train loss: 0.0016327396733686328 | train acc 0.9641833901405334
step: 1040 | train loss: 0.000560529064387083 | train acc 0.9729729890823364
step: 1050 | train loss: 0.0032163537107408047 | train acc 0.9497907757759094
step: 1050 | train loss: 0.008164594881236553 | train acc 0.9189189672470093
step: 1060 | train loss: 0.0035276012495160103 | train acc 0.9375907182693481
step: 1060 | train loss: 0.0011080763069912791 | train acc 0.9677419066429138
step: 1070 | train loss: 0.0017470947932451963 | train acc 0.9700149893760681
step: 1070 | train loss: 0.0006309379823505878 | train acc 1.0
step: 1080 | train loss: 0.001637310371734202 | train acc 0.9621784687042236
step: 1080 | train loss: 0.0007427039672620595 | train acc 0.9714285731315613
step: 1090 | train loss: 0.0036497879773378372 | train acc 0.9144384860992432
step: 1090 | train loss: 0.0002488738391548395 | train acc 1.0
step: 1100 | train loss: 0.0016780850710347295 | train acc 0.9655172824859619
step: 1100 | train loss: 0.0002519843983463943 | train acc 1.0
step: 1110 | train loss: 0.0029852434527128935 | train acc 0.9400855898857117
step: 1110 | train loss: 4.956253542331979e-05 | train acc 1.0
step: 1120 | train loss: 0.0019200012320652604 | train acc 0.9692308306694031
step: 1120 | train loss: 0.0028797981794923544 | train acc 0.925000011920929
step: 1130 | train loss: 0.003915182780474424 | train acc 0.9397759437561035
step: 1130 | train loss: 0.0001728262286633253 | train acc 1.0
step: 1140 | train loss: 0.0027222095523029566 | train acc 0.9472182989120483
step: 1140 | train loss: 0.0002708871616050601 | train acc 1.0
step: 1150 | train loss: 0.0027304298710078 | train acc 0.9410828351974487
step: 1150 | train loss: 0.001919394126161933 | train acc 0.9375
step: 1160 | train loss: 0.004521872848272324 | train acc 0.916938066482544
step: 1160 | train loss: 0.0015028000343590975 | train acc 0.9729729890823364
step: 1170 | train loss: 0.0016705720918253064 | train acc 0.9573863744735718
step: 1170 | train loss: 0.003604552708566189 | train acc 0.9743589758872986
step: 1180 | train loss: 0.0016975670587271452 | train acc 0.9729729890823364
step: 1180 | train loss: 0.0011475670617073774 | train acc 0.9714285731315613
step: 1190 | train loss: 0.003942926414310932 | train acc 0.9477401375770569
step: 1190 | train loss: 0.0008139222045429051 | train acc 0.9750000238418579
step: 1200 | train loss: 0.0015766894211992621 | train acc 0.9680696725845337
step: 1200 | train loss: 0.0011913467897102237 | train acc 0.9750000238418579
step: 1210 | train loss: 0.002012818120419979 | train acc 0.9590643644332886
step: 1210 | train loss: 0.0034737102687358856 | train acc 0.9000000357627869
step: 1220 | train loss: 0.002507285214960575 | train acc 0.9607201218605042
step: 1220 | train loss: 0.0004394463903736323 | train acc 1.0
step: 1230 | train loss: 0.0024744730908423662 | train acc 0.9687055349349976
step: 1230 | train loss: 0.0005599025171250105 | train acc 1.0
step: 1240 | train loss: 0.0049694436602294445 | train acc 0.9217638373374939
step: 1240 | train loss: 0.0068000853061676025 | train acc 0.8974359035491943
step: 1250 | train loss: 0.00135180598590523 | train acc 0.9750000238418579
step: 1250 | train loss: 0.0056337621062994 | train acc 0.8529411554336548
step: 1260 | train loss: 0.0018776255892589688 | train acc 0.9572271108627319
step: 1260 | train loss: 0.005680371075868607 | train acc 0.9375
step: 1270 | train loss: 0.0013975092442706227 | train acc 0.9615384340286255
step: 1270 | train loss: 0.004020067397505045 | train acc 0.9166666865348816
step: 1280 | train loss: 0.004349233582615852 | train acc 0.9242174625396729
step: 1280 | train loss: 0.0015256807673722506 | train acc 1.0
step: 1290 | train loss: 0.005786508321762085 | train acc 0.9204713106155396
step: 1290 | train loss: 0.0021137716248631477 | train acc 0.96875
step: 1300 | train loss: 0.0021249360870569944 | train acc 0.9606987237930298
step: 1300 | train loss: 0.0006832567742094398 | train acc 1.0
step: 1310 | train loss: 0.0016424519708380103 | train acc 0.9531478881835938
step: 1310 | train loss: 0.0041101123206317425 | train acc 0.9375
step: 1320 | train loss: 0.0019649944733828306 | train acc 0.9554597735404968
step: 1320 | train loss: 0.0019881713669747114 | train acc 0.9487179517745972
step: 1330 | train loss: 0.0034466919023543596 | train acc 0.9443585276603699
step: 1330 | train loss: 0.003829970257356763 | train acc 0.925000011920929
step: 1340 | train loss: 0.0031535709276795387 | train acc 0.9239482283592224
step: 1340 | train loss: 0.005383248906582594 | train acc 0.8571428656578064
step: 1350 | train loss: 0.001996509497985244 | train acc 0.9603174924850464
step: 1350 | train loss: 0.0018669128185138106 | train acc 0.925000011920929
step: 1360 | train loss: 0.0018424995942041278 | train acc 0.9612069129943848
step: 1360 | train loss: 0.0002541849098633975 | train acc 1.0
step: 1370 | train loss: 0.002173936227336526 | train acc 0.9578651785850525
step: 1370 | train loss: 0.0007172734476625919 | train acc 0.9696969985961914
step: 1380 | train loss: 0.0018786891596391797 | train acc 0.9603960514068604
step: 1380 | train loss: 0.0013010931434109807 | train acc 0.9750000238418579
step: 1390 | train loss: 0.0029719953890889883 | train acc 0.9497206211090088
step: 1390 | train loss: 0.0016749863279983401 | train acc 0.9000000357627869
step: 1400 | train loss: 0.0012678134953603148 | train acc 0.9743224382400513
step: 1400 | train loss: 0.0004509776772465557 | train acc 1.0
step: 1410 | train loss: 0.004535370506346226 | train acc 0.9288389682769775
step: 1410 | train loss: 0.011517503298819065 | train acc 0.8421052694320679
step: 1420 | train loss: 0.001830297987908125 | train acc 0.9639769196510315
step: 1420 | train loss: 0.0018165733199566603 | train acc 0.9354838132858276
step: 1430 | train loss: 0.001957847736775875 | train acc 0.9627072215080261
step: 1430 | train loss: 0.0020383333321660757 | train acc 0.9743589758872986
step: 1440 | train loss: 0.00160815694835037 | train acc 0.9602273106575012
step: 1440 | train loss: 0.0010640030959621072 | train acc 0.9750000238418579
step: 1450 | train loss: 0.0013367000501602888 | train acc 0.9783861637115479
step: 1450 | train loss: 0.0007551859598606825 | train acc 1.0
step: 1460 | train loss: 0.002822057344019413 | train acc 0.9502196311950684
step: 1460 | train loss: 0.0003237262135371566 | train acc 1.0
step: 1470 | train loss: 0.0024654904846102 | train acc 0.9462184906005859
step: 1470 | train loss: 0.00027037193649448454 | train acc 1.0
step: 1480 | train loss: 0.002640759339556098 | train acc 0.949526846408844
step: 1480 | train loss: 0.0011356835020706058 | train acc 0.9473684430122375
step: 1490 | train loss: 0.0035363687202334404 | train acc 0.9363241195678711
step: 1490 | train loss: 0.00036306085530668497 | train acc 1.0
step: 1500 | train loss: 0.0034812043886631727 | train acc 0.933238685131073
step: 1500 | train loss: 0.00037776888348162174 | train acc 1.0
step: 1510 | train loss: 0.0017060041427612305 | train acc 0.9572649598121643
step: 1510 | train loss: 0.00041713114478625357 | train acc 1.0
step: 1520 | train loss: 0.001504561398178339 | train acc 0.9702549576759338
step: 1520 | train loss: 0.005237917881458998 | train acc 0.8684210777282715
step: 1530 | train loss: 0.0014257406583055854 | train acc 0.9800613522529602
step: 1530 | train loss: 0.0016158533981069922 | train acc 0.9705882668495178
step: 1540 | train loss: 0.002228537341579795 | train acc 0.9439867734909058
step: 1540 | train loss: 0.0016509389970451593 | train acc 0.9166666865348816
step: 1550 | train loss: 0.0020935831125825644 | train acc 0.9635568857192993
step: 1550 | train loss: 0.000283432804280892 | train acc 1.0
step: 1560 | train loss: 0.0014247404178604484 | train acc 0.9640179872512817
step: 1560 | train loss: 0.0006395715172402561 | train acc 0.9750000238418579
step: 1570 | train loss: 0.001975405728444457 | train acc 0.9579100012779236
step: 1570 | train loss: 0.00953257828950882 | train acc 0.8205128312110901
step: 1580 | train loss: 0.0015645739622414112 | train acc 0.9678770899772644
step: 1580 | train loss: 0.0024008541367948055 | train acc 0.949999988079071
step: 1590 | train loss: 0.0016116530168801546 | train acc 0.9597222208976746
step: 1590 | train loss: 0.00098426325712353 | train acc 0.9743589758872986
step: 1600 | train loss: 0.001833583926782012 | train acc 0.9652892351150513
step: 1600 | train loss: 0.003187796100974083 | train acc 0.8857142925262451
step: 1610 | train loss: 0.0017532806377857924 | train acc 0.9609261751174927
step: 1610 | train loss: 0.0017309181857854128 | train acc 0.9230769276618958
step: 1620 | train loss: 0.0025202117394655943 | train acc 0.9523099660873413
step: 1620 | train loss: 0.0014829038409516215 | train acc 0.9714285731315613
step: 1630 | train loss: 0.0012085731141269207 | train acc 0.97826087474823
step: 1630 | train loss: 0.00036910013295710087 | train acc 1.0
step: 1640 | train loss: 0.0044271377846598625 | train acc 0.9250720143318176
step: 1640 | train loss: 0.001311583793722093 | train acc 0.9459459781646729
step: 1650 | train loss: 0.001603019773028791 | train acc 0.9648093581199646
step: 1650 | train loss: 0.0013152934843674302 | train acc 0.9729729890823364
step: 1660 | train loss: 0.002389100380241871 | train acc 0.9508196711540222
step: 1660 | train loss: 0.0003160082269459963 | train acc 1.0
step: 1670 | train loss: 0.0022795256227254868 | train acc 0.971962571144104
step: 1670 | train loss: 0.0018163567874580622 | train acc 0.96875
step: 1680 | train loss: 0.003956641536206007 | train acc 0.9395683407783508
step: 1680 | train loss: 0.0025568397250026464 | train acc 0.949999988079071
step: 1690 | train loss: 0.003611790481954813 | train acc 0.9489361643791199
step: 1690 | train loss: 0.00018932878447230905 | train acc 1.0
step: 1700 | train loss: 0.001442474196664989 | train acc 0.9710982441902161
step: 1700 | train loss: 0.0007500521605834365 | train acc 1.0
step: 1710 | train loss: 0.001629498670808971 | train acc 0.9644444584846497
step: 1710 | train loss: 0.02896450273692608 | train acc 0.550000011920929
step: 1720 | train loss: 0.00258539617061615 | train acc 0.9467625617980957
step: 1720 | train loss: 0.0016006175428628922 | train acc 0.9375
step: 1730 | train loss: 0.0023557383101433516 | train acc 0.9669565558433533
step: 1730 | train loss: 0.0064400299452245235 | train acc 0.84375
step: 1740 | train loss: 0.0024598869495093822 | train acc 0.9382184147834778
step: 1740 | train loss: 0.0038077279459685087 | train acc 0.8947368264198303
step: 1750 | train loss: 0.0011200966546311975 | train acc 0.9715909361839294
step: 1750 | train loss: 0.0016716202953830361 | train acc 0.9487179517745972
step: 1760 | train loss: 0.0018486835760995746 | train acc 0.9629629850387573
step: 1760 | train loss: 0.001511618378572166 | train acc 0.949999988079071
step: 1770 | train loss: 0.0022834306582808495 | train acc 0.9534206986427307
step: 1770 | train loss: 0.00019636914657894522 | train acc 1.0
step: 1780 | train loss: 0.0025854480918496847 | train acc 0.9483013153076172
step: 1780 | train loss: 0.001177008613012731 | train acc 0.9714285731315613
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1784
  valid_eval_accuracy = 0.900359066427289
  valid_eval_loss = 0.3706076410862635
