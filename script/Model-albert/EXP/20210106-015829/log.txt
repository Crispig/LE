device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1834
step: 10 | train loss: 0.0225022304803133 | train acc 0.4252336323261261
step: 10 | train loss: 0.013125014491379261 | train acc 0.6000000238418579
step: 20 | train loss: 0.011376078240573406 | train acc 0.6861626505851746
step: 20 | train loss: 0.012420733459293842 | train acc 0.7096773982048035
step: 30 | train loss: 0.010593605227768421 | train acc 0.7514534592628479
step: 30 | train loss: 0.006961077451705933 | train acc 0.824999988079071
step: 40 | train loss: 0.008104187436401844 | train acc 0.8104667663574219
step: 40 | train loss: 0.008681362494826317 | train acc 0.7948718070983887
step: 50 | train loss: 0.006767459213733673 | train acc 0.8448023200035095
step: 50 | train loss: 0.005156068131327629 | train acc 0.824999988079071
step: 60 | train loss: 0.008245592936873436 | train acc 0.7818447947502136
step: 60 | train loss: 0.007375854998826981 | train acc 0.800000011920929
step: 70 | train loss: 0.008382754400372505 | train acc 0.8057921528816223
step: 70 | train loss: 0.006877197418361902 | train acc 0.8285714387893677
step: 80 | train loss: 0.008243880234658718 | train acc 0.8043795228004456
step: 80 | train loss: 0.003599513554945588 | train acc 0.8947368264198303
step: 90 | train loss: 0.00818551704287529 | train acc 0.7959184050559998
step: 90 | train loss: 0.004269011784344912 | train acc 0.8571428656578064
step: 100 | train loss: 0.008307401090860367 | train acc 0.8095930218696594
step: 100 | train loss: 0.0025719532277435064 | train acc 0.949999988079071
step: 110 | train loss: 0.007544598542153835 | train acc 0.790960431098938
step: 110 | train loss: 0.012603983283042908 | train acc 0.675000011920929
step: 120 | train loss: 0.007601012475788593 | train acc 0.8034188151359558
step: 120 | train loss: 0.010248778387904167 | train acc 0.7750000357627869
step: 130 | train loss: 0.008477391675114632 | train acc 0.7882165908813477
step: 130 | train loss: 0.009351465851068497 | train acc 0.8947368264198303
step: 140 | train loss: 0.007086395286023617 | train acc 0.843478262424469
step: 140 | train loss: 0.02963932417333126 | train acc 0.5250000357627869
step: 150 | train loss: 0.006622514687478542 | train acc 0.84375
step: 150 | train loss: 0.001566004939377308 | train acc 1.0
step: 160 | train loss: 0.007515855133533478 | train acc 0.8226037621498108
step: 160 | train loss: 0.0032962877303361893 | train acc 0.8974359035491943
step: 170 | train loss: 0.006805003620684147 | train acc 0.8276353478431702
step: 170 | train loss: 0.011408603750169277 | train acc 0.696969747543335
step: 180 | train loss: 0.006154060363769531 | train acc 0.8371757864952087
step: 180 | train loss: 0.007730298675596714 | train acc 0.8461538553237915
step: 190 | train loss: 0.006672874093055725 | train acc 0.811347484588623
step: 190 | train loss: 0.0046184551902115345 | train acc 0.9000000357627869
step: 200 | train loss: 0.009443917311728 | train acc 0.8177257180213928
step: 200 | train loss: 0.03787859156727791 | train acc 0.5
step: 210 | train loss: 0.005760303232818842 | train acc 0.8538682460784912
step: 210 | train loss: 0.007713716942816973 | train acc 0.7692307829856873
step: 220 | train loss: 0.005235724616795778 | train acc 0.8628005981445312
step: 220 | train loss: 0.004736211150884628 | train acc 0.9459459781646729
step: 230 | train loss: 0.00570742879062891 | train acc 0.848703145980835
step: 230 | train loss: 0.004550387617200613 | train acc 0.8378378748893738
step: 240 | train loss: 0.007133465260267258 | train acc 0.8374100923538208
step: 240 | train loss: 0.0054422165267169476 | train acc 0.8500000238418579
step: 250 | train loss: 0.006572357378900051 | train acc 0.837142825126648
step: 250 | train loss: 0.005806782282888889 | train acc 0.8888888955116272
step: 260 | train loss: 0.008565534837543964 | train acc 0.8290766477584839
step: 260 | train loss: 0.0042833429761230946 | train acc 0.9523809552192688
step: 270 | train loss: 0.0070349606685340405 | train acc 0.8526315689086914
step: 270 | train loss: 0.007441794034093618 | train acc 0.8064515590667725
step: 280 | train loss: 0.005268680863082409 | train acc 0.8762446641921997
step: 280 | train loss: 0.010138742625713348 | train acc 0.7631579041481018
step: 290 | train loss: 0.006116022355854511 | train acc 0.8599106073379517
step: 290 | train loss: 0.0026436864864081144 | train acc 0.8918918967247009
step: 300 | train loss: 0.00624371413141489 | train acc 0.8209607005119324
step: 300 | train loss: 0.005932508036494255 | train acc 0.8857142925262451
step: 310 | train loss: 0.006441363133490086 | train acc 0.862017810344696
step: 310 | train loss: 0.008399437181651592 | train acc 0.7714285850524902
step: 320 | train loss: 0.0055975597351789474 | train acc 0.8636363744735718
step: 320 | train loss: 0.010159636847674847 | train acc 0.9000000357627869
step: 330 | train loss: 0.006876959465444088 | train acc 0.8541997075080872
step: 330 | train loss: 0.0031757380347698927 | train acc 0.9487179517745972
step: 340 | train loss: 0.00506000267341733 | train acc 0.8657342791557312
step: 340 | train loss: 0.003360545262694359 | train acc 0.8947368264198303
step: 350 | train loss: 0.005908537656068802 | train acc 0.8640776872634888
step: 350 | train loss: 0.007201951462775469 | train acc 0.8181818723678589
step: 360 | train loss: 0.005848738364875317 | train acc 0.8727015852928162
step: 360 | train loss: 0.00529089942574501 | train acc 0.800000011920929
step: 370 | train loss: 0.00466579245403409 | train acc 0.8842729926109314
step: 370 | train loss: 0.0029053480830043554 | train acc 0.8918918967247009
step: 380 | train loss: 0.006870369426906109 | train acc 0.857988178730011
step: 380 | train loss: 0.005221958737820387 | train acc 0.8571428656578064
step: 390 | train loss: 0.006495533045381308 | train acc 0.8678343892097473
step: 390 | train loss: 0.008805546909570694 | train acc 0.78125
step: 400 | train loss: 0.0041448683477938175 | train acc 0.9106627702713013
step: 400 | train loss: 0.0015888885827735066 | train acc 0.9714285731315613
step: 410 | train loss: 0.006667992565780878 | train acc 0.8478872776031494
step: 410 | train loss: 0.005502607673406601 | train acc 0.824999988079071
step: 420 | train loss: 0.004463581368327141 | train acc 0.8947368264198303
step: 420 | train loss: 0.0037357581313699484 | train acc 0.8974359035491943
step: 430 | train loss: 0.005879456177353859 | train acc 0.8646408915519714
step: 430 | train loss: 0.002593760611489415 | train acc 0.9000000357627869
step: 440 | train loss: 0.005521847400814295 | train acc 0.8670438528060913
step: 440 | train loss: 0.011889568530023098 | train acc 0.7250000238418579
step: 450 | train loss: 0.00625505531206727 | train acc 0.857621431350708
step: 450 | train loss: 0.05210093408823013 | train acc 1.0
step: 460 | train loss: 0.004174261819571257 | train acc 0.8883861303329468
step: 460 | train loss: 0.004180693067610264 | train acc 0.8947368264198303
step: 470 | train loss: 0.004672427661716938 | train acc 0.897398829460144
step: 470 | train loss: 0.0034849755465984344 | train acc 0.9000000357627869
step: 480 | train loss: 0.004763692617416382 | train acc 0.8888888955116272
step: 480 | train loss: 0.0021949466317892075 | train acc 0.9473684430122375
step: 490 | train loss: 0.004976577125489712 | train acc 0.866946816444397
step: 490 | train loss: 0.002001177053898573 | train acc 1.0
step: 500 | train loss: 0.006784746889024973 | train acc 0.8808139562606812
step: 500 | train loss: 0.003815609263256192 | train acc 0.8857142925262451
step: 510 | train loss: 0.00526899890974164 | train acc 0.8607198596000671
step: 510 | train loss: 0.0031137496698647738 | train acc 0.8974359035491943
step: 520 | train loss: 0.0059453584253787994 | train acc 0.8829786777496338
step: 520 | train loss: 0.0010743706952780485 | train acc 0.9729729890823364
step: 530 | train loss: 0.0062720319256186485 | train acc 0.8657817244529724
step: 530 | train loss: 0.03614826872944832 | train acc 0.575757622718811
step: 540 | train loss: 0.004170714411884546 | train acc 0.9015691876411438
step: 540 | train loss: 0.0034460839815437794 | train acc 0.9032257795333862
step: 550 | train loss: 0.0042845928110182285 | train acc 0.8960114121437073
step: 550 | train loss: 0.0017996442038565874 | train acc 1.0
step: 560 | train loss: 0.0038558884989470243 | train acc 0.9101449847221375
step: 560 | train loss: 0.0056489622220396996 | train acc 0.8918918967247009
step: 570 | train loss: 0.0038200272247195244 | train acc 0.902718186378479
step: 570 | train loss: 0.00940790306776762 | train acc 0.8709677457809448
step: 580 | train loss: 0.005459176376461983 | train acc 0.8823529481887817
step: 580 | train loss: 0.002039299812167883 | train acc 0.9411764740943909
step: 590 | train loss: 0.0038622035644948483 | train acc 0.8945086598396301
step: 590 | train loss: 0.0019158649956807494 | train acc 0.9473684430122375
step: 600 | train loss: 0.003742984961718321 | train acc 0.9042253494262695
step: 600 | train loss: 0.003514312207698822 | train acc 0.9210526347160339
step: 610 | train loss: 0.0051790629513561726 | train acc 0.8776978254318237
step: 610 | train loss: 0.004760583862662315 | train acc 0.9117646813392639
step: 620 | train loss: 0.00445147231221199 | train acc 0.9030390381813049
step: 620 | train loss: 0.001563750091008842 | train acc 0.9473684430122375
step: 630 | train loss: 0.006738831289112568 | train acc 0.8689956665039062
step: 630 | train loss: 0.01303388923406601 | train acc 0.6470588445663452
step: 640 | train loss: 0.005736637394875288 | train acc 0.8854625225067139
step: 640 | train loss: 0.005485341884195805 | train acc 0.8500000238418579
step: 650 | train loss: 0.004346061497926712 | train acc 0.8894230723381042
step: 650 | train loss: 0.0036341254599392414 | train acc 0.8974359035491943
step: 660 | train loss: 0.0033397492952644825 | train acc 0.9147727489471436
step: 660 | train loss: 0.04059083014726639 | train acc 0.45945948362350464
step: 670 | train loss: 0.004056673496961594 | train acc 0.9188033938407898
step: 670 | train loss: 0.004865538794547319 | train acc 0.8421052694320679
step: 680 | train loss: 0.004518656525760889 | train acc 0.8992700576782227
step: 680 | train loss: 0.004249645862728357 | train acc 0.8947368264198303
step: 690 | train loss: 0.003823766252025962 | train acc 0.9144927859306335
step: 690 | train loss: 0.002546766772866249 | train acc 0.9487179517745972
step: 700 | train loss: 0.004514897242188454 | train acc 0.8846153616905212
step: 700 | train loss: 0.002467131009325385 | train acc 0.9473684430122375
step: 710 | train loss: 0.006161987315863371 | train acc 0.8881239295005798
step: 710 | train loss: 0.002712822053581476 | train acc 0.9000000357627869
step: 720 | train loss: 0.007359447423368692 | train acc 0.8478261232376099
step: 720 | train loss: 0.007148358039557934 | train acc 0.8666667342185974
step: 730 | train loss: 0.005028203129768372 | train acc 0.9137199521064758
step: 730 | train loss: 0.003043093951418996 | train acc 0.8888888955116272
step: 740 | train loss: 0.003618162591010332 | train acc 0.9109195470809937
step: 740 | train loss: 0.004653425421565771 | train acc 0.8421052694320679
step: 750 | train loss: 0.004369343630969524 | train acc 0.8881019949913025
step: 750 | train loss: 0.020461179316043854 | train acc 0.7179487347602844
step: 760 | train loss: 0.004203712567687035 | train acc 0.9064327478408813
step: 760 | train loss: 0.020810455083847046 | train acc 0.6764705777168274
step: 770 | train loss: 0.00482738995924592 | train acc 0.901253879070282
step: 770 | train loss: 0.00272398185916245 | train acc 0.9411764740943909
step: 780 | train loss: 0.0038955057971179485 | train acc 0.9076682329177856
step: 780 | train loss: 0.0037502003833651543 | train acc 0.8947368264198303
step: 790 | train loss: 0.005099722649902105 | train acc 0.8764534592628479
step: 790 | train loss: 0.0038490858860313892 | train acc 0.9166666865348816
step: 800 | train loss: 0.00400339113548398 | train acc 0.8986784219741821
step: 800 | train loss: 0.0026678629219532013 | train acc 0.90625
step: 810 | train loss: 0.007980868220329285 | train acc 0.8632352948188782
step: 810 | train loss: 0.003356292610988021 | train acc 0.9000000357627869
step: 820 | train loss: 0.004449876490980387 | train acc 0.8939828276634216
step: 820 | train loss: 0.001436086604371667 | train acc 0.9729729890823364
step: 830 | train loss: 0.004555677995085716 | train acc 0.9089574217796326
step: 830 | train loss: 0.0024796011857688427 | train acc 0.9354838132858276
step: 840 | train loss: 0.0046664089895784855 | train acc 0.899193525314331
step: 840 | train loss: 0.0022179174702614546 | train acc 0.9333333969116211
step: 850 | train loss: 0.0040435390546917915 | train acc 0.9031338691711426
step: 850 | train loss: 0.0035740172024816275 | train acc 0.9230769276618958
step: 860 | train loss: 0.004271314013749361 | train acc 0.9112081527709961
step: 860 | train loss: 0.0072937519289553165 | train acc 0.8378378748893738
step: 870 | train loss: 0.004322000313550234 | train acc 0.895714282989502
step: 870 | train loss: 0.0034154716413468122 | train acc 0.9736841917037964
step: 880 | train loss: 0.004073368385434151 | train acc 0.9169013500213623
step: 880 | train loss: 0.005640172865241766 | train acc 0.8684210777282715
step: 890 | train loss: 0.0037696450017392635 | train acc 0.910404622554779
step: 890 | train loss: 0.0014318095054477453 | train acc 0.9428571462631226
step: 900 | train loss: 0.005051555577665567 | train acc 0.88908451795578
step: 900 | train loss: 0.007600342854857445 | train acc 0.84375
step: 910 | train loss: 0.005262900143861771 | train acc 0.8999999761581421
step: 910 | train loss: 0.0050779893063008785 | train acc 0.8666667342185974
step: 920 | train loss: 0.0062820883467793465 | train acc 0.918367326259613
step: 920 | train loss: 0.008127634413540363 | train acc 0.8666667342185974
step: 930 | train loss: 0.003232632065191865 | train acc 0.9440994262695312
step: 930 | train loss: 0.0018880476709455252 | train acc 0.9736841917037964
step: 940 | train loss: 0.002615018980577588 | train acc 0.9428152441978455
step: 940 | train loss: 0.0007019134936854243 | train acc 1.0
step: 950 | train loss: 0.002783342031762004 | train acc 0.9469914436340332
step: 950 | train loss: 0.001208315254189074 | train acc 1.0
step: 960 | train loss: 0.002273691352456808 | train acc 0.9599428176879883
step: 960 | train loss: 0.004240754526108503 | train acc 0.9000000357627869
step: 970 | train loss: 0.005276825744658709 | train acc 0.9030390381813049
step: 970 | train loss: 0.0010734556708484888 | train acc 1.0
step: 980 | train loss: 0.0022078072652220726 | train acc 0.9583333134651184
step: 980 | train loss: 0.008237309753894806 | train acc 0.7714285850524902
step: 990 | train loss: 0.002416140167042613 | train acc 0.9501718282699585
step: 990 | train loss: 0.003999525681138039 | train acc 0.9210526347160339
step: 1000 | train loss: 0.0026627802290022373 | train acc 0.9484978914260864
step: 1000 | train loss: 0.000956447038333863 | train acc 0.9705882668495178
step: 1010 | train loss: 0.00583077035844326 | train acc 0.9116809368133545
step: 1010 | train loss: 0.0012578541645780206 | train acc 0.9459459781646729
step: 1020 | train loss: 0.002531709149479866 | train acc 0.9493670463562012
step: 1020 | train loss: 0.005021822638809681 | train acc 0.925000011920929
step: 1030 | train loss: 0.0021628423128277063 | train acc 0.9502841234207153
step: 1030 | train loss: 0.0006417540716938674 | train acc 1.0
step: 1040 | train loss: 0.003273230977356434 | train acc 0.9283667802810669
step: 1040 | train loss: 0.0011801389046013355 | train acc 0.9714285731315613
step: 1050 | train loss: 0.0019167661666870117 | train acc 0.9734513163566589
step: 1050 | train loss: 0.0015086258063092828 | train acc 0.949999988079071
step: 1060 | train loss: 0.006810429506003857 | train acc 0.897810161113739
step: 1060 | train loss: 0.000807326112408191 | train acc 1.0
step: 1070 | train loss: 0.0027633996214717627 | train acc 0.9427754282951355
step: 1070 | train loss: 0.0009491801029071212 | train acc 0.9729729890823364
step: 1080 | train loss: 0.0017590326024219394 | train acc 0.9645389914512634
step: 1080 | train loss: 0.0008922450360842049 | train acc 1.0
step: 1090 | train loss: 0.0014831341104581952 | train acc 0.9621543288230896
step: 1090 | train loss: 0.006373874843120575 | train acc 0.8500000238418579
step: 1100 | train loss: 0.0012720543891191483 | train acc 0.9761193990707397
step: 1100 | train loss: 0.0009764038259163499 | train acc 0.9696969985961914
step: 1110 | train loss: 0.004974230658262968 | train acc 0.9207607507705688
step: 1110 | train loss: 0.0001967534626601264 | train acc 1.0
step: 1120 | train loss: 0.002475813962519169 | train acc 0.9473683834075928
step: 1120 | train loss: 0.00040107377571985126 | train acc 1.0
step: 1130 | train loss: 0.0024009239859879017 | train acc 0.9544159770011902
step: 1130 | train loss: 0.00039701868081465364 | train acc 1.0
step: 1140 | train loss: 0.004536066669970751 | train acc 0.9295976758003235
step: 1140 | train loss: 0.0030297408811748028 | train acc 0.9411764740943909
step: 1150 | train loss: 0.0032570231705904007 | train acc 0.930939257144928
step: 1150 | train loss: 0.0039166552014648914 | train acc 0.9411764740943909
step: 1160 | train loss: 0.004104170948266983 | train acc 0.9379509091377258
step: 1160 | train loss: 0.005102497525513172 | train acc 0.8918918967247009
step: 1170 | train loss: 0.0028155858162790537 | train acc 0.9345930218696594
step: 1170 | train loss: 0.0012690384173765779 | train acc 0.9666666984558105
step: 1180 | train loss: 0.005650783888995647 | train acc 0.9166666865348816
step: 1180 | train loss: 0.0007355473935604095 | train acc 0.9714285731315613
step: 1190 | train loss: 0.0017747139791026711 | train acc 0.960982620716095
step: 1190 | train loss: 0.0020115328952670097 | train acc 0.9230769276618958
step: 1200 | train loss: 0.0017861782107502222 | train acc 0.9538904428482056
step: 1200 | train loss: 0.001758756348863244 | train acc 0.925000011920929
step: 1210 | train loss: 0.002227144781500101 | train acc 0.9527326226234436
step: 1210 | train loss: 0.0010609797900542617 | train acc 0.9736841917037964
step: 1220 | train loss: 0.001741141197271645 | train acc 0.9685264825820923
step: 1220 | train loss: 0.00048741884529590607 | train acc 1.0
step: 1230 | train loss: 0.0021988973021507263 | train acc 0.9469696879386902
step: 1230 | train loss: 0.004280370660126209 | train acc 0.875
step: 1240 | train loss: 0.003449880052357912 | train acc 0.9278523325920105
step: 1240 | train loss: 0.0013944902457296848 | train acc 0.9729729890823364
step: 1250 | train loss: 0.003870283719152212 | train acc 0.932374119758606
step: 1250 | train loss: 0.00139370106626302 | train acc 0.9705882668495178
step: 1260 | train loss: 0.001631182269193232 | train acc 0.9531914591789246
step: 1260 | train loss: 0.003966222051531076 | train acc 0.8461538553237915
step: 1270 | train loss: 0.0024588529486209154 | train acc 0.9384616017341614
step: 1270 | train loss: 0.0003493174153845757 | train acc 1.0
step: 1280 | train loss: 0.0037890695966780186 | train acc 0.9262410998344421
step: 1280 | train loss: 0.0012332912301644683 | train acc 0.9743589758872986
step: 1290 | train loss: 0.0028559204656630754 | train acc 0.9483775496482849
step: 1290 | train loss: 0.0037049984093755484 | train acc 0.90625
step: 1300 | train loss: 0.002456683199852705 | train acc 0.9434524178504944
step: 1300 | train loss: 0.001171571551822126 | train acc 0.9750000238418579
step: 1310 | train loss: 0.0029249247163534164 | train acc 0.9349315166473389
step: 1310 | train loss: 0.003610801650211215 | train acc 0.875
step: 1320 | train loss: 0.0019278295803815126 | train acc 0.9579831957817078
step: 1320 | train loss: 0.003583737649023533 | train acc 0.9722222089767456
step: 1330 | train loss: 0.004239396192133427 | train acc 0.939828097820282
step: 1330 | train loss: 0.0006209621788002551 | train acc 1.0
step: 1340 | train loss: 0.004372089635580778 | train acc 0.9283667802810669
step: 1340 | train loss: 0.0011828350834548473 | train acc 0.9750000238418579
step: 1350 | train loss: 0.002221501898020506 | train acc 0.9613670110702515
step: 1350 | train loss: 0.0009799684630706906 | train acc 0.9736841917037964
step: 1360 | train loss: 0.0018051372608169913 | train acc 0.9552669525146484
step: 1360 | train loss: 0.0007713313098065555 | train acc 1.0
step: 1370 | train loss: 0.004396283067762852 | train acc 0.924242377281189
step: 1370 | train loss: 0.0031437836587429047 | train acc 0.9354838132858276
step: 1380 | train loss: 0.002288201590999961 | train acc 0.9485294222831726
step: 1380 | train loss: 0.0021398616954684258 | train acc 0.9473684430122375
step: 1390 | train loss: 0.0019852814730256796 | train acc 0.9604105353355408
step: 1390 | train loss: 0.0023913902696222067 | train acc 0.949999988079071
step: 1400 | train loss: 0.003049589227885008 | train acc 0.946403443813324
step: 1400 | train loss: 0.0003049004590138793 | train acc 1.0
step: 1410 | train loss: 0.001341728144325316 | train acc 0.9710982441902161
step: 1410 | train loss: 0.00037874202826060355 | train acc 1.0
step: 1420 | train loss: 0.002442015800625086 | train acc 0.9528571367263794
step: 1420 | train loss: 0.0004887915565632284 | train acc 1.0
step: 1430 | train loss: 0.004110697656869888 | train acc 0.9312865734100342
step: 1430 | train loss: 0.007826268672943115 | train acc 1.0
step: 1440 | train loss: 0.004047077149152756 | train acc 0.9252971410751343
step: 1440 | train loss: 0.0021317231003195047 | train acc 0.8947368264198303
step: 1450 | train loss: 0.0024612729903310537 | train acc 0.9533528089523315
step: 1450 | train loss: 0.0013895813608542085 | train acc 0.9459459781646729
step: 1460 | train loss: 0.00174817000515759 | train acc 0.9596412777900696
step: 1460 | train loss: 0.00019732695363927633 | train acc 1.0
step: 1470 | train loss: 0.0019416984869167209 | train acc 0.9707174301147461
step: 1470 | train loss: 0.0022547149565070868 | train acc 0.9428571462631226
step: 1480 | train loss: 0.0014883886324241757 | train acc 0.9635343551635742
step: 1480 | train loss: 0.0002944969746749848 | train acc 1.0
step: 1490 | train loss: 0.0018775872886180878 | train acc 0.9577677249908447
step: 1490 | train loss: 0.002931388793513179 | train acc 0.9142857193946838
step: 1500 | train loss: 0.0027127480134367943 | train acc 0.9458483457565308
step: 1500 | train loss: 0.0017703392077237368 | train acc 0.9411764740943909
step: 1510 | train loss: 0.0016225662548094988 | train acc 0.960283637046814
step: 1510 | train loss: 0.0002055161603493616 | train acc 1.0
step: 1520 | train loss: 0.0028555516619235277 | train acc 0.9465541243553162
step: 1520 | train loss: 0.0008881743415258825 | train acc 1.0
step: 1530 | train loss: 0.0026922093238681555 | train acc 0.9614835977554321
step: 1530 | train loss: 0.0014004588592797518 | train acc 0.9736841917037964
step: 1540 | train loss: 0.0022234299685806036 | train acc 0.9540889859199524
step: 1540 | train loss: 0.0009782378328964114 | train acc 0.9743589758872986
step: 1550 | train loss: 0.003095118096098304 | train acc 0.9444444179534912
step: 1550 | train loss: 0.001093094702810049 | train acc 0.9705882668495178
step: 1560 | train loss: 0.003566091414541006 | train acc 0.9413735270500183
step: 1560 | train loss: 0.0024726532865315676 | train acc 0.9545454978942871
step: 1570 | train loss: 0.0020990928169339895 | train acc 0.9500734210014343
step: 1570 | train loss: 0.0010096171172335744 | train acc 0.9722222089767456
step: 1580 | train loss: 0.0019647586159408092 | train acc 0.9566473960876465
step: 1580 | train loss: 0.0010511580621823668 | train acc 0.9736841917037964
step: 1590 | train loss: 0.00278689106926322 | train acc 0.9454806447029114
step: 1590 | train loss: 0.0003496376157272607 | train acc 1.0
step: 1600 | train loss: 0.0023024745751172304 | train acc 0.9513888955116272
step: 1600 | train loss: 0.0020401051733642817 | train acc 0.9473684430122375
step: 1610 | train loss: 0.0037982820067554712 | train acc 0.9318841099739075
step: 1610 | train loss: 0.0003908464277628809 | train acc 1.0
step: 1620 | train loss: 0.0022709104232490063 | train acc 0.9391796588897705
step: 1620 | train loss: 0.0002631140814628452 | train acc 1.0
step: 1630 | train loss: 0.002451069885864854 | train acc 0.9646017551422119
step: 1630 | train loss: 0.0005055789370089769 | train acc 1.0
step: 1640 | train loss: 0.0024887043982744217 | train acc 0.9579100012779236
step: 1640 | train loss: 0.0015423170989379287 | train acc 0.9743589758872986
step: 1650 | train loss: 0.0022263103164732456 | train acc 0.9598854184150696
step: 1650 | train loss: 0.0021322346292436123 | train acc 0.9333333969116211
step: 1660 | train loss: 0.0025041953194886446 | train acc 0.9529411792755127
step: 1660 | train loss: 0.004978343844413757 | train acc 0.9032257795333862
step: 1670 | train loss: 0.0020972874481230974 | train acc 0.9568244814872742
step: 1670 | train loss: 0.0010315412655472755 | train acc 1.0
step: 1680 | train loss: 0.003723432309925556 | train acc 0.9411764740943909
step: 1680 | train loss: 0.003586625447496772 | train acc 0.925000011920929
step: 1690 | train loss: 0.0024385617580264807 | train acc 0.9519572854042053
step: 1690 | train loss: 0.00996082928031683 | train acc 0.8461538553237915
step: 1700 | train loss: 0.0036931459326297045 | train acc 0.9383070468902588
step: 1700 | train loss: 0.004069003276526928 | train acc 0.9459459781646729
step: 1710 | train loss: 0.003098913701251149 | train acc 0.939481258392334
step: 1710 | train loss: 0.0036808429285883904 | train acc 0.9736841917037964
step: 1720 | train loss: 0.0024185320362448692 | train acc 0.948863685131073
step: 1720 | train loss: 0.0022307620383799076 | train acc 0.9729729890823364
step: 1730 | train loss: 0.0023434623144567013 | train acc 0.9625899195671082
step: 1730 | train loss: 0.00026555691147223115 | train acc 1.0
step: 1740 | train loss: 0.0016322862356901169 | train acc 0.9689807891845703
step: 1740 | train loss: 0.0024323470424860716 | train acc 0.9189189672470093
step: 1750 | train loss: 0.002490230370312929 | train acc 0.9401574730873108
step: 1750 | train loss: 0.002254198072478175 | train acc 0.9473684430122375
step: 1760 | train loss: 0.00368434633128345 | train acc 0.9412628412246704
step: 1760 | train loss: 0.000592441763728857 | train acc 1.0
step: 1770 | train loss: 0.002069953130558133 | train acc 0.9503649473190308
step: 1770 | train loss: 0.0009715435444377363 | train acc 0.9705882668495178
step: 1780 | train loss: 0.0014079789398238063 | train acc 0.9694323539733887
step: 1780 | train loss: 0.0017151093343272805 | train acc 0.949999988079071
step: 1790 | train loss: 0.0013794106198474765 | train acc 0.9659091234207153
step: 1790 | train loss: 0.0002834487531799823 | train acc 1.0
step: 1800 | train loss: 0.005599161144345999 | train acc 0.9202362895011902
step: 1800 | train loss: 0.0021698083728551865 | train acc 0.9210526347160339
step: 1810 | train loss: 0.003228280460461974 | train acc 0.9338958859443665
step: 1810 | train loss: 0.0035109391901642084 | train acc 0.9189189672470093
step: 1820 | train loss: 0.0028096686583012342 | train acc 0.936842143535614
step: 1820 | train loss: 0.0003323974378872663 | train acc 1.0
step: 1830 | train loss: 0.0013592415489256382 | train acc 0.9727402925491333
step: 1830 | train loss: 0.0031172395683825016 | train acc 0.949999988079071
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1834
  valid_eval_accuracy = 0.8979225442421134
  valid_eval_loss = 0.36628232460539295
