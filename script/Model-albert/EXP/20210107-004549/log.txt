device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1784
step: 10 | train loss: 0.02136418968439102 | train acc 0.453125
step: 10 | train loss: 0.014064633287489414 | train acc 0.6486486792564392
step: 20 | train loss: 0.013451158069074154 | train acc 0.6719653010368347
step: 20 | train loss: 0.005755321588367224 | train acc 0.8611111044883728
step: 30 | train loss: 0.008632938377559185 | train acc 0.7855072617530823
step: 30 | train loss: 0.01980871893465519 | train acc 0.6578947305679321
step: 40 | train loss: 0.008093291893601418 | train acc 0.8114525079727173
step: 40 | train loss: 0.03364262729883194 | train acc 0.5882353186607361
step: 50 | train loss: 0.006452052854001522 | train acc 0.8267045617103577
step: 50 | train loss: 0.006753659341484308 | train acc 0.8205128312110901
step: 60 | train loss: 0.007427649572491646 | train acc 0.7861189842224121
step: 60 | train loss: 0.009744941256940365 | train acc 0.7941176295280457
step: 70 | train loss: 0.009144531562924385 | train acc 0.8010849952697754
step: 70 | train loss: 0.006321043241769075 | train acc 0.8648648858070374
step: 80 | train loss: 0.005749688483774662 | train acc 0.8420290350914001
step: 80 | train loss: 0.006112910341471434 | train acc 0.8684210777282715
step: 90 | train loss: 0.0073868148028850555 | train acc 0.8064992427825928
step: 90 | train loss: 0.0031786481849849224 | train acc 0.9411764740943909
step: 100 | train loss: 0.006943199783563614 | train acc 0.8323863744735718
step: 100 | train loss: 0.005449031945317984 | train acc 0.7692307829856873
step: 110 | train loss: 0.007080360781401396 | train acc 0.8383838534355164
step: 110 | train loss: 0.003585129277780652 | train acc 0.9615384936332703
step: 120 | train loss: 0.006772566121071577 | train acc 0.8464849591255188
step: 120 | train loss: 0.0017353384755551815 | train acc 0.96875
step: 130 | train loss: 0.006120382808148861 | train acc 0.859967052936554
step: 130 | train loss: 0.0028403475880622864 | train acc 1.0
step: 140 | train loss: 0.004900685511529446 | train acc 0.8820961117744446
step: 140 | train loss: 0.005351755302399397 | train acc 0.8666667342185974
step: 150 | train loss: 0.0068124812096357346 | train acc 0.8555240631103516
step: 150 | train loss: 0.0027768996078521013 | train acc 0.9459459781646729
step: 160 | train loss: 0.0057122292928397655 | train acc 0.8454935550689697
step: 160 | train loss: 0.008613563142716885 | train acc 0.8055555820465088
step: 170 | train loss: 0.004446973092854023 | train acc 0.8934659361839294
step: 170 | train loss: 0.005942388903349638 | train acc 0.800000011920929
step: 180 | train loss: 0.0053877257741987705 | train acc 0.8876080513000488
step: 180 | train loss: 0.005914275534451008 | train acc 0.800000011920929
step: 190 | train loss: 0.004930730909109116 | train acc 0.8842257261276245
step: 190 | train loss: 0.006120344623923302 | train acc 0.8461538553237915
step: 200 | train loss: 0.008194100111722946 | train acc 0.8623999953269958
step: 200 | train loss: 0.004514938686043024 | train acc 0.8888888955116272
step: 210 | train loss: 0.004926143679767847 | train acc 0.8866571187973022
step: 210 | train loss: 0.008102184161543846 | train acc 0.8378378748893738
step: 220 | train loss: 0.005289323627948761 | train acc 0.8677098155021667
step: 220 | train loss: 0.0023215925320982933 | train acc 0.9473684430122375
step: 230 | train loss: 0.0045035346411168575 | train acc 0.8923512697219849
step: 230 | train loss: 0.0047178976237773895 | train acc 0.8918918967247009
step: 240 | train loss: 0.00393158383667469 | train acc 0.9000000357627869
step: 240 | train loss: 0.0021797306835651398 | train acc 0.96875
step: 250 | train loss: 0.004709598608314991 | train acc 0.875
step: 250 | train loss: 0.0013731814688071609 | train acc 1.0
step: 260 | train loss: 0.006254767067730427 | train acc 0.8620129823684692
step: 260 | train loss: 0.0005620206356979907 | train acc 1.0
step: 270 | train loss: 0.004652728792279959 | train acc 0.8954344391822815
step: 270 | train loss: 0.003158747451379895 | train acc 0.9000000357627869
step: 280 | train loss: 0.005689210724085569 | train acc 0.8714285492897034
step: 280 | train loss: 0.0031685875728726387 | train acc 0.9210526347160339
step: 290 | train loss: 0.003321971744298935 | train acc 0.9059829115867615
step: 290 | train loss: 0.004674948751926422 | train acc 0.8611111044883728
step: 300 | train loss: 0.0038804165087640285 | train acc 0.9126074910163879
step: 300 | train loss: 0.001940093352459371 | train acc 0.949999988079071
step: 310 | train loss: 0.005390625447034836 | train acc 0.8935860395431519
step: 310 | train loss: 0.0005435410421341658 | train acc 1.0
step: 320 | train loss: 0.004271759185940027 | train acc 0.9010339379310608
step: 320 | train loss: 0.019670812413096428 | train acc 0.8500000238418579
step: 330 | train loss: 0.007157540414482355 | train acc 0.8735440969467163
step: 330 | train loss: 0.0051873670890927315 | train acc 0.8888888955116272
step: 340 | train loss: 0.006853912491351366 | train acc 0.8573508262634277
step: 340 | train loss: 0.004042153712362051 | train acc 0.8684210777282715
step: 350 | train loss: 0.0036277836188673973 | train acc 0.9146164655685425
step: 350 | train loss: 0.004712587688118219 | train acc 0.9000000357627869
step: 360 | train loss: 0.0033197577577084303 | train acc 0.9170182943344116
step: 360 | train loss: 0.004662156105041504 | train acc 0.8421052694320679
step: 370 | train loss: 0.004167365841567516 | train acc 0.8872180581092834
step: 370 | train loss: 0.002632017247378826 | train acc 0.9230769276618958
step: 380 | train loss: 0.003921580500900745 | train acc 0.9164223074913025
step: 380 | train loss: 0.004705158062279224 | train acc 0.8666667342185974
step: 390 | train loss: 0.009024670347571373 | train acc 0.8759398460388184
step: 390 | train loss: 0.005081424489617348 | train acc 0.8857142925262451
step: 400 | train loss: 0.004181850701570511 | train acc 0.8935860395431519
step: 400 | train loss: 0.0005852431058883667 | train acc 1.0
step: 410 | train loss: 0.004541128408163786 | train acc 0.8991596698760986
step: 410 | train loss: 0.01242719404399395 | train acc 0.7419354915618896
step: 420 | train loss: 0.005139595828950405 | train acc 0.8880813717842102
step: 420 | train loss: 0.0032449716236442327 | train acc 0.9000000357627869
step: 430 | train loss: 0.003927560057491064 | train acc 0.887798011302948
step: 430 | train loss: 0.005480574909597635 | train acc 0.8857142925262451
step: 440 | train loss: 0.00480124494060874 | train acc 0.8849431872367859
step: 440 | train loss: 0.0031167245469987392 | train acc 0.875
step: 450 | train loss: 0.006164216436445713 | train acc 0.8623418211936951
step: 450 | train loss: 0.009037972427904606 | train acc 0.8125
step: 460 | train loss: 0.0042623234912753105 | train acc 0.9003021121025085
step: 460 | train loss: 0.006135913543403149 | train acc 0.8648648858070374
step: 470 | train loss: 0.0036334272008389235 | train acc 0.9123563170433044
step: 470 | train loss: 0.002110725035890937 | train acc 0.944444477558136
step: 480 | train loss: 0.005190553143620491 | train acc 0.8940027952194214
step: 480 | train loss: 0.02003845013678074 | train acc 0.6052631735801697
step: 490 | train loss: 0.003981540445238352 | train acc 0.9021276235580444
step: 490 | train loss: 0.005021651741117239 | train acc 0.9230769276618958
step: 500 | train loss: 0.0037256693467497826 | train acc 0.9173789024353027
step: 500 | train loss: 0.005059029906988144 | train acc 0.8108108043670654
step: 510 | train loss: 0.005494257435202599 | train acc 0.8839161396026611
step: 510 | train loss: 0.005959930829703808 | train acc 0.8823529481887817
step: 520 | train loss: 0.005967567674815655 | train acc 0.8814814686775208
step: 520 | train loss: 0.0029452915769070387 | train acc 0.9166666865348816
step: 530 | train loss: 0.004153347108513117 | train acc 0.913616418838501
step: 530 | train loss: 0.006424570456147194 | train acc 0.8000000715255737
step: 540 | train loss: 0.005061654839664698 | train acc 0.8861111402511597
step: 540 | train loss: 0.00428498862311244 | train acc 0.8823529481887817
step: 550 | train loss: 0.004570864140987396 | train acc 0.8835227489471436
step: 550 | train loss: 0.002946386346593499 | train acc 0.9459459781646729
step: 560 | train loss: 0.0073312376625835896 | train acc 0.849056601524353
step: 560 | train loss: 0.004243804607540369 | train acc 0.8717948794364929
step: 570 | train loss: 0.005402157083153725 | train acc 0.8642335534095764
step: 570 | train loss: 0.007073512300848961 | train acc 0.8157894611358643
step: 580 | train loss: 0.006026883143931627 | train acc 0.8880455493927002
step: 580 | train loss: 0.06092527136206627 | train acc 0.800000011920929
step: 590 | train loss: 0.0043764421716332436 | train acc 0.9084302186965942
step: 590 | train loss: 0.004912273492664099 | train acc 0.8888888955116272
step: 600 | train loss: 0.0038428972475230694 | train acc 0.9177126884460449
step: 600 | train loss: 0.006829073652625084 | train acc 0.8684210777282715
step: 610 | train loss: 0.003649708814918995 | train acc 0.9214285612106323
step: 610 | train loss: 0.003998029977083206 | train acc 0.9210526347160339
step: 620 | train loss: 0.004362099803984165 | train acc 0.9035087823867798
step: 620 | train loss: 0.00255073350854218 | train acc 0.96875
step: 630 | train loss: 0.004146679770201445 | train acc 0.9126637578010559
step: 630 | train loss: 0.002802890492603183 | train acc 0.9000000357627869
step: 640 | train loss: 0.005513519048690796 | train acc 0.8751835227012634
step: 640 | train loss: 0.009386369958519936 | train acc 0.7000000476837158
step: 650 | train loss: 0.004349123686552048 | train acc 0.914185643196106
step: 650 | train loss: 0.004693545866757631 | train acc 0.9189189672470093
step: 660 | train loss: 0.006015245337039232 | train acc 0.8914285898208618
step: 660 | train loss: 0.006031110882759094 | train acc 0.8333333134651184
step: 670 | train loss: 0.004025725182145834 | train acc 0.8931623697280884
step: 670 | train loss: 0.0013853362761437893 | train acc 0.9729729890823364
step: 680 | train loss: 0.0063051688484847546 | train acc 0.8714285492897034
step: 680 | train loss: 0.0017751478590071201 | train acc 0.9736841917037964
step: 690 | train loss: 0.0030576554127037525 | train acc 0.921875
step: 690 | train loss: 0.010549100115895271 | train acc 0.9000000357627869
step: 700 | train loss: 0.004551389254629612 | train acc 0.8970381021499634
step: 700 | train loss: 0.0029966849833726883 | train acc 0.925000011920929
step: 710 | train loss: 0.005452956538647413 | train acc 0.8971428275108337
step: 710 | train loss: 0.0035110809840261936 | train acc 0.9000000357627869
step: 720 | train loss: 0.007029645144939423 | train acc 0.8908818960189819
step: 720 | train loss: 0.00566390436142683 | train acc 0.8684210777282715
step: 730 | train loss: 0.00480616744607687 | train acc 0.9083216190338135
step: 730 | train loss: 0.005325182806700468 | train acc 0.8500000238418579
step: 740 | train loss: 0.004837634041905403 | train acc 0.9021276235580444
step: 740 | train loss: 0.0037082366179674864 | train acc 0.8461538553237915
step: 750 | train loss: 0.005536569282412529 | train acc 0.8846715092658997
step: 750 | train loss: 0.0033331699669361115 | train acc 0.9000000357627869
step: 760 | train loss: 0.00645942147821188 | train acc 0.8703703880310059
step: 760 | train loss: 0.006200176198035479 | train acc 0.8387096524238586
step: 770 | train loss: 0.004633886739611626 | train acc 0.9087837934494019
step: 770 | train loss: 0.004562269896268845 | train acc 0.8709677457809448
step: 780 | train loss: 0.0040931254625320435 | train acc 0.9104938507080078
step: 780 | train loss: 0.003051488660275936 | train acc 0.875
step: 790 | train loss: 0.005033912602812052 | train acc 0.9005934596061707
step: 790 | train loss: 0.03912996128201485 | train acc 0.6000000238418579
step: 800 | train loss: 0.003594315145164728 | train acc 0.9182209372520447
step: 800 | train loss: 0.0014732062118127942 | train acc 0.9473684430122375
step: 810 | train loss: 0.003370814723894 | train acc 0.9172713756561279
step: 810 | train loss: 0.009869233705103397 | train acc 0.6666666865348816
step: 820 | train loss: 0.0035097876098006964 | train acc 0.9210134148597717
step: 820 | train loss: 0.003007987979799509 | train acc 0.9375
step: 830 | train loss: 0.004593063145875931 | train acc 0.8847305774688721
step: 830 | train loss: 0.002765848534181714 | train acc 0.9117646813392639
step: 840 | train loss: 0.004581404849886894 | train acc 0.9046154022216797
step: 840 | train loss: 0.002912698546424508 | train acc 0.9411764740943909
step: 850 | train loss: 0.004885904025286436 | train acc 0.8826087117195129
step: 850 | train loss: 0.007870102301239967 | train acc 0.7435897588729858
step: 860 | train loss: 0.003973186947405338 | train acc 0.8965517282485962
step: 860 | train loss: 0.0009123499039560556 | train acc 0.9714285731315613
step: 870 | train loss: 0.0041150604374706745 | train acc 0.9049645066261292
step: 870 | train loss: 0.0015559280291199684 | train acc 0.925000011920929
step: 880 | train loss: 0.005245611537247896 | train acc 0.8802919387817383
step: 880 | train loss: 0.003427152754738927 | train acc 0.8500000238418579
step: 890 | train loss: 0.006170048378407955 | train acc 0.8925869464874268
step: 890 | train loss: 0.010407187975943089 | train acc 0.800000011920929
step: 900 | train loss: 0.0028222338296473026 | train acc 0.9487870335578918
step: 900 | train loss: 0.0010106338886544108 | train acc 0.9736841917037964
step: 910 | train loss: 0.002178893657401204 | train acc 0.9684210419654846
step: 910 | train loss: 0.0008846552227623761 | train acc 1.0
step: 920 | train loss: 0.0017185657052323222 | train acc 0.9742489457130432
step: 920 | train loss: 0.0018618371104821563 | train acc 0.9729729890823364
step: 930 | train loss: 0.0021082651801407337 | train acc 0.9586894512176514
step: 930 | train loss: 0.009203903377056122 | train acc 0.8611111044883728
step: 940 | train loss: 0.0018818735843524337 | train acc 0.9682539701461792
step: 940 | train loss: 0.0009625352104194462 | train acc 0.9696969985961914
step: 950 | train loss: 0.0018823950085788965 | train acc 0.9573257565498352
step: 950 | train loss: 0.002263326197862625 | train acc 0.9375
step: 960 | train loss: 0.0026581226848065853 | train acc 0.9379432201385498
step: 960 | train loss: 0.0009294817573390901 | train acc 1.0
step: 970 | train loss: 0.0022016798611730337 | train acc 0.9459853768348694
step: 970 | train loss: 0.0005122859729453921 | train acc 1.0
step: 980 | train loss: 0.0021305368281900883 | train acc 0.9546741843223572
step: 980 | train loss: 0.00036924623418599367 | train acc 1.0
step: 990 | train loss: 0.0016468454850837588 | train acc 0.9763560891151428
step: 990 | train loss: 0.0004668121109716594 | train acc 1.0
step: 1000 | train loss: 0.0032515425700694323 | train acc 0.948179304599762
step: 1000 | train loss: 0.0019318284466862679 | train acc 0.9714285731315613
step: 1010 | train loss: 0.0025132184382528067 | train acc 0.9402984976768494
step: 1010 | train loss: 0.00281050824560225 | train acc 0.944444477558136
step: 1020 | train loss: 0.004154232330620289 | train acc 0.9218989610671997
step: 1020 | train loss: 0.001114638289436698 | train acc 1.0
step: 1030 | train loss: 0.00296635995618999 | train acc 0.9419794678688049
step: 1030 | train loss: 0.0019069284899160266 | train acc 0.949999988079071
step: 1040 | train loss: 0.0016632425831630826 | train acc 0.9535210728645325
step: 1040 | train loss: 0.0012248173588886857 | train acc 0.9729729890823364
step: 1050 | train loss: 0.001350570353679359 | train acc 0.9676511883735657
step: 1050 | train loss: 0.0009963428601622581 | train acc 0.9736841917037964
step: 1060 | train loss: 0.0032976369839161634 | train acc 0.9511494040489197
step: 1060 | train loss: 0.00015391701890621334 | train acc 1.0
step: 1070 | train loss: 0.0024140600580722094 | train acc 0.9654654860496521
step: 1070 | train loss: 0.001624473137781024 | train acc 0.9729729890823364
step: 1080 | train loss: 0.002071976661682129 | train acc 0.9699699878692627
step: 1080 | train loss: 0.0011372879380360246 | train acc 0.949999988079071
step: 1090 | train loss: 0.003511295886710286 | train acc 0.9567669630050659
step: 1090 | train loss: 0.00019601540407165885 | train acc 1.0
step: 1100 | train loss: 0.002699894132092595 | train acc 0.9590044021606445
step: 1100 | train loss: 0.00025832452229224145 | train acc 1.0
step: 1110 | train loss: 0.005136972293257713 | train acc 0.9255474209785461
step: 1110 | train loss: 0.00014771262067370117 | train acc 1.0
step: 1120 | train loss: 0.0023560982663184404 | train acc 0.9537572264671326
step: 1120 | train loss: 0.00129978999029845 | train acc 0.949999988079071
step: 1130 | train loss: 0.0023899562656879425 | train acc 0.9542203545570374
step: 1130 | train loss: 0.0009474231046624482 | train acc 1.0
step: 1140 | train loss: 0.0018498854478821158 | train acc 0.9629080295562744
step: 1140 | train loss: 0.0015011823270469904 | train acc 0.9729729890823364
step: 1150 | train loss: 0.006002441979944706 | train acc 0.8954041600227356
step: 1150 | train loss: 0.0001475811004638672 | train acc 1.0
step: 1160 | train loss: 0.0013884793734177947 | train acc 0.9668174982070923
step: 1160 | train loss: 0.01355869323015213 | train acc 0.8965517282485962
step: 1170 | train loss: 0.0021884210873395205 | train acc 0.9509804248809814
step: 1170 | train loss: 0.002852164674550295 | train acc 0.9722222089767456
step: 1180 | train loss: 0.0018636825261637568 | train acc 0.9638727903366089
step: 1180 | train loss: 0.0019724133890122175 | train acc 0.9487179517745972
step: 1190 | train loss: 0.002822778420522809 | train acc 0.9551374316215515
step: 1190 | train loss: 0.0004893061122857034 | train acc 1.0
step: 1200 | train loss: 0.0016869611572474241 | train acc 0.960283637046814
step: 1200 | train loss: 0.0003479944134596735 | train acc 1.0
step: 1210 | train loss: 0.0016477584140375257 | train acc 0.9647576808929443
step: 1210 | train loss: 0.0007727959891781211 | train acc 0.9750000238418579
step: 1220 | train loss: 0.0020631819497793913 | train acc 0.9523809552192688
step: 1220 | train loss: 0.0005869614542461932 | train acc 0.9736841917037964
step: 1230 | train loss: 0.0077107809484004974 | train acc 0.8857566714286804
step: 1230 | train loss: 0.001345010125078261 | train acc 0.925000011920929
step: 1240 | train loss: 0.0021772037725895643 | train acc 0.9524495601654053
step: 1240 | train loss: 0.005685522221028805 | train acc 0.949999988079071
step: 1250 | train loss: 0.0020267535001039505 | train acc 0.9482758641242981
step: 1250 | train loss: 0.0004620337567757815 | train acc 1.0
step: 1260 | train loss: 0.002769825980067253 | train acc 0.9523121118545532
step: 1260 | train loss: 0.0006721907411701977 | train acc 1.0
step: 1270 | train loss: 0.0016726667527109385 | train acc 0.9620786905288696
step: 1270 | train loss: 0.00142099114600569 | train acc 0.9743589758872986
step: 1280 | train loss: 0.003331525018438697 | train acc 0.9399999976158142
step: 1280 | train loss: 0.0005165033508092165 | train acc 1.0
step: 1290 | train loss: 0.0012534073321148753 | train acc 0.9696969985961914
step: 1290 | train loss: 0.0012870064238086343 | train acc 0.9750000238418579
step: 1300 | train loss: 0.0018290255684405565 | train acc 0.9596099853515625
step: 1300 | train loss: 0.001444850116968155 | train acc 0.9743589758872986
step: 1310 | train loss: 0.0014103243593126535 | train acc 0.972375750541687
step: 1310 | train loss: 0.00020236567070242018 | train acc 1.0
step: 1320 | train loss: 0.0027568659279495478 | train acc 0.9570815563201904
step: 1320 | train loss: 0.0011461371323093772 | train acc 0.9750000238418579
step: 1330 | train loss: 0.0035897030029445887 | train acc 0.9446064233779907
step: 1330 | train loss: 0.000327565532643348 | train acc 1.0
step: 1340 | train loss: 0.0034084944054484367 | train acc 0.9609022736549377
step: 1340 | train loss: 0.001028847531415522 | train acc 0.9750000238418579
step: 1350 | train loss: 0.001663454226218164 | train acc 0.9740484952926636
step: 1350 | train loss: 0.00024994887644425035 | train acc 1.0
step: 1360 | train loss: 0.0042529660277068615 | train acc 0.9312321543693542
step: 1360 | train loss: 0.0006674009491689503 | train acc 0.9750000238418579
step: 1370 | train loss: 0.00373520003631711 | train acc 0.9396551847457886
step: 1370 | train loss: 0.003079006914049387 | train acc 0.9189189672470093
step: 1380 | train loss: 0.002152196830138564 | train acc 0.9527897238731384
step: 1380 | train loss: 0.0015299305086955428 | train acc 0.9743589758872986
step: 1390 | train loss: 0.0017739139730110765 | train acc 0.9597122073173523
step: 1390 | train loss: 0.0004394936840981245 | train acc 1.0
step: 1400 | train loss: 0.0030907567124813795 | train acc 0.9413407444953918
step: 1400 | train loss: 0.0015990588581189513 | train acc 0.9714285731315613
step: 1410 | train loss: 0.001967265736311674 | train acc 0.961476743221283
step: 1410 | train loss: 0.0003758470993489027 | train acc 1.0
step: 1420 | train loss: 0.0059639159590005875 | train acc 0.9161849617958069
step: 1420 | train loss: 0.0031232021283358335 | train acc 0.90625
step: 1430 | train loss: 0.0020098735112696886 | train acc 0.966325044631958
step: 1430 | train loss: 0.0010597554501146078 | train acc 1.0
step: 1440 | train loss: 0.0018559811869636178 | train acc 0.9727011322975159
step: 1440 | train loss: 0.0017664558254182339 | train acc 0.9473684430122375
step: 1450 | train loss: 0.0019401820609346032 | train acc 0.9614835977554321
step: 1450 | train loss: 0.0001929664722410962 | train acc 1.0
step: 1460 | train loss: 0.0034150073770433664 | train acc 0.933143675327301
step: 1460 | train loss: 0.013666102662682533 | train acc 0.8857142925262451
step: 1470 | train loss: 0.0019835936836898327 | train acc 0.9511834383010864
step: 1470 | train loss: 0.010177000425755978 | train acc 0.800000011920929
step: 1480 | train loss: 0.0021707704290747643 | train acc 0.9604811072349548
step: 1480 | train loss: 0.0012068207142874599 | train acc 0.9729729890823364
step: 1490 | train loss: 0.0019422174664214253 | train acc 0.95924311876297
step: 1490 | train loss: 0.0017133097862824798 | train acc 0.9750000238418579
step: 1500 | train loss: 0.0015262895030900836 | train acc 0.9634317755699158
step: 1500 | train loss: 0.0005487200687639415 | train acc 1.0
step: 1510 | train loss: 0.0017084188293665648 | train acc 0.9562764763832092
step: 1510 | train loss: 0.001519417273811996 | train acc 0.949999988079071
step: 1520 | train loss: 0.0014460604870691895 | train acc 0.9659091234207153
step: 1520 | train loss: 0.014283386059105396 | train acc 0.7750000357627869
step: 1530 | train loss: 0.00131114455871284 | train acc 0.9698275923728943
step: 1530 | train loss: 0.0023942221887409687 | train acc 0.949999988079071
step: 1540 | train loss: 0.005269539076834917 | train acc 0.923758864402771
step: 1540 | train loss: 0.0007074414752423763 | train acc 1.0
step: 1550 | train loss: 0.002298080362379551 | train acc 0.9540889859199524
step: 1550 | train loss: 0.004045409616082907 | train acc 0.9166666865348816
step: 1560 | train loss: 0.0017961242701858282 | train acc 0.9575070738792419
step: 1560 | train loss: 0.0025181639939546585 | train acc 0.9230769276618958
step: 1570 | train loss: 0.0016388262156397104 | train acc 0.9632353186607361
step: 1570 | train loss: 0.0015195243759080768 | train acc 0.9736841917037964
step: 1580 | train loss: 0.001659619272686541 | train acc 0.9660537838935852
step: 1580 | train loss: 0.0003409112978260964 | train acc 1.0
step: 1590 | train loss: 0.0032332122791558504 | train acc 0.9422534704208374
step: 1590 | train loss: 0.003949788864701986 | train acc 0.9090909361839294
step: 1600 | train loss: 0.002445201389491558 | train acc 0.9416961073875427
step: 1600 | train loss: 0.0015284073306247592 | train acc 1.0
step: 1610 | train loss: 0.001576568465679884 | train acc 0.9577039480209351
step: 1610 | train loss: 0.030524268746376038 | train acc 0.6551724076271057
step: 1620 | train loss: 0.0017572970828041434 | train acc 0.9599428176879883
step: 1620 | train loss: 0.0019699851982295513 | train acc 0.9210526347160339
step: 1630 | train loss: 0.00214055716060102 | train acc 0.9509379267692566
step: 1630 | train loss: 0.0002129646309185773 | train acc 1.0
step: 1640 | train loss: 0.0013386091450229287 | train acc 0.9675993919372559
step: 1640 | train loss: 0.00041669668280519545 | train acc 1.0
step: 1650 | train loss: 0.0018794549396261573 | train acc 0.9639098048210144
step: 1650 | train loss: 0.0008288907120004296 | train acc 0.9750000238418579
step: 1660 | train loss: 0.0015852650394663215 | train acc 0.9624624848365784
step: 1660 | train loss: 0.004100624937564135 | train acc 0.925000011920929
step: 1670 | train loss: 0.0018002396682277322 | train acc 0.9694915413856506
step: 1670 | train loss: 0.0017167646437883377 | train acc 0.944444477558136
step: 1680 | train loss: 0.001630260143429041 | train acc 0.9497126340866089
step: 1680 | train loss: 0.0009167093667201698 | train acc 0.9736841917037964
step: 1690 | train loss: 0.0019667160231620073 | train acc 0.9590973258018494
step: 1690 | train loss: 0.003674902021884918 | train acc 0.9210526347160339
step: 1700 | train loss: 0.0042069763876497746 | train acc 0.9383954405784607
step: 1700 | train loss: 0.003971621859818697 | train acc 0.9189189672470093
step: 1710 | train loss: 0.0015265981201082468 | train acc 0.969740629196167
step: 1710 | train loss: 0.001058220281265676 | train acc 1.0
step: 1720 | train loss: 0.003187549766153097 | train acc 0.9340175986289978
step: 1720 | train loss: 0.0006879921420477331 | train acc 1.0
step: 1730 | train loss: 0.002396839438006282 | train acc 0.9518458843231201
step: 1730 | train loss: 0.0013165924465283751 | train acc 0.9655172228813171
step: 1740 | train loss: 0.0020199499558657408 | train acc 0.9581465125083923
step: 1740 | train loss: 0.0031752807553857565 | train acc 0.9230769276618958
step: 1750 | train loss: 0.003977456595748663 | train acc 0.9351199269294739
step: 1750 | train loss: 0.0010133158648386598 | train acc 0.9705882668495178
step: 1760 | train loss: 0.003476089099422097 | train acc 0.9449275732040405
step: 1760 | train loss: 0.002324148779734969 | train acc 0.9354838132858276
step: 1770 | train loss: 0.0024887481704354286 | train acc 0.9534883499145508
step: 1770 | train loss: 0.0008384633110836148 | train acc 0.9722222089767456
step: 1780 | train loss: 0.003118257038295269 | train acc 0.9448373317718506
step: 1780 | train loss: 0.00037229404551908374 | train acc 1.0
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1786
  valid_eval_accuracy = 0.9022826365734804
  valid_eval_loss = 0.3647072413619959
