device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1783
step: 10 | train loss: 0.023526202887296677 | train acc 0.39074960350990295
step: 10 | train loss: 0.018481068313121796 | train acc 0.5714285969734192
step: 20 | train loss: 0.01221492886543274 | train acc 0.6738816499710083
step: 20 | train loss: 0.008857599459588528 | train acc 0.7878788113594055
step: 30 | train loss: 0.007451062556356192 | train acc 0.8020378351211548
step: 30 | train loss: 0.009538548067212105 | train acc 0.8378378748893738
step: 40 | train loss: 0.008362662978470325 | train acc 0.7962697148323059
step: 40 | train loss: 0.008274969644844532 | train acc 0.7567567825317383
step: 50 | train loss: 0.006217597518116236 | train acc 0.8426966667175293
step: 50 | train loss: 0.002502871211618185 | train acc 0.9000000357627869
step: 60 | train loss: 0.0069714817218482494 | train acc 0.8022598624229431
step: 60 | train loss: 0.0030270423740148544 | train acc 0.925000011920929
step: 70 | train loss: 0.0069997492246329784 | train acc 0.858951210975647
step: 70 | train loss: 0.006588919088244438 | train acc 0.7948718070983887
step: 80 | train loss: 0.005316851660609245 | train acc 0.8529412150382996
step: 80 | train loss: 0.004381551407277584 | train acc 0.8717948794364929
step: 90 | train loss: 0.007810388226062059 | train acc 0.7953889966011047
step: 90 | train loss: 0.003548354608938098 | train acc 0.8947368264198303
step: 100 | train loss: 0.00800689123570919 | train acc 0.8195050954818726
step: 100 | train loss: 0.004829249810427427 | train acc 0.875
step: 110 | train loss: 0.00590038625523448 | train acc 0.8515849709510803
step: 110 | train loss: 0.008081366308033466 | train acc 0.8888888955116272
step: 120 | train loss: 0.006900850683450699 | train acc 0.8036723136901855
step: 120 | train loss: 0.005306275095790625 | train acc 0.800000011920929
step: 130 | train loss: 0.007692110724747181 | train acc 0.8247787356376648
step: 130 | train loss: 0.010631297715008259 | train acc 0.8823529481887817
step: 140 | train loss: 0.009943087585270405 | train acc 0.7906626462936401
step: 140 | train loss: 0.008779154159128666 | train acc 0.7435897588729858
step: 150 | train loss: 0.006211656611412764 | train acc 0.8447293639183044
step: 150 | train loss: 0.006480872165411711 | train acc 0.8378378748893738
step: 160 | train loss: 0.006507544778287411 | train acc 0.8352273106575012
step: 160 | train loss: 0.007398947142064571 | train acc 0.7297297716140747
step: 170 | train loss: 0.006488042883574963 | train acc 0.8414464592933655
step: 170 | train loss: 0.004244751762598753 | train acc 0.8888888955116272
step: 180 | train loss: 0.006813499145209789 | train acc 0.8415697813034058
step: 180 | train loss: 0.0030741682276129723 | train acc 0.9428571462631226
step: 190 | train loss: 0.007794850040227175 | train acc 0.7984962463378906
step: 190 | train loss: 0.018261108547449112 | train acc 0.75
step: 200 | train loss: 0.009479220025241375 | train acc 0.7794871926307678
step: 200 | train loss: 0.006198310758918524 | train acc 0.7894737124443054
step: 210 | train loss: 0.007189618889242411 | train acc 0.8287769556045532
step: 210 | train loss: 0.007991857826709747 | train acc 0.8181818723678589
step: 220 | train loss: 0.006157932803034782 | train acc 0.8438818454742432
step: 220 | train loss: 0.007590731140226126 | train acc 0.7586206793785095
step: 230 | train loss: 0.0062213195487856865 | train acc 0.8364153504371643
step: 230 | train loss: 0.005322152283042669 | train acc 0.8205128312110901
step: 240 | train loss: 0.005126828793436289 | train acc 0.8577525019645691
step: 240 | train loss: 0.012046669609844685 | train acc 0.7179487347602844
step: 250 | train loss: 0.0057278783060610294 | train acc 0.8567454814910889
step: 250 | train loss: 0.005469317082315683 | train acc 0.8421052694320679
step: 260 | train loss: 0.0071471272967755795 | train acc 0.8644940257072449
step: 260 | train loss: 0.007890178821980953 | train acc 0.8571428656578064
step: 270 | train loss: 0.006305996794253588 | train acc 0.8613569140434265
step: 270 | train loss: 0.0032287968788295984 | train acc 0.9473684430122375
step: 280 | train loss: 0.0038833010476082563 | train acc 0.8851540684700012
step: 280 | train loss: 0.004036650061607361 | train acc 0.944444477558136
step: 290 | train loss: 0.004409218672662973 | train acc 0.8876244425773621
step: 290 | train loss: 0.00265631265938282 | train acc 0.8857142925262451
step: 300 | train loss: 0.004698643926531076 | train acc 0.8943661451339722
step: 300 | train loss: 0.0031610678415745497 | train acc 0.9428571462631226
step: 310 | train loss: 0.003842250443994999 | train acc 0.9023323655128479
step: 310 | train loss: 0.004118135664612055 | train acc 0.8857142925262451
step: 320 | train loss: 0.005956725683063269 | train acc 0.855282187461853
step: 320 | train loss: 0.004052216652780771 | train acc 0.9333333969116211
step: 330 | train loss: 0.004897975828498602 | train acc 0.8936508297920227
step: 330 | train loss: 0.0014594376552850008 | train acc 0.9743589758872986
step: 340 | train loss: 0.0049624694511294365 | train acc 0.8757143020629883
step: 340 | train loss: 0.025914818048477173 | train acc 0.6052631735801697
step: 350 | train loss: 0.00444491533562541 | train acc 0.8907563090324402
step: 350 | train loss: 0.006390607450157404 | train acc 0.8857142925262451
step: 360 | train loss: 0.003967303317040205 | train acc 0.892307698726654
step: 360 | train loss: 0.0024482121225446463 | train acc 0.9487179517745972
step: 370 | train loss: 0.006023067981004715 | train acc 0.867521345615387
step: 370 | train loss: 0.008431677706539631 | train acc 0.8648648858070374
step: 380 | train loss: 0.005592936649918556 | train acc 0.8742603659629822
step: 380 | train loss: 0.002778188558295369 | train acc 0.9599999785423279
step: 390 | train loss: 0.004575204569846392 | train acc 0.8986928462982178
step: 390 | train loss: 0.004316194448620081 | train acc 0.8918918967247009
step: 400 | train loss: 0.006597562227398157 | train acc 0.8805969953536987
step: 400 | train loss: 0.0032622681464999914 | train acc 0.9230769276618958
step: 410 | train loss: 0.007141532842069864 | train acc 0.8441558480262756
step: 410 | train loss: 0.0032639324199408293 | train acc 0.8974359035491943
step: 420 | train loss: 0.004734402988106012 | train acc 0.8999999761581421
step: 420 | train loss: 0.0034739801194518805 | train acc 0.9000000357627869
step: 430 | train loss: 0.004175036679953337 | train acc 0.906204879283905
step: 430 | train loss: 0.005064550321549177 | train acc 0.75
step: 440 | train loss: 0.005104626063257456 | train acc 0.8955007195472717
step: 440 | train loss: 0.009145274758338928 | train acc 0.7714285850524902
step: 450 | train loss: 0.007688038516789675 | train acc 0.8271812200546265
step: 450 | train loss: 0.002783656818792224 | train acc 0.9677419066429138
step: 460 | train loss: 0.004583969246596098 | train acc 0.9142857193946838
step: 460 | train loss: 0.0059321229346096516 | train acc 0.8529411554336548
step: 470 | train loss: 0.004466228187084198 | train acc 0.8888888955116272
step: 470 | train loss: 0.0048299687914550304 | train acc 0.9333333969116211
step: 480 | train loss: 0.003707987256348133 | train acc 0.9088358879089355
step: 480 | train loss: 0.003112176666036248 | train acc 0.8611111044883728
step: 490 | train loss: 0.0035372870042920113 | train acc 0.9142857193946838
step: 490 | train loss: 0.0037278502713888884 | train acc 0.8684210777282715
step: 500 | train loss: 0.00451572285965085 | train acc 0.9189985394477844
step: 500 | train loss: 0.002496668603271246 | train acc 0.9487179517745972
step: 510 | train loss: 0.003920343238860369 | train acc 0.9077599048614502
step: 510 | train loss: 0.007857764139771461 | train acc 0.8461538553237915
step: 520 | train loss: 0.00890430435538292 | train acc 0.85467129945755
step: 520 | train loss: 0.0012265249388292432 | train acc 0.9743589758872986
step: 530 | train loss: 0.0040085893124341965 | train acc 0.9195906519889832
step: 530 | train loss: 0.0051530650816857815 | train acc 0.8235294222831726
step: 540 | train loss: 0.005453919060528278 | train acc 0.8860759139060974
step: 540 | train loss: 0.003447593655437231 | train acc 0.9142857193946838
step: 550 | train loss: 0.0032801986671984196 | train acc 0.9362605810165405
step: 550 | train loss: 0.004669192712754011 | train acc 0.8500000238418579
step: 560 | train loss: 0.0043639312498271465 | train acc 0.8995363116264343
step: 560 | train loss: 0.0054614185355603695 | train acc 0.8571428656578064
step: 570 | train loss: 0.004147697240114212 | train acc 0.906876802444458
step: 570 | train loss: 0.00334490230306983 | train acc 0.9230769276618958
step: 580 | train loss: 0.0046389359049499035 | train acc 0.892405092716217
step: 580 | train loss: 0.004379396792501211 | train acc 0.9000000357627869
step: 590 | train loss: 0.006403560284525156 | train acc 0.8860398530960083
step: 590 | train loss: 0.002960040932521224 | train acc 0.9230769276618958
step: 600 | train loss: 0.0033772115129977465 | train acc 0.9169054627418518
step: 600 | train loss: 0.003375845029950142 | train acc 0.925000011920929
step: 610 | train loss: 0.004441027995198965 | train acc 0.9038461446762085
step: 610 | train loss: 0.0019703838042914867 | train acc 0.9729729890823364
step: 620 | train loss: 0.004264819901436567 | train acc 0.9126074910163879
step: 620 | train loss: 0.011956531554460526 | train acc 0.7714285850524902
step: 630 | train loss: 0.004437990952283144 | train acc 0.8884120583534241
step: 630 | train loss: 0.001653830404393375 | train acc 0.9750000238418579
step: 640 | train loss: 0.004391597118228674 | train acc 0.8970814347267151
step: 640 | train loss: 0.0022097767796367407 | train acc 0.949999988079071
step: 650 | train loss: 0.005231249611824751 | train acc 0.8937197923660278
step: 650 | train loss: 0.0026044431142508984 | train acc 0.9333333969116211
step: 660 | train loss: 0.00383908418007195 | train acc 0.9186046719551086
step: 660 | train loss: 0.003293737070634961 | train acc 0.8974359035491943
step: 670 | train loss: 0.0037902258336544037 | train acc 0.9071428179740906
step: 670 | train loss: 0.009469712153077126 | train acc 0.8421052694320679
step: 680 | train loss: 0.003312998218461871 | train acc 0.917730450630188
step: 680 | train loss: 0.003419166198000312 | train acc 0.9459459781646729
step: 690 | train loss: 0.00584222050383687 | train acc 0.8871428370475769
step: 690 | train loss: 0.0068864980712533 | train acc 0.78125
step: 700 | train loss: 0.007067343220114708 | train acc 0.8474820256233215
step: 700 | train loss: 0.0022990971338003874 | train acc 0.9655172228813171
step: 710 | train loss: 0.0040310826152563095 | train acc 0.9103690981864929
step: 710 | train loss: 0.0022194364573806524 | train acc 0.9666666984558105
step: 720 | train loss: 0.005453784950077534 | train acc 0.8862019777297974
step: 720 | train loss: 0.0022500487975776196 | train acc 0.9459459781646729
step: 730 | train loss: 0.005666676443070173 | train acc 0.8999999761581421
step: 730 | train loss: 0.0013762953458353877 | train acc 0.9729729890823364
step: 740 | train loss: 0.003995104227215052 | train acc 0.8967001438140869
step: 740 | train loss: 0.009703143499791622 | train acc 0.8500000238418579
step: 750 | train loss: 0.004028693772852421 | train acc 0.9028986096382141
step: 750 | train loss: 0.002202414907515049 | train acc 0.949999988079071
step: 760 | train loss: 0.003577797906473279 | train acc 0.9300292134284973
step: 760 | train loss: 0.003715591738000512 | train acc 0.8823529481887817
step: 770 | train loss: 0.006727862637490034 | train acc 0.8674304485321045
step: 770 | train loss: 0.003384022042155266 | train acc 0.9230769276618958
step: 780 | train loss: 0.003926699049770832 | train acc 0.9165446758270264
step: 780 | train loss: 0.0017677973955869675 | train acc 0.9722222089767456
step: 790 | train loss: 0.004197793081402779 | train acc 0.908707857131958
step: 790 | train loss: 0.003999792039394379 | train acc 0.9210526347160339
step: 800 | train loss: 0.003396346466615796 | train acc 0.9018492102622986
step: 800 | train loss: 0.0018496105913072824 | train acc 0.9696969985961914
step: 810 | train loss: 0.003329203464090824 | train acc 0.9255014657974243
step: 810 | train loss: 0.006083667743951082 | train acc 0.8285714387893677
step: 820 | train loss: 0.005430974066257477 | train acc 0.9073243737220764
step: 820 | train loss: 0.00268893432803452 | train acc 0.8823529481887817
step: 830 | train loss: 0.0033863522112369537 | train acc 0.9203125238418579
step: 830 | train loss: 0.011820212006568909 | train acc 0.7142857313156128
step: 840 | train loss: 0.005976254586130381 | train acc 0.8854368925094604
step: 840 | train loss: 0.0032241479493677616 | train acc 0.8918918967247009
step: 850 | train loss: 0.006327530834823847 | train acc 0.8619717955589294
step: 850 | train loss: 0.005025321152061224 | train acc 0.8157894611358643
step: 860 | train loss: 0.003923710901290178 | train acc 0.895714282989502
step: 860 | train loss: 0.022047672420740128 | train acc 0.5675675868988037
step: 870 | train loss: 0.004462485667318106 | train acc 0.8803894519805908
step: 870 | train loss: 0.0017488485900685191 | train acc 0.9487179517745972
step: 880 | train loss: 0.004246355965733528 | train acc 0.9167882800102234
step: 880 | train loss: 0.0029884525574743748 | train acc 0.9411764740943909
step: 890 | train loss: 0.0057569751515984535 | train acc 0.8753846287727356
step: 890 | train loss: 0.00834729615598917 | train acc 0.7941176295280457
step: 900 | train loss: 0.0023516537621617317 | train acc 0.954838752746582
step: 900 | train loss: 0.0016762703889980912 | train acc 0.9459459781646729
step: 910 | train loss: 0.00229483749717474 | train acc 0.957602322101593
step: 910 | train loss: 0.001675819861702621 | train acc 0.944444477558136
step: 920 | train loss: 0.0021802156697958708 | train acc 0.9605633616447449
step: 920 | train loss: 0.0008063109708018601 | train acc 1.0
step: 930 | train loss: 0.0033265615347772837 | train acc 0.9272727370262146
step: 930 | train loss: 0.0005343170487321913 | train acc 1.0
step: 940 | train loss: 0.0017366248648613691 | train acc 0.9673758745193481
step: 940 | train loss: 0.0044164517894387245 | train acc 0.9487179517745972
step: 950 | train loss: 0.0013118594652041793 | train acc 0.9736111164093018
step: 950 | train loss: 0.0015983199700713158 | train acc 0.9750000238418579
step: 960 | train loss: 0.0023638412822037935 | train acc 0.9616088271141052
step: 960 | train loss: 0.0003074263804592192 | train acc 1.0
step: 970 | train loss: 0.0026912433095276356 | train acc 0.9545454382896423
step: 970 | train loss: 0.00382789084687829 | train acc 0.9459459781646729
step: 980 | train loss: 0.0017534373328089714 | train acc 0.9632892608642578
step: 980 | train loss: 0.004857063293457031 | train acc 0.9230769276618958
step: 990 | train loss: 0.0032244252506643534 | train acc 0.9540889859199524
step: 990 | train loss: 0.007187953684478998 | train acc 0.9117646813392639
step: 1000 | train loss: 0.002254374325275421 | train acc 0.9557521939277649
step: 1000 | train loss: 0.0005106360767967999 | train acc 1.0
step: 1010 | train loss: 0.0015780605608597398 | train acc 0.9694767594337463
step: 1010 | train loss: 0.0005030336324125528 | train acc 1.0
step: 1020 | train loss: 0.0023161680437624454 | train acc 0.9419448375701904
step: 1020 | train loss: 0.005176806356757879 | train acc 0.8666667342185974
step: 1030 | train loss: 0.003522003535181284 | train acc 0.9350649118423462
step: 1030 | train loss: 0.00168867118190974 | train acc 0.949999988079071
step: 1040 | train loss: 0.001192229799926281 | train acc 0.9753265380859375
step: 1040 | train loss: 0.0003843603772111237 | train acc 1.0
step: 1050 | train loss: 0.0034959125332534313 | train acc 0.9444444179534912
step: 1050 | train loss: 0.0011239363811910152 | train acc 0.96875
step: 1060 | train loss: 0.002099768491461873 | train acc 0.9553313851356506
step: 1060 | train loss: 0.004542444832623005 | train acc 0.8571428656578064
step: 1070 | train loss: 0.0020436327904462814 | train acc 0.9677419066429138
step: 1070 | train loss: 0.00048516772221773863 | train acc 1.0
step: 1080 | train loss: 0.0023841611109673977 | train acc 0.9431487321853638
step: 1080 | train loss: 0.0006041786400601268 | train acc 1.0
step: 1090 | train loss: 0.0021609633695334196 | train acc 0.9509305953979492
step: 1090 | train loss: 0.0011051336769014597 | train acc 0.9459459781646729
step: 1100 | train loss: 0.002949496963992715 | train acc 0.9431487321853638
step: 1100 | train loss: 0.002934647724032402 | train acc 0.9428571462631226
step: 1110 | train loss: 0.0020553595386445522 | train acc 0.9491279125213623
step: 1110 | train loss: 0.0018842450808733702 | train acc 0.9677419066429138
step: 1120 | train loss: 0.0012487253407016397 | train acc 0.9737206101417542
step: 1120 | train loss: 0.0017375200986862183 | train acc 0.9230769276618958
step: 1130 | train loss: 0.0010327850468456745 | train acc 0.9790105223655701
step: 1130 | train loss: 0.0027830242179334164 | train acc 0.9696969985961914
step: 1140 | train loss: 0.002032435731962323 | train acc 0.9586305618286133
step: 1140 | train loss: 0.001371779479086399 | train acc 0.9473684430122375
step: 1150 | train loss: 0.002029962604865432 | train acc 0.9568822383880615
step: 1150 | train loss: 0.0006511108949780464 | train acc 0.9736841917037964
step: 1160 | train loss: 0.0029195789247751236 | train acc 0.9437229633331299
step: 1160 | train loss: 0.0009640776552259922 | train acc 0.9729729890823364
step: 1170 | train loss: 0.0035000902134925127 | train acc 0.9497848153114319
step: 1170 | train loss: 0.003480765502899885 | train acc 0.9473684430122375
step: 1180 | train loss: 0.002521043410524726 | train acc 0.9491279125213623
step: 1180 | train loss: 0.0016243505524471402 | train acc 0.9459459781646729
step: 1190 | train loss: 0.0040679932571947575 | train acc 0.9472140669822693
step: 1190 | train loss: 0.0030059735290706158 | train acc 0.944444477558136
step: 1200 | train loss: 0.00212325737811625 | train acc 0.970457911491394
step: 1200 | train loss: 0.004223025403916836 | train acc 0.8787878751754761
step: 1210 | train loss: 0.001731492462567985 | train acc 0.9631268382072449
step: 1210 | train loss: 0.0033522495068609715 | train acc 0.90625
step: 1220 | train loss: 0.0018297124188393354 | train acc 0.9584087133407593
step: 1220 | train loss: 0.001732206204906106 | train acc 0.949999988079071
step: 1230 | train loss: 0.003560208948329091 | train acc 0.9519650936126709
step: 1230 | train loss: 0.0012233670568093657 | train acc 0.9714285731315613
step: 1240 | train loss: 0.0024587158113718033 | train acc 0.9502074718475342
step: 1240 | train loss: 0.0003113137208856642 | train acc 1.0
step: 1250 | train loss: 0.0011402148520573974 | train acc 0.9751824140548706
step: 1250 | train loss: 0.0013848035596311092 | train acc 0.9714285731315613
step: 1260 | train loss: 0.0011157410917803645 | train acc 0.9710982441902161
step: 1260 | train loss: 0.0014453170588240027 | train acc 0.9750000238418579
step: 1270 | train loss: 0.003266899148002267 | train acc 0.9530791640281677
step: 1270 | train loss: 0.00034565539681352675 | train acc 1.0
step: 1280 | train loss: 0.0034860095474869013 | train acc 0.9375
step: 1280 | train loss: 0.0009547668742015958 | train acc 0.9729729890823364
step: 1290 | train loss: 0.0018551155226305127 | train acc 0.9608696103096008
step: 1290 | train loss: 0.003978714346885681 | train acc 0.9428571462631226
step: 1300 | train loss: 0.002689176006242633 | train acc 0.9463276863098145
step: 1300 | train loss: 0.002576665487140417 | train acc 0.9459459781646729
step: 1310 | train loss: 0.0012726109707728028 | train acc 0.9743224382400513
step: 1310 | train loss: 0.00028830935480073094 | train acc 1.0
step: 1320 | train loss: 0.001926505588926375 | train acc 0.969298243522644
step: 1320 | train loss: 0.00019712508947122842 | train acc 1.0
step: 1330 | train loss: 0.0011489440221339464 | train acc 0.9767441749572754
step: 1330 | train loss: 0.002262951573356986 | train acc 0.9750000238418579
step: 1340 | train loss: 0.0012018759734928608 | train acc 0.9752187132835388
step: 1340 | train loss: 0.0007658643298782408 | train acc 0.9750000238418579
step: 1350 | train loss: 0.0023859848733991385 | train acc 0.9627832174301147
step: 1350 | train loss: 0.0006177923642098904 | train acc 1.0
step: 1360 | train loss: 0.003262135200202465 | train acc 0.9468531608581543
step: 1360 | train loss: 0.0010806084610521793 | train acc 0.9714285731315613
step: 1370 | train loss: 0.002007988980039954 | train acc 0.9618768095970154
step: 1370 | train loss: 0.0007137823267839849 | train acc 0.9743589758872986
step: 1380 | train loss: 0.0015435792738571763 | train acc 0.9702549576759338
step: 1380 | train loss: 0.0014768532710149884 | train acc 0.9736841917037964
step: 1390 | train loss: 0.003940042573958635 | train acc 0.9337175488471985
step: 1390 | train loss: 0.005871384404599667 | train acc 0.96875
step: 1400 | train loss: 0.0018805168801918626 | train acc 0.9538239240646362
step: 1400 | train loss: 0.0008379744249396026 | train acc 0.949999988079071
step: 1410 | train loss: 0.004726671148091555 | train acc 0.927099883556366
step: 1410 | train loss: 0.001281317905522883 | train acc 0.9736841917037964
step: 1420 | train loss: 0.0016878045862540603 | train acc 0.956204354763031
step: 1420 | train loss: 0.0005178491119295359 | train acc 0.9729729890823364
step: 1430 | train loss: 0.0016667996533215046 | train acc 0.9662446975708008
step: 1430 | train loss: 0.0012534505221992731 | train acc 0.9722222089767456
step: 1440 | train loss: 0.0014375988394021988 | train acc 0.9713056087493896
step: 1440 | train loss: 0.003585304832085967 | train acc 0.9210526347160339
step: 1450 | train loss: 0.0013094365131109953 | train acc 0.9714693427085876
step: 1450 | train loss: 0.0006456256378442049 | train acc 1.0
step: 1460 | train loss: 0.0020159331616014242 | train acc 0.9597700834274292
step: 1460 | train loss: 0.00109000108204782 | train acc 0.9729729890823364
step: 1470 | train loss: 0.0023443561512976885 | train acc 0.9644067883491516
step: 1470 | train loss: 0.00226305378600955 | train acc 0.9487179517745972
step: 1480 | train loss: 0.00475097494199872 | train acc 0.9340659379959106
step: 1480 | train loss: 0.003072864143177867 | train acc 0.9189189672470093
step: 1490 | train loss: 0.0019378532888367772 | train acc 0.9518950581550598
step: 1490 | train loss: 0.005528119392693043 | train acc 0.8888888955116272
step: 1500 | train loss: 0.0029672503005713224 | train acc 0.946915328502655
step: 1500 | train loss: 0.0026436264161020517 | train acc 0.9210526347160339
step: 1510 | train loss: 0.0033838513772934675 | train acc 0.955523669719696
step: 1510 | train loss: 0.0006498710135929286 | train acc 1.0
step: 1520 | train loss: 0.0016293155495077372 | train acc 0.9601706862449646
step: 1520 | train loss: 0.003038408700376749 | train acc 0.9696969985961914
step: 1530 | train loss: 0.002376461634412408 | train acc 0.9460270404815674
step: 1530 | train loss: 0.0018259459175169468 | train acc 0.9428571462631226
step: 1540 | train loss: 0.0025001175235956907 | train acc 0.951076328754425
step: 1540 | train loss: 0.0004854191793128848 | train acc 1.0
step: 1550 | train loss: 0.002573103876784444 | train acc 0.9570815563201904
step: 1550 | train loss: 4.919197454000823e-05 | train acc 1.0
step: 1560 | train loss: 0.0016685461159795523 | train acc 0.9679767489433289
step: 1560 | train loss: 0.0015029547503218055 | train acc 0.949999988079071
step: 1570 | train loss: 0.0010056933388113976 | train acc 0.9772403836250305
step: 1570 | train loss: 0.0012208442203700542 | train acc 0.9750000238418579
step: 1580 | train loss: 0.0020340103656053543 | train acc 0.9672364592552185
step: 1580 | train loss: 0.0013088650302961469 | train acc 0.9722222089767456
step: 1590 | train loss: 0.0017168786143884063 | train acc 0.9632768630981445
step: 1590 | train loss: 0.01626557670533657 | train acc 0.7179487347602844
step: 1600 | train loss: 0.0026431232690811157 | train acc 0.9528301954269409
step: 1600 | train loss: 0.001344767864793539 | train acc 1.0
step: 1610 | train loss: 0.002897833939641714 | train acc 0.961262583732605
step: 1610 | train loss: 0.0007494816672988236 | train acc 1.0
step: 1620 | train loss: 0.002860518405213952 | train acc 0.9500000476837158
step: 1620 | train loss: 0.00018557600560598075 | train acc 1.0
step: 1630 | train loss: 0.0014570135390385985 | train acc 0.9663865566253662
step: 1630 | train loss: 0.000923630315810442 | train acc 0.96875
step: 1640 | train loss: 0.0017889146693050861 | train acc 0.9589442610740662
step: 1640 | train loss: 0.005963719915598631 | train acc 0.800000011920929
step: 1650 | train loss: 0.0029885827098041773 | train acc 0.9573257565498352
step: 1650 | train loss: 0.0031648785807192326 | train acc 0.925000011920929
step: 1660 | train loss: 0.0021458836272358894 | train acc 0.9540582299232483
step: 1660 | train loss: 0.0006505479104816914 | train acc 1.0
step: 1670 | train loss: 0.007933675311505795 | train acc 0.9143327474594116
step: 1670 | train loss: 0.001656623906455934 | train acc 0.9473684430122375
step: 1680 | train loss: 0.0022644863929599524 | train acc 0.9511172771453857
step: 1680 | train loss: 0.0007408499368466437 | train acc 0.9487179517745972
step: 1690 | train loss: 0.0014120710548013449 | train acc 0.9720177054405212
step: 1690 | train loss: 0.0012905383482575417 | train acc 0.9743589758872986
step: 1700 | train loss: 0.0023572028148919344 | train acc 0.9569093585014343
step: 1700 | train loss: 0.0013674891088157892 | train acc 0.9428571462631226
step: 1710 | train loss: 0.0017196140252053738 | train acc 0.9684814214706421
step: 1710 | train loss: 0.002928496804088354 | train acc 0.9230769276618958
step: 1720 | train loss: 0.0038564230781048536 | train acc 0.9289693236351013
step: 1720 | train loss: 0.003453705459833145 | train acc 0.925000011920929
step: 1730 | train loss: 0.0017152115469798446 | train acc 0.978378415107727
step: 1730 | train loss: 0.0008410920272581279 | train acc 0.9736841917037964
step: 1740 | train loss: 0.004087226931005716 | train acc 0.9485294222831726
step: 1740 | train loss: 0.000562067492865026 | train acc 0.9743589758872986
step: 1750 | train loss: 0.0012641563080251217 | train acc 0.9684814214706421
step: 1750 | train loss: 0.00019299142877571285 | train acc 1.0
step: 1760 | train loss: 0.00393315264955163 | train acc 0.9450549483299255
step: 1760 | train loss: 0.006252286955714226 | train acc 0.9230769276618958
step: 1770 | train loss: 0.0013874301221221685 | train acc 0.971222996711731
step: 1770 | train loss: 0.029955565929412842 | train acc 0.6052631735801697
step: 1780 | train loss: 0.001564560690894723 | train acc 0.9688427448272705
step: 1780 | train loss: 0.0004964492400176823 | train acc 1.0
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1784
  valid_eval_accuracy = 0.904719158758656
  valid_eval_loss = 0.3635903594066512
