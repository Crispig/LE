device cuda n_gpu 1 distributed training False
***** Running training *****
  Batch size = 2
  Num steps = 1836
step: 10 | train loss: 0.02090705931186676 | train acc 0.45468997955322266
step: 10 | train loss: 0.01916074939072132 | train acc 0.5
step: 20 | train loss: 0.01384621299803257 | train acc 0.6681159734725952
step: 20 | train loss: 0.013007331639528275 | train acc 0.7837837934494019
step: 30 | train loss: 0.009042915888130665 | train acc 0.7784091234207153
step: 30 | train loss: 0.006091510411351919 | train acc 0.824999988079071
step: 40 | train loss: 0.007262561935931444 | train acc 0.8089261054992676
step: 40 | train loss: 0.012507149018347263 | train acc 0.7352941036224365
step: 50 | train loss: 0.0071222069673240185 | train acc 0.8215339183807373
step: 50 | train loss: 0.0059322211891412735 | train acc 0.8421052694320679
step: 60 | train loss: 0.007695023901760578 | train acc 0.7922077775001526
step: 60 | train loss: 0.004749852232635021 | train acc 0.8666667342185974
step: 70 | train loss: 0.010476565919816494 | train acc 0.8022598624229431
step: 70 | train loss: 0.008223414421081543 | train acc 0.800000011920929
step: 80 | train loss: 0.006145121995359659 | train acc 0.8526466488838196
step: 80 | train loss: 0.0019629935268312693 | train acc 0.9487179517745972
step: 90 | train loss: 0.006314567755907774 | train acc 0.8453900218009949
step: 90 | train loss: 0.011831510812044144 | train acc 0.7179487347602844
step: 100 | train loss: 0.005988757591694593 | train acc 0.8376068472862244
step: 100 | train loss: 0.0019142304081469774 | train acc 0.9473684430122375
step: 110 | train loss: 0.007375848479568958 | train acc 0.8283262252807617
step: 110 | train loss: 0.007438726723194122 | train acc 0.8108108043670654
step: 120 | train loss: 0.006865798961371183 | train acc 0.8199999928474426
step: 120 | train loss: 0.0022987208794802427 | train acc 1.0
step: 130 | train loss: 0.007555073592811823 | train acc 0.8135313987731934
step: 130 | train loss: 0.009827417321503162 | train acc 0.9047619104385376
step: 140 | train loss: 0.007140064612030983 | train acc 0.8284024000167847
step: 140 | train loss: 0.004207826219499111 | train acc 0.8717948794364929
step: 150 | train loss: 0.006114036776125431 | train acc 0.8526011109352112
step: 150 | train loss: 0.009777958504855633 | train acc 0.9189189672470093
step: 160 | train loss: 0.006742565892636776 | train acc 0.8462643623352051
step: 160 | train loss: 0.004647723864763975 | train acc 0.90625
step: 170 | train loss: 0.00692197447642684 | train acc 0.8089261054992676
step: 170 | train loss: 0.0059861172921955585 | train acc 0.8235294222831726
step: 180 | train loss: 0.006766858976334333 | train acc 0.8185653686523438
step: 180 | train loss: 0.010690891183912754 | train acc 0.6578947305679321
step: 190 | train loss: 0.006479965057224035 | train acc 0.8284457325935364
step: 190 | train loss: 0.01258295588195324 | train acc 0.8333333730697632
step: 200 | train loss: 0.009058639407157898 | train acc 0.833707869052887
step: 200 | train loss: 0.005408382974565029 | train acc 0.8205128312110901
step: 210 | train loss: 0.007982867769896984 | train acc 0.8308383822441101
step: 210 | train loss: 0.005223084706813097 | train acc 0.8684210777282715
step: 220 | train loss: 0.0061988974921405315 | train acc 0.8408104181289673
step: 220 | train loss: 0.007781161926686764 | train acc 0.8235294222831726
step: 230 | train loss: 0.006471164524555206 | train acc 0.8328571319580078
step: 230 | train loss: 0.011828359216451645 | train acc 0.7250000238418579
step: 240 | train loss: 0.00796434748917818 | train acc 0.7999999523162842
step: 240 | train loss: 0.007142039015889168 | train acc 0.7878788113594055
step: 250 | train loss: 0.008826381526887417 | train acc 0.7696709632873535
step: 250 | train loss: 0.004233693704009056 | train acc 0.9000000357627869
step: 260 | train loss: 0.011096437461674213 | train acc 0.7827788591384888
step: 260 | train loss: 0.003552500158548355 | train acc 0.875
step: 270 | train loss: 0.007533625699579716 | train acc 0.8187134265899658
step: 270 | train loss: 0.005121968220919371 | train acc 0.875
step: 280 | train loss: 0.007330466527491808 | train acc 0.7757405042648315
step: 280 | train loss: 0.0039505367167294025 | train acc 0.8947368264198303
step: 290 | train loss: 0.008582265116274357 | train acc 0.7855113744735718
step: 290 | train loss: 0.008259830996394157 | train acc 0.8484848737716675
step: 300 | train loss: 0.006091926712542772 | train acc 0.8403955101966858
step: 300 | train loss: 0.006123383063822985 | train acc 0.7692307829856873
step: 310 | train loss: 0.007003035396337509 | train acc 0.845255434513092
step: 310 | train loss: 0.005842090584337711 | train acc 0.8965517282485962
step: 320 | train loss: 0.005620053503662348 | train acc 0.8595944046974182
step: 320 | train loss: 0.0058056022971868515 | train acc 0.9583333730697632
step: 330 | train loss: 0.007484083063900471 | train acc 0.8430420756340027
step: 330 | train loss: 0.002203022362664342 | train acc 0.9230769276618958
step: 340 | train loss: 0.005730085540562868 | train acc 0.846372663974762
step: 340 | train loss: 0.004355346783995628 | train acc 0.8611111044883728
step: 350 | train loss: 0.004416732583194971 | train acc 0.9069767594337463
step: 350 | train loss: 0.0036757271736860275 | train acc 0.9230769276618958
step: 360 | train loss: 0.0050084576942026615 | train acc 0.8717579245567322
step: 360 | train loss: 0.0029647769406437874 | train acc 0.944444477558136
step: 370 | train loss: 0.006456396542489529 | train acc 0.8592162728309631
step: 370 | train loss: 0.004465495236217976 | train acc 0.8717948794364929
step: 380 | train loss: 0.007231374736875296 | train acc 0.8512160181999207
step: 380 | train loss: 0.0055227424018085 | train acc 0.824999988079071
step: 390 | train loss: 0.006298695225268602 | train acc 0.8779599070549011
step: 390 | train loss: 0.003505039494484663 | train acc 0.9166666865348816
step: 400 | train loss: 0.0043945955112576485 | train acc 0.8853410482406616
step: 400 | train loss: 0.0029146727174520493 | train acc 0.9189189672470093
step: 410 | train loss: 0.005198008846491575 | train acc 0.8695651888847351
step: 410 | train loss: 0.004167884588241577 | train acc 0.8500000238418579
step: 420 | train loss: 0.004509465303272009 | train acc 0.8806818723678589
step: 420 | train loss: 0.0026077607180923223 | train acc 0.9166666865348816
step: 430 | train loss: 0.007011604495346546 | train acc 0.8759123682975769
step: 430 | train loss: 0.0029024144168943167 | train acc 0.8717948794364929
step: 440 | train loss: 0.004270145203918219 | train acc 0.8895348906517029
step: 440 | train loss: 0.0014800634235143661 | train acc 0.9714285731315613
step: 450 | train loss: 0.00513044698163867 | train acc 0.8885496258735657
step: 450 | train loss: 0.00199302495457232 | train acc 0.9473684430122375
step: 460 | train loss: 0.005183292552828789 | train acc 0.8779411911964417
step: 460 | train loss: 0.0011494706850498915 | train acc 0.9743589758872986
step: 470 | train loss: 0.00551229901611805 | train acc 0.878917396068573
step: 470 | train loss: 0.0012353960191830993 | train acc 0.9743589758872986
step: 480 | train loss: 0.004413324408233166 | train acc 0.8995757102966309
step: 480 | train loss: 0.0022292493376880884 | train acc 0.9210526347160339
step: 490 | train loss: 0.0033986996859312057 | train acc 0.9279412031173706
step: 490 | train loss: 0.005313380621373653 | train acc 0.8857142925262451
step: 500 | train loss: 0.0056616514921188354 | train acc 0.8849929571151733
step: 500 | train loss: 0.0036610011011362076 | train acc 0.9117646813392639
step: 510 | train loss: 0.00459439679980278 | train acc 0.8826151490211487
step: 510 | train loss: 0.00941375270485878 | train acc 0.8378378748893738
step: 520 | train loss: 0.005407204385846853 | train acc 0.8791732788085938
step: 520 | train loss: 0.003258139593526721 | train acc 0.9210526347160339
step: 530 | train loss: 0.0036018569953739643 | train acc 0.9214586019515991
step: 530 | train loss: 0.008741763420403004 | train acc 0.8181818723678589
step: 540 | train loss: 0.0033124079927802086 | train acc 0.9102563858032227
step: 540 | train loss: 0.002282357309013605 | train acc 0.9459459781646729
step: 550 | train loss: 0.005276501644402742 | train acc 0.8748201131820679
step: 550 | train loss: 0.000731281703338027 | train acc 1.0
step: 560 | train loss: 0.0032995252404361963 | train acc 0.9198855757713318
step: 560 | train loss: 0.005703052505850792 | train acc 0.8333333134651184
step: 570 | train loss: 0.0037959092296659946 | train acc 0.9000000357627869
step: 570 | train loss: 0.0055346111766994 | train acc 0.9090909361839294
step: 580 | train loss: 0.005663474090397358 | train acc 0.9065420627593994
step: 580 | train loss: 0.0027005181182175875 | train acc 0.944444477558136
step: 590 | train loss: 0.004632909316569567 | train acc 0.9087018966674805
step: 590 | train loss: 0.005433147773146629 | train acc 0.9696969985961914
step: 600 | train loss: 0.0056434692814946175 | train acc 0.8874269127845764
step: 600 | train loss: 0.004265864845365286 | train acc 0.9189189672470093
step: 610 | train loss: 0.004709587898105383 | train acc 0.9059829115867615
step: 610 | train loss: 0.0030969721265137196 | train acc 0.925000011920929
step: 620 | train loss: 0.004451570101082325 | train acc 0.8988603949546814
step: 620 | train loss: 0.001830541412346065 | train acc 0.925000011920929
step: 630 | train loss: 0.004023394547402859 | train acc 0.9063444137573242
step: 630 | train loss: 0.004056375939399004 | train acc 0.9000000357627869
step: 640 | train loss: 0.005590254440903664 | train acc 0.8630338907241821
step: 640 | train loss: 0.009954552166163921 | train acc 0.8666667342185974
step: 650 | train loss: 0.005501762963831425 | train acc 0.8762711882591248
step: 650 | train loss: 0.00237403460778296 | train acc 0.9722222089767456
step: 660 | train loss: 0.003650361206382513 | train acc 0.9135446548461914
step: 660 | train loss: 0.002216557040810585 | train acc 0.9677419066429138
step: 670 | train loss: 0.002973745809867978 | train acc 0.9321789145469666
step: 670 | train loss: 0.004450520034879446 | train acc 0.9000000357627869
step: 680 | train loss: 0.0036292753648012877 | train acc 0.9238505959510803
step: 680 | train loss: 0.00569536630064249 | train acc 0.8666667342185974
step: 690 | train loss: 0.002956199226900935 | train acc 0.9299269914627075
step: 690 | train loss: 0.005983167327940464 | train acc 0.8157894611358643
step: 700 | train loss: 0.004348829388618469 | train acc 0.898716151714325
step: 700 | train loss: 0.0018447496695443988 | train acc 1.0
step: 710 | train loss: 0.00688288826495409 | train acc 0.8790170550346375
step: 710 | train loss: 0.00165354716591537 | train acc 1.0
step: 720 | train loss: 0.006399585399776697 | train acc 0.8696883916854858
step: 720 | train loss: 0.003742610802873969 | train acc 0.8823529481887817
step: 730 | train loss: 0.00383152742870152 | train acc 0.9097525477409363
step: 730 | train loss: 0.004157080315053463 | train acc 0.9210526347160339
step: 740 | train loss: 0.003471443895250559 | train acc 0.9313305020332336
step: 740 | train loss: 0.0012042844900861382 | train acc 0.949999988079071
step: 750 | train loss: 0.003989165648818016 | train acc 0.9179632663726807
step: 750 | train loss: 0.002782773459330201 | train acc 0.90625
step: 760 | train loss: 0.004618812818080187 | train acc 0.8967066407203674
step: 760 | train loss: 0.00466015562415123 | train acc 0.8684210777282715
step: 770 | train loss: 0.006882339250296354 | train acc 0.8413461446762085
step: 770 | train loss: 0.0021827782038599253 | train acc 0.949999988079071
step: 780 | train loss: 0.004037406295537949 | train acc 0.9177631735801697
step: 780 | train loss: 0.0063440557569265366 | train acc 0.8157894611358643
step: 790 | train loss: 0.005495116580277681 | train acc 0.8809869289398193
step: 790 | train loss: 0.002302616136148572 | train acc 0.949999988079071
step: 800 | train loss: 0.0055087716318666935 | train acc 0.9024045467376709
step: 800 | train loss: 0.0031033833511173725 | train acc 0.9459459781646729
step: 810 | train loss: 0.00460033817216754 | train acc 0.8920863270759583
step: 810 | train loss: 0.0030920347198843956 | train acc 0.9487179517745972
step: 820 | train loss: 0.003935862798243761 | train acc 0.9107913374900818
step: 820 | train loss: 0.00467686215415597 | train acc 0.8461538553237915
step: 830 | train loss: 0.006028805393725634 | train acc 0.8879055976867676
step: 830 | train loss: 0.00809780228883028 | train acc 0.7666667103767395
step: 840 | train loss: 0.006527674850076437 | train acc 0.8775510191917419
step: 840 | train loss: 0.002411661669611931 | train acc 0.9230769276618958
step: 850 | train loss: 0.004116279073059559 | train acc 0.9134328365325928
step: 850 | train loss: 0.004221805837005377 | train acc 0.8684210777282715
step: 860 | train loss: 0.003986181225627661 | train acc 0.9118942618370056
step: 860 | train loss: 0.0010828629601746798 | train acc 0.9736841917037964
step: 870 | train loss: 0.003085284261032939 | train acc 0.917613685131073
step: 870 | train loss: 0.0020570324268192053 | train acc 0.944444477558136
step: 880 | train loss: 0.0037837312556803226 | train acc 0.9231905341148376
step: 880 | train loss: 0.0030759782530367374 | train acc 0.9393939971923828
step: 890 | train loss: 0.0031127159018069506 | train acc 0.9278642535209656
step: 890 | train loss: 0.0026113924104720354 | train acc 0.949999988079071
step: 900 | train loss: 0.00391784030944109 | train acc 0.9106060266494751
step: 900 | train loss: 0.0009861948201432824 | train acc 0.9750000238418579
step: 910 | train loss: 0.004089923109859228 | train acc 0.9051094651222229
step: 910 | train loss: 0.004540011286735535 | train acc 0.8205128312110901
step: 920 | train loss: 0.003822723403573036 | train acc 0.9402984976768494
step: 920 | train loss: 0.006636116653680801 | train acc 0.8666667342185974
step: 930 | train loss: 0.0024486202746629715 | train acc 0.9534534811973572
step: 930 | train loss: 0.003065768862143159 | train acc 0.9743589758872986
step: 940 | train loss: 0.0020486435387283564 | train acc 0.9604105353355408
step: 940 | train loss: 0.0007020244956947863 | train acc 1.0
step: 950 | train loss: 0.0028940283227711916 | train acc 0.946915328502655
step: 950 | train loss: 0.001256000716239214 | train acc 0.9677419066429138
step: 960 | train loss: 0.0031307612080127 | train acc 0.9340974688529968
step: 960 | train loss: 0.0005207295180298388 | train acc 1.0
step: 970 | train loss: 0.0059251850470900536 | train acc 0.9067796468734741
step: 970 | train loss: 0.0007128394790925086 | train acc 1.0
step: 980 | train loss: 0.0032093727495521307 | train acc 0.9458599090576172
step: 980 | train loss: 0.0018105326453223825 | train acc 0.9714285731315613
step: 990 | train loss: 0.007543018553406 | train acc 0.9102804064750671
step: 990 | train loss: 0.0035096697974950075 | train acc 0.8918918967247009
step: 1000 | train loss: 0.003229867434129119 | train acc 0.9377777576446533
step: 1000 | train loss: 0.004305755253881216 | train acc 0.8611111044883728
step: 1010 | train loss: 0.002201416064053774 | train acc 0.9606987237930298
step: 1010 | train loss: 0.0018278348725289106 | train acc 0.9487179517745972
step: 1020 | train loss: 0.0035235118120908737 | train acc 0.9444444179534912
step: 1020 | train loss: 0.0007761911256238818 | train acc 1.0
step: 1030 | train loss: 0.0018264180980622768 | train acc 0.9619883298873901
step: 1030 | train loss: 0.004727885127067566 | train acc 0.9142857193946838
step: 1040 | train loss: 0.0029606944881379604 | train acc 0.9406077861785889
step: 1040 | train loss: 0.00042324844980612397 | train acc 1.0
step: 1050 | train loss: 0.0020671971142292023 | train acc 0.9697479009628296
step: 1050 | train loss: 0.004171181004494429 | train acc 0.9230769276618958
step: 1060 | train loss: 0.002723154379054904 | train acc 0.9551374316215515
step: 1060 | train loss: 0.002138786017894745 | train acc 0.9722222089767456
step: 1070 | train loss: 0.002141454489901662 | train acc 0.9595375657081604
step: 1070 | train loss: 0.001689129858277738 | train acc 0.944444477558136
step: 1080 | train loss: 0.0024466069880872965 | train acc 0.9542856812477112
step: 1080 | train loss: 0.0007240072591230273 | train acc 1.0
step: 1090 | train loss: 0.004378042183816433 | train acc 0.9380403161048889
step: 1090 | train loss: 0.003666957840323448 | train acc 0.8947368264198303
step: 1100 | train loss: 0.0016676982631906867 | train acc 0.9594203233718872
step: 1100 | train loss: 0.00024219253100454807 | train acc 1.0
step: 1110 | train loss: 0.0033779272343963385 | train acc 0.9244094491004944
step: 1110 | train loss: 0.0008809733553789556 | train acc 1.0
step: 1120 | train loss: 0.0018252779264003038 | train acc 0.9611020684242249
step: 1120 | train loss: 0.0031564696691930294 | train acc 0.9375
step: 1130 | train loss: 0.003634993452578783 | train acc 0.94017094373703
step: 1130 | train loss: 0.0014679096639156342 | train acc 0.9333333969116211
step: 1140 | train loss: 0.0021671822760254145 | train acc 0.9529244303703308
step: 1140 | train loss: 0.0030791745521128178 | train acc 0.9473684430122375
step: 1150 | train loss: 0.0028293333016335964 | train acc 0.9524495601654053
step: 1150 | train loss: 0.00041248725028708577 | train acc 1.0
step: 1160 | train loss: 0.0018192793941125274 | train acc 0.9680696725845337
step: 1160 | train loss: 0.0006424664170481265 | train acc 1.0
step: 1170 | train loss: 0.0035983845591545105 | train acc 0.9293078184127808
step: 1170 | train loss: 0.0012730518355965614 | train acc 0.9750000238418579
step: 1180 | train loss: 0.003923874348402023 | train acc 0.931640625
step: 1180 | train loss: 0.0006724880076944828 | train acc 1.0
step: 1190 | train loss: 0.0014191813534125686 | train acc 0.964963436126709
step: 1190 | train loss: 0.0009155757143162191 | train acc 0.9743589758872986
step: 1200 | train loss: 0.0020750549156218767 | train acc 0.9606414437294006
step: 1200 | train loss: 0.0030680743511766195 | train acc 0.9210526347160339
step: 1210 | train loss: 0.0035010408610105515 | train acc 0.9273504018783569
step: 1210 | train loss: 0.00025047187227755785 | train acc 1.0
step: 1220 | train loss: 0.002114832168444991 | train acc 0.9571428298950195
step: 1220 | train loss: 0.0016437247395515442 | train acc 0.9750000238418579
step: 1230 | train loss: 0.0014670011587440968 | train acc 0.9673758745193481
step: 1230 | train loss: 0.0033108429051935673 | train acc 0.925000011920929
step: 1240 | train loss: 0.002029807073995471 | train acc 0.9523809552192688
step: 1240 | train loss: 0.00016313741798512638 | train acc 1.0
step: 1250 | train loss: 0.0017757624154910445 | train acc 0.9652568101882935
step: 1250 | train loss: 0.00022886441729497164 | train acc 1.0
step: 1260 | train loss: 0.001745122135616839 | train acc 0.9525179862976074
step: 1260 | train loss: 0.0002912489289883524 | train acc 1.0
step: 1270 | train loss: 0.0016180482925847173 | train acc 0.958213210105896
step: 1270 | train loss: 0.00014938510139472783 | train acc 1.0
step: 1280 | train loss: 0.002183376345783472 | train acc 0.9528571367263794
step: 1280 | train loss: 0.001178836333565414 | train acc 0.9750000238418579
step: 1290 | train loss: 0.0015482130693271756 | train acc 0.9636099338531494
step: 1290 | train loss: 0.0006706492858938873 | train acc 1.0
step: 1300 | train loss: 0.0012728100409731269 | train acc 0.9629080295562744
step: 1300 | train loss: 0.0020241737365722656 | train acc 0.9666666984558105
step: 1310 | train loss: 0.0015561350155621767 | train acc 0.967391312122345
step: 1310 | train loss: 0.0011075498769059777 | train acc 0.9714285731315613
step: 1320 | train loss: 0.0017992786597460508 | train acc 0.9632248878479004
step: 1320 | train loss: 0.0009557307930663228 | train acc 0.9743589758872986
step: 1330 | train loss: 0.002550615929067135 | train acc 0.9502841234207153
step: 1330 | train loss: 0.0005635682609863579 | train acc 1.0
step: 1340 | train loss: 0.002035301411524415 | train acc 0.9567099809646606
step: 1340 | train loss: 0.0019147286657243967 | train acc 0.9473684430122375
step: 1350 | train loss: 0.0018619487527757883 | train acc 0.9631205201148987
step: 1350 | train loss: 0.007934946566820145 | train acc 0.8823529481887817
step: 1360 | train loss: 0.0016018376918509603 | train acc 0.9670014381408691
step: 1360 | train loss: 0.0004135852213948965 | train acc 1.0
step: 1370 | train loss: 0.0025497875176370144 | train acc 0.9637681245803833
step: 1370 | train loss: 0.0012159091420471668 | train acc 0.96875
step: 1380 | train loss: 0.0013887258246541023 | train acc 0.9622641205787659
step: 1380 | train loss: 0.0021336583886295557 | train acc 0.9199999570846558
step: 1390 | train loss: 0.002428367966786027 | train acc 0.9548105597496033
step: 1390 | train loss: 0.0005693334969691932 | train acc 1.0
step: 1400 | train loss: 0.0019801666494458914 | train acc 0.9560283422470093
step: 1400 | train loss: 0.0031039458699524403 | train acc 0.9736841917037964
step: 1410 | train loss: 0.0012869423953816295 | train acc 0.9698275923728943
step: 1410 | train loss: 0.00040345205343328416 | train acc 1.0
step: 1420 | train loss: 0.003581543453037739 | train acc 0.9391304850578308
step: 1420 | train loss: 0.0016137096099555492 | train acc 0.9705882668495178
step: 1430 | train loss: 0.0032880243379622698 | train acc 0.943368136882782
step: 1430 | train loss: 0.001156254904344678 | train acc 1.0
step: 1440 | train loss: 0.0037035150453448296 | train acc 0.9413580298423767
step: 1440 | train loss: 0.0010775362607091665 | train acc 0.9743589758872986
step: 1450 | train loss: 0.004803691525012255 | train acc 0.9258741736412048
step: 1450 | train loss: 0.0022600980009883642 | train acc 0.9696969985961914
step: 1460 | train loss: 0.002056659199297428 | train acc 0.9649122953414917
step: 1460 | train loss: 0.0018621266353875399 | train acc 0.949999988079071
step: 1470 | train loss: 0.0017473604530096054 | train acc 0.9574467539787292
step: 1470 | train loss: 0.0013013513525947928 | train acc 1.0
step: 1480 | train loss: 0.002775362692773342 | train acc 0.9527897238731384
step: 1480 | train loss: 0.00029603776056319475 | train acc 1.0
step: 1490 | train loss: 0.003636830486357212 | train acc 0.9325681328773499
step: 1490 | train loss: 0.0033254455775022507 | train acc 0.9090909361839294
step: 1500 | train loss: 0.0022591054439544678 | train acc 0.9589257836341858
step: 1500 | train loss: 0.0020672595128417015 | train acc 0.949999988079071
step: 1510 | train loss: 0.001712005934678018 | train acc 0.9614835977554321
step: 1510 | train loss: 0.000877212849445641 | train acc 0.9743589758872986
step: 1520 | train loss: 0.0027715894393622875 | train acc 0.9484679698944092
step: 1520 | train loss: 0.00036368146538734436 | train acc 1.0
step: 1530 | train loss: 0.0031460945028811693 | train acc 0.931034505367279
step: 1530 | train loss: 0.0027120003942400217 | train acc 0.949999988079071
step: 1540 | train loss: 0.002481843112036586 | train acc 0.9528571367263794
step: 1540 | train loss: 0.0006985848885960877 | train acc 1.0
step: 1550 | train loss: 0.0018124146154150367 | train acc 0.9520958662033081
step: 1550 | train loss: 0.0015410726191475987 | train acc 0.9666666984558105
step: 1560 | train loss: 0.002739374293014407 | train acc 0.9370967745780945
step: 1560 | train loss: 0.0002419175871182233 | train acc 1.0
step: 1570 | train loss: 0.0018738623475655913 | train acc 0.966183602809906
step: 1570 | train loss: 0.03546231985092163 | train acc 0.5806451439857483
step: 1580 | train loss: 0.004680122248828411 | train acc 0.9264069199562073
step: 1580 | train loss: 0.0022056957241147757 | train acc 0.925000011920929
step: 1590 | train loss: 0.0015939961886033416 | train acc 0.9688385128974915
step: 1590 | train loss: 0.00034506761585362256 | train acc 1.0
step: 1600 | train loss: 0.0022600279189646244 | train acc 0.9574467539787292
step: 1600 | train loss: 0.012512833811342716 | train acc 0.9333333969116211
step: 1610 | train loss: 0.0026356419548392296 | train acc 0.9622904658317566
step: 1610 | train loss: 0.0008977354736998677 | train acc 0.9729729890823364
step: 1620 | train loss: 0.0018462552689015865 | train acc 0.9594789743423462
step: 1620 | train loss: 0.0008106492459774017 | train acc 1.0
step: 1630 | train loss: 0.0029445101972669363 | train acc 0.9486725330352783
step: 1630 | train loss: 0.0005696885637007654 | train acc 1.0
step: 1640 | train loss: 0.0020063030533492565 | train acc 0.9557142853736877
step: 1640 | train loss: 0.002816234016790986 | train acc 0.9487179517745972
step: 1650 | train loss: 0.001378085813485086 | train acc 0.9661495089530945
step: 1650 | train loss: 0.007501807063817978 | train acc 0.949999988079071
step: 1660 | train loss: 0.0015159379690885544 | train acc 0.9652174115180969
step: 1660 | train loss: 0.0013531801523640752 | train acc 0.9487179517745972
step: 1670 | train loss: 0.001960420049726963 | train acc 0.9604685306549072
step: 1670 | train loss: 0.0028893635608255863 | train acc 0.90625
step: 1680 | train loss: 0.002332230331376195 | train acc 0.9521739482879639
step: 1680 | train loss: 0.00449617812409997 | train acc 0.8974359035491943
step: 1690 | train loss: 0.0028591162990778685 | train acc 0.9490566253662109
step: 1690 | train loss: 0.0016194988274946809 | train acc 1.0
step: 1700 | train loss: 0.0020236207637935877 | train acc 0.9579710364341736
step: 1700 | train loss: 0.000493245548568666 | train acc 1.0
step: 1710 | train loss: 0.0019850993994623423 | train acc 0.956584632396698
step: 1710 | train loss: 0.001363279763609171 | train acc 0.9736841917037964
step: 1720 | train loss: 0.0017561125569045544 | train acc 0.9708879590034485
step: 1720 | train loss: 0.0027014054358005524 | train acc 0.9743589758872986
step: 1730 | train loss: 0.003648570505902171 | train acc 0.9402778148651123
step: 1730 | train loss: 0.003843765938654542 | train acc 0.9705882668495178
step: 1740 | train loss: 0.001983201364055276 | train acc 0.9606987237930298
step: 1740 | train loss: 0.001817629556171596 | train acc 0.9473684430122375
step: 1750 | train loss: 0.0023906640708446503 | train acc 0.9529411792755127
step: 1750 | train loss: 0.005564264487475157 | train acc 0.949999988079071
step: 1760 | train loss: 0.0019638938829302788 | train acc 0.9516128897666931
step: 1760 | train loss: 0.0012089257361367345 | train acc 0.9750000238418579
step: 1770 | train loss: 0.0017179209971800447 | train acc 0.9614243507385254
step: 1770 | train loss: 0.00042598493746481836 | train acc 1.0
step: 1780 | train loss: 0.0013391950633376837 | train acc 0.9613733887672424
step: 1780 | train loss: 0.0033313746098428965 | train acc 0.9473684430122375
step: 1790 | train loss: 0.001379069872200489 | train acc 0.9757142663002014
step: 1790 | train loss: 0.001520431018434465 | train acc 0.9736841917037964
step: 1800 | train loss: 0.0022648489102721214 | train acc 0.9596541523933411
step: 1800 | train loss: 0.0006632221047766507 | train acc 1.0
step: 1810 | train loss: 0.0025118670891970396 | train acc 0.939393937587738
step: 1810 | train loss: 0.0023039299994707108 | train acc 0.9545454978942871
step: 1820 | train loss: 0.0022686878219246864 | train acc 0.9451219439506531
step: 1820 | train loss: 0.0009464158210903406 | train acc 1.0
step: 1830 | train loss: 0.0016373302787542343 | train acc 0.9675140976905823
step: 1830 | train loss: 0.0033283529337495565 | train acc 0.9677419066429138
***** Running evaluation *****
  Batch size = 8
***** Valid Eval results *****
  global_step = 1836
  valid_eval_accuracy = 0.8985637342908438
  valid_eval_loss = 0.37625753949835616
